<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数学通识50讲]]></title>
    <url>%2F2019%2F11%2F25%2F2019-11-25%2F</url>
    <content type="text"><![CDATA[00 ｜ 发刊词：数学该怎么学？ 模块一 ｜ 数学的线索 01 ｜ 导论：数学通识课的体系和学习攻略 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理 03 ｜ 数学的预见性：如何用推理走出认知盲区 04 ｜ 数学思维：数学家如何从逻辑出发想问题 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学 07 ｜ 数学应用：华罗庚化繁为简的神来之笔 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要 09 ｜ 数列和级数（二）：传销骗局的数学原理 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密 模块二 ｜ 数学的概念 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大 12 ｜ 三次方程：数学史上的发明权之争 13 ｜ 虚数：虚构这个工具有什么用 14 ｜ 无穷：我们为什么难以理解无限的世界？ 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？ 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？ 17 ｜ 无穷小（三）：用动态和极限的眼光看世界 00 ｜ 发刊词：数学该怎么学？# 模块一 ｜ 数学的线索# 01 ｜ 导论：数学通识课的体系和学习攻略# 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理# 03 ｜ 数学的预见性：如何用推理走出认知盲区# 04 ｜ 数学思维：数学家如何从逻辑出发想问题# 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理# 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学# 07 ｜ 数学应用：华罗庚化繁为简的神来之笔# 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要# 09 ｜ 数列和级数（二）：传销骗局的数学原理# 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密# 模块二 ｜ 数学的概念# 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大# 12 ｜ 三次方程：数学史上的发明权之争# 13 ｜ 虚数：虚构这个工具有什么用# 14 ｜ 无穷：我们为什么难以理解无限的世界？# 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？# 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？# 17 ｜ 无穷小（三）：用动态和极限的眼光看世界#]]></content>
      <tags>
        <tag>吴军,数学,长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL是怎样运行的：从根儿上理解 MySQL]]></title>
    <url>%2F2019%2F09%2F20%2F2019-9-20%2F</url>
    <content type="text"><![CDATA[重新认识MySQL 客户端 + 服务器 启动服务器程序 UNIX Windows 启动客户端程序 客户端与服务器的通信 TCP/IP 命名管道和共享内存 UNIX域套接字文件 服务器处理客户端请求 存储引擎 启动选项和系统变量 在命令行上使用选项 配置文件中使用选项 Windows UNIX 系统变量 查看系统变量 设置系统变量 状态变量 字符集和比较规则 字符集的转换 InnoDB记录存 InnoDB页 InnoDB行格式 Compact行格式 行数据溢出 行溢出的临界点 InnoDB数据页 数据页结构 记录在页中的存储 记录头信息 Page Directory Page Header File Header File Trailer B+树索引 无索引查找 在页内查找 在多页中查找 索引 目录项 用页存放目录项 聚簇索引 二级索引 B+树索引的使用 合理使用索引 全值匹配 匹配左边的列 匹配列前缀 回表的代价 二级索引 + 回表 or 全表扫码 覆盖索引 合理地建立索引 MySQL的数据目录 数据库和文件系统的关系 数据目录 数据目录和安装目录的区别 查找数据目录 数据目录的结构 数据库在文件系统中的表示 表在文件系统中的表示 文件系统对数据库的影响 MySQL系统数据库简介 本文为敝人的学习记录，感兴趣的请在掘金小册购买同名原著 😎 重新认识MySQL# 客户端 + 服务器# MySQL服务器进程(也叫数据库实例) MySQL客户端进程 进程：进程号(PID，由操作系统随机分配)、进程名称 MySQL服务器进程的默认名称为mysqld， MySQL客户端进程的默认名称为mysql 启动服务器程序# UNIX# 使用安装目录下(比如 /usr/local/mysql/bin/): 1mysqld 1mysqld_safe mysqld_safe是一个启动脚本的命令，调用了mysqld，并启动一个监控进程(重启，日志) 12mysql.server startysql.server stop mysql.server是一个链接文件， 会调用mysqld_safe Windows# 使用安装目录下(比如 D:\Program Files\mysql-5.7.26-winx64\bin\) mysqld.exe 可执行文件 使用 Windows服务。把某个程序注册为Windows服务的格式： &quot;可执行文件路径&quot; --install [-manual] [服务名称] 123D:\Program Files\mysql-5.7.26-winx64\bin\mysqld --install [MySQL_Service]net start MySQL_Servicenet stop MySQL_Service 启动客户端程序# mysql -h主机名 -u用户名 -p密码 123mysql -hlocalhost -uroot -p123abcmysql -u root -pmysql --host=localhost --user=root --password=123abc 退出客户端 123quitexit\q 客户端与服务器的通信# 本质是两个进程间的通信 TCP/IP# 每台计算机都有一个唯一的IP地址 每个进程向操作系统申请一个端口号(0~65535) 通过IP地址 + 端口号来与某个进程通信 MySQL服务器进程的默认端口号为3306，自定义MySQL服务器进程的端口号如下 1mysqld -P3307 命名管道和共享内存# Windows系统中的进程间通信方式 命名管道 12345mysqld --enable-named-pipemysql --pipeormysql --protocol=pipe 共享内存 123mysqld --shared-memorymysql --protocol=memory UNIX域套接字文件# 1mysql --protocol=socket 服务器程序默认监听的套接字文件路径为/tmp/mysql.sock，指定套接字文件路径： 12mysqld --socket=/tmp/a.txtmysql -hlocalhost -uroot --socket=/tmp/a.txt -p 服务器处理客户端请求# 存储引擎# XA列代表是否支持分布式事务 Savepoints代表是否支持部分事务回滚 启动选项和系统变量# 在命令行上使用选项# 12mysqld --skip-networkingmysqld --default-storage-engine=MyISAM \\ 等号两边不能有空格 使用mysql --help可以看到mysql程序支持的启动选项 使用mysqld --verbose --help查看mysqld支持的启动选项 配置文件中使用选项# Windows# 12345678910111213%WINDIR%\my.ini%WINDIR%\my.cnf C:\my.iniC:\my.cnfBASEDIR\my.ini \\ MySQL安装路径BASEDIR\my.cnf defaults-extra-file 命令行指定的额外配置文件路径，如mysqld --defaults-extra-file=C:\Users\chiangtao ho\my_extra_file.txt%APPDATA%\MySQL\.mylogin.cnf 登录路径选项（仅限客户端） UNIX# 12345678910/etc/my.cnf /etc/mysql/my.cnf SYSCONFDIR/my.cnf $MYSQL_HOME/my.cnf 特定于服务器的选项（仅限服务器）defaults-extra-file ~/.my.cnf 用户特定选项~/.mylogin.cnf 用户特定的登录路径选项（仅限客户端） 系统变量# 查看系统变量# 12SHOW VARIABLES like 'max_connections';SHOW VARIABLES LIKE 'default%'; 系统变量的单词之间必须使用下划线_连接 设置系统变量# 变量的作用范围 GLOBAL：全局变量，影响服务器的整体操作 SESSION (LOCAL)：会话变量，影响某个客户端连接的操作 123456SET GLOBAL default_storage_engine = MyISAM;SET @@GLOBAL.default_storage_engine = MyISAM;SET SESSION default_storage_engine = MyISAM;SET @@SESSION.default_storage_engine = MyISAM;SET default_storage_engine = MyISAM; \\ 默认作用范围是LOCAL 那我们的SHOW VARIABLES语句默认查看的是SESSION作用范围的系统变量 并不是所有系统变量都具有GLOBAL和SESSION的作用范围 状态变量# 与系统变量类似，状态变量也有GLOBAL和SESSION两个作用范围的 1SHOW STATUS LIKE 'thread%'; 字符集和比较规则# 查看字符集 12SHOW CHARSET;SHOW CHARACTER SET; Default collation表示字符集默认的比较规则 Maxlen代表该字符集表示一个字符最多需要几个字节 查看比较规则 MySQL中utf8是utf8mb3的别名，所以在MySQL中utf8就意味着使用1~3个字节来表示一个字符，如果大家有使用4字节编码一个字符的情况，比如存储一些emoji表情，使用utf8mb4 MySQL有4个级别的字符集和比较规则，分别是： 服务器级别 character_set_server, collation_server 数据库级别 character_set_database, collation_database 表级别 列级别 编码和解码使用的字符集不一致将导致乱码 字符集的转换# character_set_client 服务器解码请求语句时使用的字符集 character_set_connection 服务器处理请求时会把请求字符串从character_set_client转为character_set_connection character_set_results 服务器向客户端返回数据时使用的字符集 通常把 character_set_client 、character_set_connection、character_set_results 这三个系统变量设置成和客户端使用的相同的字符集 12345SET NAMES 字符集名;SET character_set_client = 字符集名;SET character_set_connection = 字符集名;SET character_set_results = 字符集名; InnoDB记录存# InnoDB页# InnoDB是一个将表中的数据存储到磁盘上的存储引擎。磁盘读写的速度比内存的读写速度差了几个数量级，因此设计InnoDB时将数据划分为若干个页并以页作为磁盘和内存之间交互的基本单位，页的大小一般为 16 KB。 InnoDB行格式# 4种行格式: Compact Redundant Dynamic Compressed 1CREATE TABLE 表名 ROW_FORMAT=行格式名称 Compact行格式# 所有变长字段的真实数据占用的字节长度都被存放在变长字段长度列表 把值为NULL的列统一存储到NULL值列表中 记录头信息是由固定的5个字节组成 MySQL会为每个记录默认的添加一些列（隐藏列），包括：row_id（DB_ROW_ID）、transaction_id（DB_TRX_ID）、roll_pointer（DB_ROLL_PTR）。 行数据溢出# 对于MySQL的每条记录，除了BLOB或者TEXT类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。这个65535个字节除了列本身的数据之外，还包括一些其他的数据，即 真实数据本身 真实数据占用字节的长度标识（&lt;= 2 bytes） NULL值标识（&lt;= 1 byte），当列都有NOT NULL属性时为0 因此，上图中设置变长类型VARCHAR(M)（M表示允许的字符数量）M=65535时导致了溢出。 真实数据：65533 = 65529(c1)+ 4(c2) 长度标识：2 NULL值标识：1 共65536 &gt; 65535溢出。 更换字符集后溢出。 VARCHAR(M)类型的列就最多可以存储65533个字节，而一个页的大小一般是16KB，也就是16384字节，因此在Compact和Reduntant行格式中，在本记录只会存储该列的前768个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中；而在Dynamic和Compressed行格式中，记录中只存储其他页的地址。 行溢出的临界点# MySQL中规定一个页中至少要存放两行记录 每个页除了存放记录外，也需要存储一些额外的信息，这些额外信息加起来需要132个字节 每个记录的额外信息需要27字节 真实数据的长度标识 1B NULL值标识 1B 记录头信息 5B row_id 6B transaction_id 6B roll_pointer 7B 不溢出的临界条件：132 + 2×(27 + n) &lt; 16384 InnoDB数据页# 数据页结构# 记录在页中的存储# 记录头信息# 以 page_demo 表为例 123456CREATE TABLE page_demo( c1 INT, c2 INT, c3 VARCHAR(10000), PRIMARY KEY (c1)) CHARSET=ascii ROW_FORMAT=Compact; 由于指定 c1 为主键，所以在行格式中就没有隐藏列 row_id。 插入数据4条记录 1234INSERT INTO page_demo VALUES(1, 100, 'aaaa'), (2, 200, 'bbbb'), (3, 300, 'cccc'), (4, 400, 'dddd'); delete_mask 标记当前记录是否被删除，值为0的时候代表记录没有被删除，1则被删除了； 所有被删的记录会组成一个垃圾链表，新记录插入到表时可以覆盖这些被删除的记录占用的存储空间。 n_owned 见Page Directory heap_no 表示当前记录在本页中的位置，从上图中可以看出，插入的4条记录在本页中的位置分别是：2、3、4、5。最小记录和最大记录分别为0、1。 record_type 记录类型，共4种： 0：普通记录 1：B+树非叶节点记录 （或目录项记录，见目录项） 2：最小记录 3：最大记录 min_rec_mask 代表B+树的每层非叶节点中的最小记录 （或者主键值最小的目录项记录的min_rec_mask值为1） next_record 表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。例如第一条记录的next_record值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。记录按照主键从小到大的顺序形成了一个单链表 如果删除第二条记录 1DELETE FROM page_demo WHERE c1 = 2; 删除第2条记录前后的主要变化： 第2条记录的delete_mask值设置为1； 第2条记录的next_record值变为了0，意味着该记录没有下一条记录了； 第1条记录的next_record指向了第3条记录； 最大记录的n_owned值从5变成了4。 Page Directory# 设计页目录是为了方便快速查找记录，就像书的目录那样，创建 page directory 的步骤： 将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组； 每个组内最大的那条记录的头信息的 n_owned 表示组内记录的数量； 将每个组的最大的那条记录的地址偏移量（也称槽，slot）集中起来存放，构成 Page Directory； InnoDB规定最小记录所在的分组只能有 1 条记录，最大记录所在的分组的记录条数在 1~8 条之间，其它分组中记录的条数则在是 4~8 条之间。 利用页目录查找指定主键的记录的过程分为两步： 通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录； 通过记录的 next_record 属性遍历组中的各个记录。 Page Header# 存储数据的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等。 File Header# 不同类型的页都会以File Header作为第一个组成部分，它记录了针对各种页都通用的一些信息。 索引页（数据页）通过 file header 构成双向链表 File Trailer# 与file header一样对不同类型的页通用，主要用于校验页数据的完整性。 B+树索引# 无索引查找# 在页内查找# 以主键查找 依据页目录（槽）采用二分查找定位分组，再遍历分组 以主键以外的列查找 遍历页内的记录链表 在多页中查找# 定位记录所在的页 页内查找 索引# 建立索引是为了快速定位记录所在的数据页。 对数据页进行排序。即让下一个数据页的记录的主键值大于上一个页的记录的主键值，因此在插入新的记录时涉及数据页间的记录的调整 对页进行排序后，全部记录的主键值就构成了一个递增的序列，从而可以利用二分法实现快速查找。 对每个页设置目录项 目录项# 目录项包括 数据页中的记录的最小主键值，用key来表示； 页号，用page_no表示。 用页存放目录项# 用户记录都存放在B+树的叶节点上，而目录项都存放在非页节点上。 聚簇索引# 特性包括： 依据记录的主键值排序 页内的记录是按照主键的大小顺序排成一个单向链表 数据页根据主键大小顺序排成一个双向链表 存放目录项记录的页根据主键大小分为不同的层次 B+树的叶节点存储的是完整的记录，即记录的所有列的值（包括隐藏列） 二级索引# 依据记录的其它列（比如c1）的值排序形成的B+树。将聚簇索引的主键值换为c1的值，此外，叶节点存储的不是完整的记录而只有主键和c1。 通过二级索引来查找完整记录：通过二级索引找到主键值之后再通过聚簇索引查找完整记录。 B+树索引的使用# 合理使用索引# 考虑表 person_info 123456789CREATE TABLE person_info( id INT NOT NULL auto_increment, name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, PRIMARY KEY (id), KEY idx_name_birthday_phone (name, birthday, phone)); idx_name_birthday_phone 为二级索引 全值匹配# 1SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone = '15123983239'; 由于查询优化器的存在，调换name、birthday、phone这几个搜索列的顺序不影响查询的执行过程。 匹配左边的列# 1SELECT * FROM person_info WHERE name = 'Ashburn'; 可以使用索引idx_name_birthday_phone，而 1SELECT * FROM person_info WHERE birthday = '1990-09-27'; 不能使用索引idx_name_birthday_phone。 匹配列前缀# 比如查询名字以 As 开头的记录 1SELECT * FROM person_info WHERE name LIKE 'As%'; 回表的代价# 1SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow'; 二级索引搜索到的结果（即值在Asa～Barlow之间的记录）在磁盘中的存储是相连的，集中分布在一个或几个数据页中，因此可以很快从磁盘中读出，这种读取方式可以称为顺序I/O。而回表是根据不连续的id值到聚簇索引中读出完整的用户记录（可能分布在不同的数据页中），这种读取方式可以称为随机I/O。一般情况下，顺序I/O比随机I/O的性能高很多。 二级索引 + 回表 or 全表扫码# 需要回表的记录越多，使用二级索引的性能就越低，甚至不如使用聚簇索引全表扫码； 使用LIMIT限制回表次数，使优化器倾向于使用二级索引 + 回表的方式执行查询。 覆盖索引# 如果需要查询的列包含在二级索引中，就可以避免回表查询，这种只需要用到索引的查询方式称为索引覆盖。例如对于索引idx_name_birthday_phone 1SELECT name, birthday, phone FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow' 合理地建立索引# 只给搜索、排序、分组的列创建索引 即只给出现在 WHERE、ORDER BY、GROUP BY 子句中的列创建索引； 列的方差越大越适合建立索引 列的数据越分散，越适合索引查询。举个极端的例子，数据都相同的列，对这样的列建立索引毫无意义； 列的数据类型越小越适合建立索引 比较数据大小更快，占用的存储空间更小； 索引字符串的前缀 1234567CREATE TABLE person_info( name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, KEY idx_name_birthday_phone (name(10), birthday, phone)); 其中 name(10) 表示在建立的B+树索引中只保留记录的前10个字符的编码，但是该索引不支持 name 排序 1SELECT * FROM person_info ORDER BY name LIMIT 10; 让索引列在比较表达式中单独出现 12WHERE my_col * 2 &lt; 4WHERE my_col &lt; 4/2 如果列是以某个表达式或者函数调用形式出现是用不到索引的，比如上面的my_col * 2； 开启主键AUTO_INCREMENT属性 可减少页分裂和记录移位的次数。 MySQL的数据目录# 数据库和文件系统的关系# InnoDB、MyISAM等存储引擎都是把表存储在磁盘上。操作系统通过文件系统管理磁盘。 InnoDB、MyISAM等存储引擎 $ \Leftrightarrow $ 文件系统 $ \Leftrightarrow $ 磁盘 数据目录# 数据目录和安装目录的区别# 数据目录是用来存储MySQL在运行过程中产生的数据，要与MySQL的安装目录区别开来。 查找数据目录# 数据目录的结构# 数据库在文件系统中的表示# 每新建一个数据库，MySQL执行了： 在数据目录下创建一个和数据库名同名的子目录； 并在该子目录下创建一个db.opt文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则等。 查看数据库 查看数据目录 除了information_schema这个系统数据库外，其他的数据库在数据目录下都有对应的子目录。 表在文件系统中的表示# 每个表包含两部分信息： 表结构的定义 用表名.frm文件来描述表结构 表中的数据 InnoDB: 数据存在独立表空间(file-per-table tablespace)中，即 test.ibd 文件 MyISAM: 表名.MYD表示表的数据文件、表名.MYI表示表的索引文件 文件系统对数据库的影响# 数据库名和表名不得超过文件系统所允许的最大长度 特殊字符 MySQL会把数据库名和表名中除数字和拉丁字母外的所有字符在文件名里都映射成 @+编码值的形式，如test?.frm $ \rightarrow $ test@003f.frm 文件大小受文件系统限制 MySQL系统数据库简介# mysql 存储了MySQL的账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息、以及时区信息等 information_schema 这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如表、视图、触发器、列、索引等 performance_schema 这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，包括统计最近执行的语句，执行时间，内存使用情况等 sys 这个数据库主要是通过视图的形式把information_schema和performance_schema结合起来 #]]></content>
      <tags>
        <tag>MySQL, 长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL Notes]]></title>
    <url>%2F2019%2F09%2F05%2F2019-9-5%2F</url>
    <content type="text"><![CDATA[联表查询 字符替换 正则查询 导入SQL文件 排序 联表查询# 12345678SELECT library.id, library.name, r.reader_sum, b.book_sum FROM library INNER JOIN( SELECT library_id, count(*) AS reader_sum FROM reader WHERE library_group_id = 10 GROUP BY library_id ) AS rON r.library_id = library.id INNER JOIN( SELECT library_id, count( * ) AS book_sum FROM book WHERE library_group_id = 10 GROUP BY library_id ) AS bON b.library_id = library.id; 字符替换# 1UPDATE account SET grade = replace(grade,'級','级'); 正则查询# 12SELECT * FROM account WHERE grade REGEXP '級'; -- 查询包含SELECT name FROM person WHERE name REGEXP '^[aeiou]|ok$'; -- aeiou开头，或ok结尾 导入SQL文件# 1234SET @@global.max_allowed_packet = 1024*1024*1024;SET @@global.sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';SET @@sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; 排序# 1SELECT * FROM book WHERE library_id = 257 AND (title REGEXP "我" OR author REGEXP "我") ORDER BY LOCATE("我", CONCAT(title, author)), LENGTH(title), LENGTH(author);]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麻省理工 MapReduce 实验]]></title>
    <url>%2F2019%2F04%2F30%2F2019-4-30%2F</url>
    <content type="text"><![CDATA[MapReduce执行概述 序言：熟悉源代码 Part I: Map/Reduce 输入和输出 Part II: Single-worker单词统计 Part III: 分布式 MapReduce 任务 Part IV: worker错误处理 原文链接 MapReduce执行概述# 论文地址 通过自动将输入数据划分为$M$个片段，Map调用分布在多台机器上。 不同片段的输入数据可以由不同的机器并行处理。 Reduce调用的分布式则通过使用分区函数(即 $hash(key)$ $mod$ $R$)将键空间划分为$R$个部分来实现，$R$的大小和分区函数由用户指定。上图显示了MapReduce操作的总体流程。 当用户程序调用MapReduce函数时，会发生以下操作序列(图中的编号标签对应于下面的数字)： 用户程序中的MapReduce库首先将输入文件拆分为16MB到64MB(用户可通过参数设置)的$M$个片段。 然后，它会在一组计算机上启动该程序的许多副本； master为副本之一，其余的是由master分配工作的workers。 有$M$个Map任务和$R$个Reduce任务需要分配。master为每个空闲的worker分配一个Map任务或Reduce任务； 被分配Map任务的worker读取相应输入片段。 它从输入片段中解析键/值对，并将键/值对传递给用户定义的Map函数。 Map函数生成的中间键/值对缓存在内存中； 内存中的键\值对被周期性地写入到本地磁盘，并通过分区函数划分为$R$个分区。 键\值对在本地磁盘的位置将被传回到master，master再将位置信息转发给Reduce worker； 当Reduce worker收到来自master的位置信息后，它使用远程过程调用(RPC)从Map worker的本地磁盘读取缓冲数据。 当Reduce worker读取了所有中间数据时，它会根据中间键进行排序，以便将所有相同的中间键组合在一起。 之所以需要排序是因为通常有许多不同的键映射到同一个reduce任务。 如果中间数据量太大而无法容纳在内存中，则使用外部排序； Reduce worker对排好序的中间数据进行遍历。对遇到的每个唯一中间键，它将键和相应的一组中间值传递给用户的Reduce函数。 Reduce函数的输出附加到此Reduce分区的最终输出文件。 完成所有Map任务和Reduce任务后，master会唤醒用户程序。 此时，用户程序中的MapReduce()将返回用户代码。 序言：熟悉源代码# 提供的Map/Reduce代码支持两种操作模式，即串行和分布式。 在前者中，map和reduce任务每次执行一个：首先是第一个map任务执行完成，然后是第二个，然后是第三个，等等。当所有map任务完成后，执行第一个reduce任务，然后是第二个，等等。这种模式虽然不快，但方便调试。 分布式模式运行着许多worker线程，这些线程先并行执行map任务，然后reduce任务。 这要快得多，但也难以调试。mapreduce包提供了一个简单的Map/Reduce库。 应用程序通常调用master.go中的Distributed()来启动分布式模式，而调用master.go中的Sequential()来获取调试的串行执行。 代码如下执行： 该应用程序提供了许多输入文件、一个map函数、一个reduce函数和reduce任务的数量（$nReduce$）； 创建master。 master启动一个RPC服务器(参见master_rpc.go)，并等待worker注册(使用RPC调用Register()，在master.go中定义)。 当任务变得可用时(在步骤4和5中)，schedule()(位于schedule.go)决定如何将这些任务分配给workers以及如何处理worker故障； master将每个输入文件视为一个 Map任务，并为每个Map任务至少调用一次(at-least-once)doMap()(common_map.go)，可以通过直接使用Sequential()或通过向worker (worker.go)发出DoTask RPC来实现。每次调用doMap()都会读取适当的文件，调用该文件中的map函数，并将生成的键/值对写入$nReduce$个中间文件。doMap() 对每个键哈希化以便挑选中间文件和 将会处理键的reduce任务。 完成所有map任务后，将会有$nMap \times nReduce$个文件。 每个文件名都包含一个前缀，map任务编号和reduce任务编号。 如果有两个map任务和三个reduce任务，map任务将创建如下六个中间文件： mrtmp.xxx-0-0 mrtmp.xxx-0-1 mrtmp.xxx-0-2 mrtmp.xxx-1-0 mrtmp.xxx-1-1 mrtmp.xxx-1-2 每个worker必须能够读取由任何其他worker写入的文件以及输入文件。 现实部署利用分布式存储系统(如GFS)来允许此读取，即使workers在不同的计算机上运行。 在本实验中，您将在同一台计算机上运行所有workers，并使用本地文件系统； 接下来master为每个reduce任务至少调用一次(at-least-once) doReduce()(common_reduce.go)。 与doMap()一样，可以直接或通过worker来完成。 用于reduce任务r的`doReduce()从每个map任务中收集第$r$个中间文件，并为这些文件中出现的每个键调用reduce函数。 reduce任务生成$nReduce$个结果文件； master调用mr.merge()(master_splitmerge.go)，将上一步生成的所有$nReduce$个文件合并为单个输出； master向每个woker发送Shutdown RPC，然后关闭自己的RPC服务器。 说明：在后续的练习中，您必须编写/修改doMap()，doReduce()和schedule()，它们分别位于common_map.go、common_reduce.go和schedule.go中。 您还必须在../main/wc.go中编写map函数和reduce函数。 Part I: Map/Reduce 输入和输出# 提供的Map/Reduce实现缺少部分代码。 在编写第一个Map/Reduce函数对之前，您需要修改sequential的实现代码。 特别是，提供的代码缺少两个关键部分：分配一个map任务输出的函数，以及收集一个reduce任务所有输入的函数。 这些任务分别由common_map.go中的doMap()函数和common_reduce.go中的doReduce()函数执行。 为了帮助您确定是否正确实现了doMap()和doReduce()，我们为您提供了一个Go测试套件(test_test.go)用于检查文件中实现。 例如测试修改后的sequence实现代码，请运行： go test -run Sequential or go test -v -run Sequential 解答： 该部分任务只需要补全common_map.go中的doMap()和common_reduce.go中的doReduce()的代码，补全的结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package mapreduceimport ( "hash/fnv" "io/ioutil" "encoding/json" "log" "os")func doMap( jobName string, // the name of the MapReduce job mapTask int, // which map task this is inFile string, nReduce int, // the number of reduce task that will be run ("R" in the paper) mapF func(filename string, content string) []KeyValue,) &#123; // // doMap manages one map task: it should read one of the input files // (inFile), call the user-defined map function (mapF) for that file's // content, and partition mapF's output into nReduce intermediate files. // // There is one intermediate file per reduce task. The file name // includes both the map task number and the reduce task number. Use // the filename generated by reduceName(jobName, mapTask, r) // as the intermediate file for reduce task r. Call ihash() (see // below) on each key, mod nReduce, to pick r for a key/value pair. // // mapF() is the map function provided by the application. The first // argument should be the input file name, though the map function // typically ignores it. The second argument should be the entire // input file content. mapF() returns a slice containing the // key/value pairs for reduce; see common.go for the definition of // KeyValue. // // Look at Go's ioutil and os packages for functions to read // and write files. // // Coming up with a scheme for how to format the key/value pairs on // disk can be tricky, especially when taking into account that both // keys and values could contain newlines, quotes, and any other // character you can think of. // // One format often used for serializing data to a byte stream that the // other end can correctly reconstruct is JSON. You are not required to // use JSON, but as the output of the reduce tasks *must* be JSON, // familiarizing yourself with it here may prove useful. You can write // out a data structure as a JSON string to a file using the commented // code below. The corresponding decoding functions can be found in // common_reduce.go. // // enc := json.NewEncoder(file) // for _, kv := ... &#123; // err := enc.Encode(&amp;kv) // // Remember to close the file after you have written all the values! // // Your code here (Part I). //读取输入文件 content, err := ioutil.ReadFile(inFile) if err != nil &#123; log.Fatal("doMap读取输入文件错误",err) &#125; //map操作 kvPairs := mapF(inFile, string(content)) //调用mapF，返回键值对 //将键值对写入到中间文件 tmpFiles := make([] *os.File, nReduce) //R个中间文件 encoders := make([] *json.Encoder, nReduce) for i := 0; i &lt; nReduce; i++ &#123; tmpFileName := reduceName(jobName, mapTask, i) //中间文件名,mrtmp.test-mapTask-i tmpFiles[i], err = os.Create(tmpFileName) //创建中间文件mrtmp.test-mapTask-i if err != nil &#123; log.Fatal("doMap生成中间文件错误", err) &#125; defer tmpFiles[i].Close() encoders[i] = json.NewEncoder(tmpFiles[i]) if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125; for _ , kv := range kvPairs &#123; hashKey := ihash(kv.Key) % nReduce //根据键将键值对分成R组 err := encoders[hashKey].Encode(&amp;kv) //将R个键值对写入R个中间文件 if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125;&#125;func ihash(s string) int &#123; h := fnv.New32a() h.Write([]byte(s)) return int(h.Sum32() &amp; 0x7fffffff)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package mapreduceimport ( "encoding/json" "log" "os" "sort")func doReduce( jobName string, // the name of the whole MapReduce job reduceTask int, // which reduce task this is outFile string, // write the output here nMap int, // the number of map tasks that were run ("M" in the paper) reduceF func(key string, values []string) string,) &#123; // // doReduce manages one reduce task: it should read the intermediate // files for the task, sort the intermediate key/value pairs by key, // call the user-defined reduce function (reduceF) for each key, and // write reduceF's output to disk. // // You'll need to read one intermediate file from each map task; // reduceName(jobName, m, reduceTask) yields the file // name from map task m. // // Your doMap() encoded the key/value pairs in the intermediate // files, so you will need to decode them. If you used JSON, you can // read and decode by creating a decoder and repeatedly calling // .Decode(&amp;kv) on it until it returns an error. // // You may find the first example in the golang sort package // documentation useful. // // reduceF() is the application's reduce function. You should // call it once per distinct key, with a slice of all the values // for that key. reduceF() returns the reduced value for that key. // // You should write the reduce output as JSON encoded KeyValue // objects to the file named outFile. We require you to use JSON // because that is what the merger than combines the output // from all the reduce tasks expects. There is nothing special about // JSON -- it is just the marshalling format we chose to use. Your // output code will look something like this: // // enc := json.NewEncoder(file) // for key := ... &#123; // enc.Encode(KeyValue&#123;key, reduceF(...)&#125;) // &#125; // file.Close() // // Your code here (Part I). //遍历属于自己的中间文件，将键值对合并到kvs中 kvs := make(map[string][]string) for i := 0; i &lt; nMap; i++ &#123; fileName := reduceName(jobName, i, reduceTask) file, err := os.Open(fileName) //打开中间文件mrtmp.test-i-reduceTask if err != nil &#123; log.Fatal("doReduce打开文件错误", err) &#125; dec := json.NewDecoder(file) for &#123; //每个中间文件可能包含多个键值对 var kv KeyValue err = dec.Decode(&amp;kv) //解码一个键值对 if err != nil &#123; break &#125; _, ok := kvs[kv.Key] if !ok &#123; //出现新的键则初始化kvs kvs[kv.Key] = []string&#123;&#125; &#125; kvs[kv.Key] = append(kvs[kv.Key], kv.Value) //加入与键对应的值 &#125; file.Close() &#125; //将键集合到一起并排序 var keys []string for k := range kvs &#123; keys = append(keys, k) &#125; sort.Strings(keys) //创建输出文件 out := mergeName(jobName, reduceTask) file, err := os.Create(out) if err != nil &#123; log.Fatal("doReduce创建输出文件错误", err) &#125; enc := json.NewEncoder(file) //reduce操作 for _, k := range keys &#123; res := reduceF(k, kvs[k]) //调用客户端的reduceF，进行reduce enc.Encode(KeyValue&#123;k, res&#125;) //reduce后的键值对写入到输出文件 &#125; file.Close()&#125; 运行go test -run Sequential，结果如下： Part II: Single-worker单词统计# 在该部分，您将要实现一个简单的Map/Reduce示例——单词统计。 具体是需要实现main/wc.go中的mapF()和reduceF()函数。 您的工作是插入代码，以便wc.go返回输入文件中每个单词出现的次数。 一个单词是任意连续的字母序列，其中字母可用Golang的unicode.IsLetter函数来判断。 在~/6.824/src/main目录中提供了一些路径名为pg-*.txt形式的输入文件， 可用如下命令给wc.go使用输入文件运行： go run wc.go master sequential pg-*.txt 查看MapReduce论文的第2部分。mapF()和reduceF()函数与论文第2.1节中的函数略有不同。mapF()将接收一个文件名和该文件的内容，并将内容分成单词最终输出一个mapreduce.KeyValue型切片。 对于单词统计可将单词作为键。对输出中的每个键都将调用一次reduceF()，其中包含mapF()为该键生成的所有值的切片。 reduceF()返回一个包含键出现总数的字符串。 提示1：关于Go的字符串处理，可以参读 Go Blog on strings 提示2：可以使用strings.FieldsFunc函数将字符串拆分成单词 提示3： 利用Go的strconv包可以很方便地将字符串转换成整型 使用如下命令来验证答案： go run wc.go master sequential pg-*.txt 答案： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt" "mapreduce" "os" "strconv" "strings" "unicode")//// The map function is called once for each file of input. The first// argument is the name of the input file, and the second is the// file's complete contents. You should ignore the input file name,// and look only at the contents argument. The return value is a slice// of key/value pairs.//func mapF(filename string, contents string) []mapreduce.KeyValue &#123; // Your code here (Part II). var res []mapreduce.KeyValue f := func(c rune) bool &#123; //不是字母 return !unicode.IsLetter(c) &#125; words := strings.FieldsFunc(contents, f) //在不是字母地方拆分字符串contents for _, key := range words &#123; res = append(res, mapreduce.KeyValue&#123;key, "1"&#125;) &#125; return res&#125;//// The reduce function is called once for each key generated by the// map tasks, with a list of all the values created for that key by// any map task.//func reduceF(key string, values []string) string &#123; // Your code here (Part II). count := 0 for _, value := range values &#123; num, _ := strconv.ParseInt(value, 10, 64) // 将字符串value（例如："157"）按照十进制转换成整型 count = count + int(num) &#125; return strconv.Itoa(count) //整型转换成字符串&#125;// Can be run in 3 ways:// 1) Sequential (e.g., go run wc.go master sequential x1.txt .. xN.txt)// 2) Master (e.g., go run wc.go master localhost:7777 x1.txt .. xN.txt)// 3) Worker (e.g., go run wc.go worker localhost:7777 localhost:7778 &amp;)func main() &#123; if len(os.Args) &lt; 4 &#123; fmt.Printf("%s: see usage comments in file\n", os.Args[0]) &#125; else if os.Args[1] == "master" &#123; var mr *mapreduce.Master if os.Args[2] == "sequential" &#123; mr = mapreduce.Sequential("wcseq", os.Args[3:], 3, mapF, reduceF) &#125; else &#123; mr = mapreduce.Distributed("wcseq", os.Args[3:], 3, os.Args[2]) &#125; mr.Wait() &#125; else &#123; mapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil) &#125;&#125; 运行go run wc.go master sequential pg-sherlock_holmes.txt和sort -n -k2 mrtmp.wcseq | tail -10的结果： Part III: 分布式 MapReduce 任务# 在当前的实现中，是通过串行的方式来执行Map任务和Reduce任务。 Map/Reduce最大的卖点之一是它可以自动地并行执行原始的串行代码而无需开发人员的任何额外工作。 在这一部分中，您将完成一个分布式MapReduce版本，即将工作拆分为在多核上运行的一组worker线程。 尽管不像真实的Map/Reduce部署被分布在多台机器上那样，但你本部分的实现中将使用RPC来模拟分布式计算。 mapreduce/master.go中的代码完成了管理MapReduce的大部分工作。 我们还为您提供了mapreduce/worker.go中worker线程的完整代码以及在mapreduce/common_rpc.go中处理RPC的一些代码。 你的任务是实现mapreduce/schedule.go中的schedule()函数。 master在MapReduce期间将两次调用schedule()，一次用于Map阶段，一次用于Reduce阶段。 schedule()的功能是将任务分发给可用的worker。 任务的数量通常比worker线程多，因此schedule()必须为每个worker分配一系列任务，一次一个。 schedule()应该等到所有任务都完成后再返回。 schedule()通过读取registerChan参数来了解一组worker。 该channel为每个worker生成一个包含worker的RPC地址的字符串。所有的worker都会出现在registerChan，其中一些worker可能在调用schedule()之前就存在，而另一些worker可能在schedule()运行时才启动。schedule()应该充分利用所有的worker，包括启动后出现的worker。 schedule()通过向worker发送Worker.DoTaskRPC来通知worker执行任务。 此RPC的参数由mapreduce/common_rpc.go中的DoTaskArgs定义。File元素仅由Map任务使用，代表要读取的文件的名称；schedule()可以在mapFiles中找到这些文件名。 使用mapreduce/common_rpc.go中的call()函数将RPC发送给worker。 第一个参数是worker的地址，从registerChan读取，第二个参数是Worker.DoTask， 第三个参数是DoTaskArgs结构，最后一个参数是nil。 您对在第III部分的解答仅涉及对schedule.go的修改；如果您在调试过程中修改了其他文件，请恢复其原始内容。请先测试再提交。 使用go test -run TestParallel来测试您的答案。 该命令将执行两个测试，TestParallelBasic和TestParallelCheck，后者验证您的schedule()是否使worker并行执行任务。 提示1：schedule()应该并行地向worker发送RPC，以便worker可以并发执行任务。 你会发现go语句对此很有用，参见Concurrency in Go。 提示2：schedule()必须等待worker完成一个任务后才能给它另下一个任务，Go的channel对此很有用。 提示3： sync.WaitGroup 提示4：追踪错误的最简单的方法是插入print语句（在common.go中可能是调用debug()），使用go test -run TestParallel &gt; out将输出收集到一个文件中，然后分析输出是否与你对代码的预期相符。 最后一步是最重要的。 提示5：检查您的代码是否有竞争的情况可在测试中运行race detector。 注意：我们提供的代码是在单个UNIX进程中将worker作为线程运行，并且可以在单台机器上使用多核。 要想在使用网络进行通信的多台机器上运行worker必须进行一些修改：RPC必须使用TCP而不是UNIX-domain套接字；需要有一种方法来启动所有机器上的worker进程；所有的机器都必须通过某种网络文件系统共享存储。 答案见Part IV。 Part IV: worker错误处理# 在这部分中，您将实现master处理失败的worker的功能。由于worker的状态不是持久的，该功能在MapReduce中相对容易实现。 如果worker在处理来自master的RPC时发生错误，master的call()最终会因超时而返回false。在这种情况下，master会将该任务重新分配给另一个worker。 RPC故障并不一定意味着worker没有执行任务；worker可能已执行任务但是返回结果丢失，或者worker可能仍在执行但master的RPC超时。因此，可能会发生两个worker接收相同任务、计算并产生输出的情况。 需要对map或reduce函数进行两次调用才能为给定输入生成相同的输出，因此如果后续处理读取一个输出或者读取另一个输出，则不会出现不一致。 此外，MapReduce框架确保map和reduce函数输出以原子方式出现：输出文件要么不存在，要么包含单个map或单个reduce函数执行的整个输出（提供的代码不涉及这部分）。 您的实现必须通过test_test.go中剩下的两个测试用例。 第一个用例测试一个worker的失败，而第二个测试用例测试对多个worker的失败的处理。 测试用例会定期启动新的worker，master可以使用这些worker来推进程序过程，但这些worker在处理完一些任务后会失败。 使用下面的命令来运行测试： go test -run Failure 在第IV部分，只涉及对schedule.go的修改。 如果您在调试过程中修改了其他文件，请恢复其原始内容，然后再进行测试、提交。 Part III、Part IV答案： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mapreduceimport "fmt"//// schedule() starts and waits for all tasks in the given phase (mapPhase// or reducePhase). the mapFiles argument holds the names of the files that// are the inputs to the map phase, one per map task. nReduce is the// number of reduce tasks. the registerChan argument yields a stream// of registered workers; each item is the worker's RPC address,// suitable for passing to call(). registerChan will yield all// existing registered workers (if any) and new ones as they register.//func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) &#123; var ntasks int var n_other int // number of inputs (for reduce) or outputs (for map) switch phase &#123; case mapPhase: ntasks = len(mapFiles) n_other = nReduce case reducePhase: ntasks = nReduce n_other = len(mapFiles) &#125; fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other) // All ntasks tasks have to be scheduled on workers. Once all tasks // have completed successfully, schedule() should return. // // Your code here (Part III, Part IV). // done := make(chan bool) for i := 0; i &lt; ntasks; i++ &#123; go func(num int) &#123; args := DoTaskArgs&#123;jobName, mapFiles[num], phase, num, n_other&#125; var worker string reply := new(struct&#123;&#125;) ok := false for ok != true &#123; worker = &lt;-registerChan ok = call(worker, "Worker.DoTask", args, reply) &#125; done &lt;- true //任务完成 registerChan &lt;- worker //该worker工作完毕，处于空闲，加入channel中以分配给其它任务 &#125;(i) &#125; for i := 0; i &lt; ntasks; i++ &#123; //等待所有任务完成 &lt;-done &#125; fmt.Printf("Schedule: %v done\n", phase)&#125; 运行go test -run TestParallel的结果：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[远程过程调用和线程(RPC and Thread)]]></title>
    <url>%2F2019%2F03%2F25%2F2019-3-25%2F</url>
    <content type="text"><![CDATA[MIT Distributed System Course: Lecture 2 Remote Procedure Call (RPC) 目标： 建立编程友好的客户端/服务器通信 RPC消息图： 客户端 服务器 请求---&gt; &lt;---响应 软件结构： client app handlers stubs dispatcher RPC lib RPC lib net ------------ net Go rpc包： 官方文档 import &quot;net/rpc rpc包提供对通过网络或其他I / O连接的对象的导出方法的访问。 服务器注册一个对象，并作为一种服务可见。 注册的对象其导出方法可以被远程访问。 服务器可以注册不同类型的多个对象（服务），但是注册相同类型的多个对象是错误的。 只有满足下列标准的方法（method）才能被远程访问： the method's type is exported. the method is exported. the method has two arguments, both exported (or builtin) types. the method's second argument is a pointer. the method has return type error. 实际上，该方法必须看起来像 1func (t *T) MethodName(argType T1, replyType *T2) error 其中T1和T2可以通过 encoding/gob包来编码。即便使用不同的编解码器，上述标准仍然适用。 第一个参数T1表示调用者提供的参数;第二个参数T2表示要返回给调用者的结果参数。服务器可以通过调用ServeConn来处理单个连接上的请求。更典型的例子有创建网络侦听器并调用Accept，创建HTTP侦听器并调用HandleHTTP和http.Serve。 希望使用该服务的客户端首先和服务器建立连接，然后在连接的基础上调用NewClient。可以使用Dial函数（DialHTTP）方便地执行原始网络连接（HTTP连接）的两个步骤。新建的客户端对象具备Call方法和Go方法。 Call方法等待远程调用完成，而Go方法使用Call结构的Done通道启动异步调用和发出完成信号。 除非设置了显式编解码器，否则一般使用encoding/gob包来传输数据。 一个服务器导出Arith类型的对象的例子： 123456789101112131415161718192021222324252627package serverimport "errors"type Args struct &#123; A, B int&#125;type Quotient struct &#123; Quo, Rem int&#125;type Arith intfunc (t *Arith) Multiply(args *Args, reply *int) error &#123; *reply = args.A * args.B return nil&#125;func (t *Arith) Divide(args *Args, quo *Quotient) error &#123; if args.B == 0 &#123; return errors.New("divide by zero") &#125; quo.Quo = args.A / args.B quo.Rem = args.A % args.B return nil&#125; 服务器端调用 HTTP service： 12345678arith := new(Arith)rpc.Register(arith)rpc.HandleHTTP()l, e := net.Listen("tcp", ":1234")if e != nil &#123; log.Fatal("listen error:", e)&#125;go http.Serve(l, nil) 现在，客户端拥有了一项服务Arith，该服务提供了Arith.Multiply和Arith.Divide方法。要调用这些方法，客户端得先拨通服务器： 1234client, err := rpc.DialHTTP("tcp", serverAddress + ":1234")if err != nil &#123; log.Fatal("dialing:", err)&#125; 然后进行远程调用： 12345678// Synchronous callargs := &amp;server.Args&#123;7,8&#125;var reply interr = client.Call("Arith.Multiply", args, &amp;reply)if err != nil &#123; log.Fatal("arith error:", err)&#125;fmt.Printf("Arith: %d*%d=%d", args.A, args.B, reply) 或者 12345// Asynchronous callquotient := new(Quotient)divCall := client.Go("Arith.Divide", args, quotient, nil)replyCall := &lt;-divCall.Done // will be equal to divCall// check errors, print, etc. 服务器通常会为客户端提供一个简单的、类型安全的封装。 net/rpc包已冻结，不会增加新的功能属性。 Go举例： 一个简单的key/value存储服务器——Put(key,value), Get(key)-&gt;value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package mainimport ( "fmt" "log" "net" "net/rpc" "sync")//// RPC request/reply definitions//const ( OK = "OK" ErrNoKey = "ErrNoKey")type Err stringtype PutArgs struct &#123; Key string Value string&#125;type PutReply struct &#123; Err Err&#125;type GetArgs struct &#123; Key string&#125;type GetReply struct &#123; Err Err Value string&#125;//// Client//func connect() *rpc.Client &#123; client, err := rpc.Dial("tcp", ":1234") if err != nil &#123; log.Fatal("dialing:", err) &#125; return client&#125;func get(key string) string &#123; client := connect() args := GetArgs&#123;Key: key&#125; reply := GetReply&#123;&#125; err := client.Call("KV.Get", &amp;args, &amp;reply) //远程调用KV.Get，等待它完成，并返回其错误状态。 if err != nil &#123; log.Fatal("error:", err) &#125; client.Close() log.Println(reply.Err) return reply.Value&#125;func put(key string, val string) &#123; client := connect() args := PutArgs&#123;Key: key, Value: val&#125; reply := PutReply&#123;&#125; err := client.Call("KV.Put", &amp;args, &amp;reply) //远程调用KV.Put if err != nil &#123; log.Fatal("error:", err) &#125; client.Close()&#125;//// Server//type KV struct &#123; mu sync.Mutex data map[string]string&#125;func server() &#123; kv := new(KV) kv.data = map[string]string&#123;&#125; rpcs := rpc.NewServer() rpcs.Register(kv) l, e := net.Listen("tcp", ":1234") if e != nil &#123; log.Fatal("listen error:", e) &#125; go func() &#123; for &#123; conn, err := l.Accept() if err == nil &#123; go rpcs.ServeConn(conn) &#125; else &#123; break &#125; &#125; l.Close() &#125;()&#125;func (kv *KV) Get(args *GetArgs, reply *GetReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() val, ok := kv.data[args.Key] if ok &#123; reply.Err = OK reply.Value = val &#125; else &#123; reply.Err = ErrNoKey reply.Value = "" &#125; return nil&#125;func (kv *KV) Put(args *PutArgs, reply *PutReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value reply.Err = OK return nil&#125;//// main//func main() &#123; server() put("passwd", "2w6C*kcXWWmzK$Jg") //客户端存储密码 fmt.Println(get("passwd")) //客户端获取密码&#125;command-line-arguments2019/04/02 18:34:11 OK2w6C*kcXWWmzK$Jg 共同：必须为每种RPC类型声明Args和Reply结构 Client: connect()的Dial()创建与服务器的TCP连接 Call()要求RPC库执行远程调用 指定server function name, args,reply library marshalls args, sends request, waits, unmarshally reply Call()的返回值表示是否收到回复 usually you'll also have a reply.Err indicating service-level failure server： Go要求您声明一个带有方法的对象作为RPC处理程序(RPC handler) 然后，您使用RPC库注册该对象 您接受TCP连接，并给它们提供RPC库 RPC库 读取每个请求 为此请求创建一个新的goroutine unmarshalls request 调用命名方法（调度） marshalls reply 在TCP连接上写回复 服务器的Get()和Put()处理程序 必须锁定，因为RPC库给每个请求创建goroutines 解读args; 修改reply 线程: 线程是一种有用的结构化工具 Go称他们为goroutines;其他人称他们为线程 他们可能很棘手 Why threads? 用它们实现并发，在分布式系统中自然地出现 I / O并发： 在等待来自其他服务器的响应时，处理下一个请求 多核： 线程在多个核心上并行运行 Thread =“执行线程” 线程允许一个程序（逻辑上）一次执行许多事情 线程共享内存 each thread includes some per-thread state，包括：程序计数器，寄存器，堆栈 程序中有多少个线程？ 由结构驱动 例如每个客户端一个线程，一个用于后台任务 多核并行 one active thread per core。Go的 runtime 自动地在可用内核上调度可运行的goroutine I / O并发 数量由延迟和容量决定 继续增加直到吞吐量停止增长 Go threads are pretty cheap 100或1000是好的，但可能达不到数百万的量级 创建线程比方法调用更昂贵 Threading challenges： 共享数据 一个线程读取另一个线程正在改变的数据？例如当两个线程执行count = count + 1时，this is a &quot;race&quot; -- and is usually a bug ——使用互斥锁（或其他同步） ——或避免共享 线程之间的协调 如何等待所有Map线程完成？ ——使用Go channel或WaitGroup 并发的粒度 粗粒度(coarse-grained) —— 简单，但并发/并行很少 细粒度 —— 更多的并发、竞争(race)和死锁 什么是爬虫？ 目标是获取所有网页，例如提供给索引器(indexer) 网页形成一个图(graph) 每个页面的多个链接 graph has cycles Crawler challenges 安排I / O并发 同时获取多个URL 增加每秒获取的URL 由于网络延迟远远超过网络容量 Fetch each URL only once 避免浪费网络带宽 对远程服务器很好 需要记住访问过的URL 知道什么时候完成 Crawler solutions： 串行爬虫： fetched map 避免重复、进入死循环 它是一个单一的映射，通过递归调用传递 一次只能爬取一页 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// 串行爬虫func Serial(url string, fetcher Fetcher, fetched map[string]bool) &#123; if fetched[url] &#123; // 已经爬取 return &#125; fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; for _, u := range urls &#123; Serial(u, fetcher, fetched) &#125; return&#125;func main() &#123; Serial("http://golang.org/", fetcher, make(map[string]bool))&#125; ConcurrentMutex爬虫： 为每个页面的爬取创建一个线程，因此可以并发爬取，爬取率更高 线程共享 fetched map Why the Mutex (== lock)? 没有锁： 两个网页包含指向同一URL的链接，导致两个线程同时获取这这个页面 T1、T2检查获取[url]，当两者都看到url尚未获取，两者都取，导致错误 同时读写（或写入+写入）是竞争 如果我注释掉Lock()/Unlock()调用会发生什么？ go run crawler.go go run -race crawler.go The lock causes the check and update to be atomic How does it decide it is done? sync.WaitGroup implicitly waits for children to finish recursive fetches 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt" "sync")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with shared state and Mutextype fetchState struct &#123; mu sync.Mutex fetched map[string]bool&#125;func makeState() *fetchState &#123; f := &amp;fetchState&#123;&#125; f.fetched = make(map[string]bool) return f&#125;func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) &#123; f.mu.Lock() if f.fetched[url] &#123; // 已经爬取 f.mu.Unlock() return &#125; f.fetched[url] = true f.mu.Unlock() urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; var done sync.WaitGroup for _, u := range urls &#123; done.Add(1) go func(u string) &#123; defer done.Done() //等价于defer done.Add(-1) ConcurrentMutex(u, fetcher, f) &#125;(u) &#125; done.Wait() //等待所有的goroutine完成 return&#125;func main() &#123; ConcurrentMutex("http://golang.org/", fetcher, makeState())&#125; ConcurrentChannel爬虫 Go channel： channel是一个对象,可能有很多个, ch：= make（chan int） channel允许一个线程将对象发送到另一个线程： ch &lt; - x，sender等待goroutine接收 y：= &lt; - ch; for y := range ch，receiver等待goroutine发送 可以用channel来进行通信和同步 多个线程可以在一个channel上发送和接收 在发送时握住锁可能很危险... ConcurrentChannel master（） master()创建一个worker goroutine来获取每个页面 worker()在channel上发送URL 多个worker在一个channel上发送 master()从channel中读取URL [图：主人，通道，工人] 无需锁定 fetched map，因为它不是共享的！ 有共享数据吗？ channel 通道上发送的切片和字符串 master()传递给worker()的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with channelsfunc worker(url string, ch chan []string, fetcher Fetcher) &#123; urls, err := fetcher.Fetch(url) if err != nil &#123; ch &lt;- []string&#123;&#125; &#125; else &#123; ch &lt;- urls &#125;&#125;func master(ch chan []string, fetcher Fetcher) &#123; n := 1 fetched := make(map[string]bool) for urls := range ch &#123; for _, u := range urls &#123; if fetched[u] == false &#123; fetched[u] = true n += 1 go worker(u, ch, fetcher) &#125; &#125; n -= 1 if n == 0 &#123; break &#125; &#125;&#125;func ConcurrentChannel(url string, fetcher Fetcher) &#123; ch := make(chan []string) go func() &#123; ch &lt;- []string&#123;url&#125; &#125;() master(ch, fetcher)&#125;func main() &#123; ConcurrentChannel("http://golang.org/", fetcher)&#125; **什么时候使用sharing和locks，而不是channels？** - 大多数问题都可以用任何一种方式解决 - 最有意义的取决于程序员的想法 state(状态) -- sharing and locks communication -- channels waiting for events -- channels - 使用Go的竞争检测器： [Data Race Detector](https://golang.org/doc/articles/race_detector.html) go test -race]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>RPC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go并发模式 (Cocurrency Pattern)]]></title>
    <url>%2F2019%2F02%2F10%2F2019-2-10%2F</url>
    <content type="text"><![CDATA[这篇博客的原创来自Go的官方博客，其中提供了丰富的关于Go的并发的相关资料。本文仅仅是对 Rob Pike 的演讲 Go Concurrency Patterns 和 Sameer Ajmani 的续集 Advanced Go Concurrency Patterns 的学习，相关内容的视频和ppt在网上都可以找到。 1. 函数返回 channel# 12345678910111213141516171819202122232425262728293031323334package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(3e3)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("boring!") // 通道作为返回的函数 for i := 0; i &lt; 5; i++ &#123; fmt.Printf("You say: %q\n", &lt;-c) &#125; fmt.Println("You're boring; I'm leaving.")&#125;输出：You say: "boring! 0"You say: "boring! 1"You say: "boring! 2"You say: "boring! 3"You say: "boring! 4"You're boring; I'm leaving. 2. 通道作为服务# 12345678910111213141516171819202122func main() &#123; joe := boring("Joe") ann := boring("Ann") for i := 0; i &lt; 5; i++ &#123; fmt.Println(&lt;-joe) fmt.Println(&lt;-ann) &#125; fmt.Println("You're both boring; I'm leaving.")&#125;输出：Joe 0Ann 0Joe 1Ann 1Joe 2Ann 2Joe 3Ann 3Joe 4Ann 4You're both boring; I'm leaving. 3.多重通道(扇入函数，fan-in function)# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &#125; &#125;() return c&#125;func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; fmt.Println("You're both boring; I'm leaving.")&#125; 4. 通道发送通道，使 goroutine 有序# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( "fmt" "math/rand" "time")type Message struct &#123; str string wait chan bool&#125;func boring(msg string) chan Message &#123; c := make(chan Message) waitForIt := make(chan bool) // 被所有 Message 共享 go func() &#123; for i := 0; ; i++ &#123; c &lt;- Message&#123;fmt.Sprintf("%s: %d", msg, i), waitForIt&#125; time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &lt;-waitForIt // 进入等待 &#125; &#125;() return c&#125;func fanIn(input1, input2 chan Message) chan Message &#123; c := make(chan Message) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 5; i++ &#123; msg1 := &lt;-c fmt.Println(msg1.str) msg2 := &lt;-c fmt.Println(msg2.str) // 当 Joe 和 Ann 的信息都收到后，才开放下一次消息接收 msg1.wait &lt;- true msg2.wait &lt;- true &#125;&#125; 5. select 语句# 使用 select 来写扇入函数，减少 goroutine 数量 123456789101112func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; select &#123; case s := &lt;-input1: c &lt;- s case s := &lt;-input2: c &lt;- s &#125; &#125; &#125;() return c&#125; select设置超时 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1500)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("Joe") for &#123; select &#123; case s := &lt;-c: fmt.Println(s) case &lt;-time.After(1 * time.Second): fmt.Println("You're too slow.") return &#125; &#125;&#125;输出：Joe 0Joe 1Joe 2Joe 3Joe 4You're too slow.]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL驱动]]></title>
    <url>%2F2018%2F12%2F31%2F2018-12-31%2F</url>
    <content type="text"><![CDATA[MySQL基础见菜鸟教程; 本文参考了astaxie/build-web-application-with-golang. 启动、以密码登入和创建数据库# windows: 在bin目录下，运行(git-bash以管理员运行，加winpty) mysqld --remove 删除之前的mysql服务 mysqld -install mysql 安装windows服务，服务名称为mysql(任意取) mysqld --initialize-insecure 可无密码登陆root net start mysql 启动服务(关闭的命令是 net stop mysql) ubuntu: service mysql start 启动服务 service mysql stop 关闭服务 service restart stop 重启服务 ps -ef | grep mysqld 查看mysql进程列表 执行如下SQL语句以密码登入 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; 或者编写 test.sql 创建 source test.sql 文件 编写Go文件# test.go 内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( "database/sql" "fmt" _ "github.com/go-sql-driver/mysql")func main() &#123; db, err := sql.Open("mysql", "root:123456@/test") //Linux用户名:MySQL密码@/数据库名test checkErr(err) stm, err := db.Prepare("DROP TABLE IF EXISTS userinfo;") //准备SQL语句，删除数据表 checkErr(err) _, err = stm.Exec() //Excute, 执行语句 checkErr(err) stm, err = db.Prepare(`CREATE TABLE userinfo ( uid INT(10) NOT NULL AUTO_INCREMENT, name VARCHAR(64) NOT NULL DEFAULT '匿名', city VARCHAR(64) NULL DEFAULT '不详', moment DATE NOT NULL DEFAULT '1949-10-10', PRIMARY KEY (uid) ) DEFAULT CHARSET=utf8;`) //创建数据表，设置utf8以支持中文字符 checkErr(err) _, err = stm.Exec() checkErr(err) //增加数据 stm, err = db.Prepare("INSERT userinfo SET name=?, city=?, moment=?") //准备SQL语句 checkErr(err) _, err = stm.Exec("诸葛亮", "山东临沂", "234-10-8") //Excute, 传入参数并执行 checkErr(err) _, err = stm.Exec("关羽", "山西运城", "220-1-1") checkErr(err) _, err = stm.Exec("荀彧", "河南许昌", "212-1-1") checkErr(err) stm, err = db.Prepare("INSERT userinfo SET city=?") checkErr(err) res, err := stm.Exec("河南禹州") id, err := res.LastInsertId() checkErr(err) fmt.Println("最后插入的用户序号为:", id) //查询数据 rows, err := db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; //删除数据 stm, err = db.Prepare("DELETE FROM userinfo WHERE uid=?") checkErr(err) res, err = stm.Exec(2) checkErr(err) fmt.Println("删除了第2行") //更改数据 stm, err = db.Prepare("UPDATE userinfo SET name=? WHERE uid=? OR uid=?") checkErr(err) res, err = stm.Exec("郭嘉", id-1, id) checkErr(err) affect, err := res.RowsAffected() checkErr(err) fmt.Println("总共有", affect, "行的信息发生了更改") //查询数据 rows, err = db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; db.Close()&#125;func checkErr(err error) &#123; if err != nil &#123; panic(err) &#125;&#125; 运行结果： 进入MySQL查看数据表：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构]]></title>
    <url>%2F2018%2F12%2F20%2F2018-12-20%2F</url>
    <content type="text"><![CDATA[3.4 顺序存储结构 3.6 链式存储结构 3.11 单链表结构与顺序存储结构 3.12 静态链表 3.13 循环链表 3.14 双向链表 4.2 栈 4.10 队列 4.12 循环队列 6.4 树的存储结构 6.5.2 特殊二叉树 6.6 二叉树性质 6.8 遍历二叉树 6.8.6 推导遍历结果 6.10 线索二叉树 6.11.1 树转换为二叉树 6.12 赫夫曼树 7.4.1 邻接矩阵(adjacency matrix) 7.4.2 邻接表 7.5.1 深度优先遍历(Depth First Search) 7.5.2 广度优先遍历(Breadth First Search) 8.4.1 二分查找 8.6 二叉查找树(Binary Sort Tree) 8.6.2 二叉查找树插入 8.6.3 二叉查找树删除 8.7 平衡二叉树(AVL树) 9.2.1 排序的稳定性 9.2.2 内排序和外排序 9.3.2 冒泡排序算法(Bubble Sort) 9.3.3 冒泡排序优化 9.4.1 简单选择排序(Simple Selection Sort) 9.5.1 直接插入排序(Straight Insertion Sort) 9.6 希尔排序(Shell Sort) 9.7 堆排序 9.8 归并排序 9.9 快速排序 3.4 顺序存储结构# 数值data(起始位置)；数组长度MaxSize；线性表长度length LOC($a_{i}$)=LOC($a_{1}$)+(i-1)c 3.6 链式存储结构# 单链表，每个节点只包含一个指针域 头指针，头节点，第一个节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( "fmt")type Node struct &#123; data string next *Node&#125;type LinkList struct &#123; length int head *Node rear *Node&#125;func NewLinkList(head *Node) *LinkList &#123; return &amp;LinkList&#123;0, head, head&#125;&#125;func (this *LinkList) Append(data string) &#123; if this.rear == nil &#123; return &#125; node := &amp;Node&#123;data: data&#125; this.rear.next = node this.rear = node this.length++&#125;func (this *LinkList) Reverse() *LinkList &#123; head := this.head if head == nil || head.next == nil &#123; return this &#125; var pre *Node = nil cur := head.next //head不为空时，当前为第1节点 this.rear = head.next //第1节点不为空时，作为最后节点 for cur != nil &#123; cur.next, pre, cur = pre, cur, cur.next //buf := cur.next //cur.next = pre //pre = cur //cur = buf &#125; head.next = pre //指向第最后一个节点 return this&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.Append("4") bl.Reverse() for node := bl.head; node != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125;&#125;&gt; Output:command-line-arguments 4 3 2 1 3.11 单链表结构与顺序存储结构# 内存分配；时间复杂度(查找，插入和删除)；空间复杂度 3.12 静态链表# 3.13 循环链表# 尾指针rear 头节点rear-&gt;next 第一个节点rear-&gt;next-&gt;next 合并： p=rearA-&gt;next q=rearB-&gt;next rearA-&gt;next=rearB-&gt;next-&gt;next rearB-&gt;next=p free(q) 3.14 双向链表# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")type Node struct &#123; data string pre *Node next *Node&#125;type BiLinkList struct &#123; length int head *Node rear *Node&#125;func NewBiLinkList(head *Node) *BiLinkList &#123; return &amp;BiLinkList&#123;0, head, head&#125;&#125;func (this *BiLinkList) Append(data string) &#123; node := &amp;Node&#123;data: data&#125; this.rear.next = node node.pre = this.rear this.rear = node this.length++&#125;func (this *BiLinkList) InsertNext(p *Node, e string) &#123; //省略判断 nd 不为空且属于链表 if p.next == nil &#123; this.Append(e) &#125; else &#123; s := &amp;Node&#123;data: e&#125; s.pre = p s.next = p.next p.next.pre = s p.next = s &#125; this.length++&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewBiLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.InsertNext(head.next.next, "2.5") //for i := 0; i &lt; bl.length; i++ &#123; // fmt.Print(head.next.data, " ") // head = head.next //&#125; for node := bl.head; node.next != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125; fmt.Print(bl.rear.data) //打印末节点&#125;&gt; Output:command-line-arguments 1 2 2.5 3 使用标准库 1234567891011121314151617181920212223package mainimport ( "container/list" "fmt")func main() &#123; bl := list.New() for i := 1; i &lt; 4; i++ &#123; bl.PushBack(i) &#125; head := bl.Front() rear := bl.Back() for p := head; p != rear; p = p.Next() &#123; fmt.Print(p.Value, " ") &#125; fmt.Print(rear.Value)&#125;&gt; Output:command-line-arguments1 2 3 4.2 栈# 123依次进栈，出栈次序不可能有312(12同时在栈中,2一定先出) s-&gt;top 栈顶指针 栈顶指针为-1表示控栈 s-&gt;data[s-&gt;top]栈顶元素 12345678910111213type Stack struct &#123; //用于存放 int 的栈 nums []int&#125;func (this *Stack) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Stack) Pop() int &#123; res := this.nums[len(this.nums)-1] this.nums = this.nums[:len(this.nums)-1] return res&#125; 4.10 队列# 12345678910111213type Queue struct &#123; //Queue 是用于存放 int 的队列 nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125; 4.12 循环队列# 队列满的条件: (rear+1)%QueueSize == front 队列长度:(rear-front+QueueSize)%QueueSize 6.4 树的存储结构# 双亲表示(数组)，孩子兄弟表示(数组)，孩子表示(数组+链表) 6.5.2 特殊二叉树# 斜树，满二叉树，完全二叉树 6.6 二叉树性质# 总结点数：$n=n_{0}+n_{1}+n_{2}$ 分支线总数： $n-1=n_{1}+2n_{2}$ 完全二叉树深度：$[log_{2}n]+1$ 完全二叉树按层序排号：节点$i$的左节点为$2i$ 6.8 遍历二叉树# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func main() &#123; node9 := &amp;BinaryTree&#123;data: "I"&#125; node8 := &amp;BinaryTree&#123;data: "H"&#125; node7 := &amp;BinaryTree&#123;data: "G"&#125; node6 := &amp;BinaryTree&#123;data: "F"&#125; node5 := &amp;BinaryTree&#123;data: "E", right: node9&#125; node4 := &amp;BinaryTree&#123;"D", node7, node8&#125; node3 := &amp;BinaryTree&#123;"C", node5, node6&#125; node2 := &amp;BinaryTree&#123;data: "B", left: node4&#125; root := &amp;BinaryTree&#123;"A", node2, node3&#125; PreOrderRec(root) fmt.Println() MidOrderRec(root) fmt.Println() PostOrderRec(root)&#125;&gt; Output:command-line-argumentsA B D G H C E I F G D H B A E I C F G H D B I E F C A 6.8.6 推导遍历结果# 前序遍历序列+中序遍历序列-&gt;二叉树 后序遍历序列+中序遍历序列-&gt;二叉树 前中后：BAC ABC ACB 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func PreMid2Tree(pre, mid []string) *BinaryTree &#123; //前序+中序推导二叉树 if len(pre) != len(mid) &#123; panic("两个切片的长度不相等") &#125; if len(mid) == 0 &#123; return nil &#125; root := &amp;BinaryTree&#123; //前序第一个元素为root data: pre[0], &#125; if len(mid) == 1 &#123; return root &#125; position := IndexOf(root.data, mid) //找出root在中序的位置 root.left = PreMid2Tree(pre[1:position+1], mid[:position]) //递归 root.right = PreMid2Tree(pre[position+1:], mid[position+1:]) return root&#125;func IndexOf(ele string, seq []string) int &#123; for i, v := range seq &#123; if v == ele &#123; return i &#125; &#125; panic("IndexOf错误，元素不存在")&#125;func main() &#123; bt := PreMid2Tree([]string&#123;"A", "B", "D", "G", "H", "C", "E", "I", "F"&#125;, []string&#123;"G", "D", "H", "B", "A", "E", "I", "C", "F"&#125;) PostOrderRec(bt)&#125;&gt; Output:command-line-argumentsG H D B I E F C A 6.10 线索二叉树# 将节点的空指针改为指向在遍历序列中的前驱或后继的指针。 12345678910111213141516171819202122232425262728293031type ThreadBiTree struct &#123; data string left *ThreadBiTree right *ThreadBiTree lTag *ThreadBiTree //一个bit位，区分是指向孩子还是线索 rTag *ThreadBiTree&#125;var pre *ThreadBiTree //保存前驱func MidThreading(bt *ThreadBiTree) &#123; //中序遍历线索化 if bt == nil &#123; return &#125; MidThreading(bt.left) if bt.left == nil &#123; //若bt有左空指针，则把pre设为bt的前驱，并设置标志位 bt.left = pre bt.lTag = 1 &#125; if bt.right == nil &#123; //若bt有右空指针，则把bt设为pre的后继，并设置标志位 pre.right = bt pre.rTag = 1 &#125; pre = bt MidThreading(bt.right)&#125; 6.11.1 树转换为二叉树# 兄弟连线；只保留第一个孩子的连线 6.12 赫夫曼树# 带权路径长度(WPL)最小的二叉树 WPL(a)= 51+152+403+304+104 WPL(b)= 53+153+402+302+102 构造 排序：A5, E10, B15, D30, C40 7.4.1 邻接矩阵(adjacency matrix)# 无向图： 有向图： 有向网： 无向网的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport ( "fmt")const ( INFINITY int32 = 65536 // 无穷)type Edge struct &#123; //边的顶点和权值 v0 string v1 string weight int32&#125;type Graph struct &#123; //无向网 v []string //顶点数组 e []Edge //边的权值&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjMatrix() [][]int32 &#123; vertexNum := len(this.v) adjM := make([][]int32, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int32, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; if j == i &#123; adjM[i][j] = 0 &#125; else &#123; adjM[i][j] = INFINITY &#125; &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = edge.weight adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = edge.weight //因为是无向图所以是对称矩阵 &#125; return adjM&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D"&#125; e := []Edge&#123; Edge&#123;"A", "B", 5&#125;, Edge&#123;"A", "C", 3&#125;, Edge&#123;"A", "D", 6&#125;, Edge&#123;"B", "C", 7&#125;, Edge&#123;"C", "D", 9&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向网 fmt.Println(graph.AdjMatrix()) // A B C D //A [ 0 5 3 6 ] //B [ 5 0 7 65536 ] //C [ 3 7 0 9 ] //D [ 6 65536 9 0 ]&#125;&gt; Output:command-line-arguments[[0 5 3 6] [5 0 7 65536] [3 7 0 9] [6 65536 9 0]] 7.4.2 邻接表# 无向图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func main() &#123; v := []string&#123;"v0", "v1", "v2", "v3"&#125; e := []Edge&#123; Edge&#123;"v0", "v1"&#125;, Edge&#123;"v0", "v2"&#125;, Edge&#123;"v0", "v3"&#125;, Edge&#123;"v1", "v2"&#125;, Edge&#123;"v2", "v3"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(node.adjvex, " ") &#125; fmt.Println() &#125;&#125;&gt; Output:command-line-argumentsv0 1 2 3 v1 0 2 v2 0 1 3 v3 0 2 有向网： 7.5.1 深度优先遍历(Depth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package mainimport ( "fmt")var flag []bool //全局变量type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;func (this *Graph) AdjMatrix() [][]int &#123; vertexNum := len(this.v) adjM := make([][]int, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; adjM[i][j] = 0 &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = 1 adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = 1 &#125; return adjM&#125;func IndexOfVertex(vs []string, v string) int &#123; for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func DFSTraverse(adjM [][]int) &#123; //输入无向图的邻接矩阵 vertexNum := len(adjM) flag = make([]bool, vertexNum) //初始化flag，注意这里不能用 := for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; for i := 0; i &lt; vertexNum; i++ &#123; //对未访问的节点执行深度搜索 if !flag[i] &#123; DFS(vertexNum, i, adjM) &#125; &#125;&#125;func DFS(vertexNum int, i int, adjM [][]int) &#123; flag[i] = true fmt.Print(i, " ") //打印被访问的节点序号 for j := 0; j &lt; vertexNum; j++ &#123; //对未被访问的邻节点递归 if adjM[i][j] == 1 &amp;&amp; !flag[j] &#123; DFS(vertexNum, j, adjM) &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjM := graph.AdjMatrix() for i := 0; i &lt; len(adjM); i++ &#123; fmt.Println(adjM[i]) &#125; fmt.Println("-------------------") DFSTraverse(adjM)&#125;&gt; Output:command-line-arguments[0 1 0 0 0 1 0 0 0][1 0 1 0 0 0 1 0 1][0 1 0 1 0 0 0 0 1][0 0 1 0 1 0 1 0 0][0 0 0 1 0 1 0 1 0][1 0 0 0 1 0 1 0 0][0 1 0 1 0 1 0 1 0][0 0 0 0 1 0 1 0 0][0 1 1 0 0 0 0 0 0]-------------------0 1 2 3 4 5 6 7 8 7.5.2 广度优先遍历(Breadth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;type Queue struct &#123; nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func BFSTraverse(adjL []LinkList) &#123; //输入邻接表 vertexNum := len(adjL) flag := make([]bool, vertexNum) //标记被访问的节点 for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; Q := new(Queue) //队列 for i := 0; i &lt; vertexNum; i++ &#123; if !flag[i] &#123; //如果顶点未被访问 flag[i] = true Q.Push(i) for len(Q.nums) &gt; 0 &#123; //队列不为空 j := Q.Pop() fmt.Print(adjL[j].head.data, " ") //打印节点 for node := adjL[j].head.firstedge; node != nil; node = node.next &#123; if flag[node.adjvex] == false &#123; flag[node.adjvex] = true Q.Push(node.adjvex) &#125; &#125; &#125; &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(adjL[node.adjvex].head.data, " ") &#125; fmt.Println() &#125; fmt.Println("-----------------") BFSTraverse(adjL)&#125;&gt; Output:command-line-argumentsA B F B A C G I C B D I D C G E E F D H F A G E G B F D H H G E I B C -----------------A B F C G I E D H 8.4.1 二分查找# 123456789101112131415161718192021222324252627282930313233package mainimport ( "fmt")func BiSearch(a []int, n, key int) int &#123; var low, high, mid int low = 1 high = n for low &lt;= high &#123; mid = (low + high) / 2 //mid = low + (high-low)(key-1)/(99-1) 插值 if key == a[mid] &#123; return mid &#125; else if key &lt; a[mid] &#123; high = mid - 1 &#125; else &#123; low = mid + 1 &#125; &#125; return 0&#125;func main() &#123; a := []int&#123;0, 1, 16, 24, 35, 47, 59, 62, 73, 88, 99&#125; fmt.Println(BiSearch(a, 10, 62))&#125;&gt; Output:command-line-arguments7 8.6 二叉查找树(Binary Sort Tree)# 左小右大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func SearchBST(root *BinaryTree, key int) bool &#123; if root == nil &#123; return false &#125; switch &#123; case key &lt; root.data: return SearchBST(root.left, key) case key &gt; root.data: return SearchBST(root.right, key) default: return true &#125;&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(SearchBST(root, 73), " ") fmt.Print(SearchBST(root, 99), " ") fmt.Print(SearchBST(root, 37), " ") fmt.Print(SearchBST(root, 48), " ") fmt.Print(SearchBST(root, 100))&#125;&gt; Output:command-line-argumentstrue true true false false 8.6.2 二叉查找树插入# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(root.right.right.left.data, root.right.right.left.right, " ") _, root = InsertBST(root, 95) fmt.Print(root.right.right.left.right.data)&#125;&gt; Output:command-line-arguments93 &lt;nil&gt; 95 8.6.3 二叉查找树删除# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;//删除data为key的节点，并返回该二叉树的根节点。func DeleteBST(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return nil &#125; switch &#123; case key &gt; root.data: //在右子树中 root.right = DeleteBST(root.right, key) case key &lt; root.data: //在左子树中 root.left = DeleteBST(root.left, key) default: //key == root.data if root.left == nil &amp;&amp; root.right == nil &#123; //该节点为叶节点 return nil &#125; else if root.left == nil &amp;&amp; root.right != nil &#123; //该节点仅有右子树 return root.right &#125; else if root.left != nil &amp;&amp; root.right == nil &#123; //该节点仅有左子树 return root.left &#125; else &#123; //该节点有左、右子树 success := FindMin(root.right) //找到key的后继节点,即48 root.right = DeleteBST(root.right, success) root.data = success &#125; &#125; return root&#125;//找到BST中data最小的节点func FindMin(root *BinaryTree) int &#123; if root.left == nil &#123; //最小值在根节点 return root.data &#125; return FindMin(root.left) //最小值在左子树&#125;func main() &#123; node16 := &amp;BinaryTree&#123;data: 50&#125; node15 := &amp;BinaryTree&#123;data: 48&#125; node14 := &amp;BinaryTree&#123;data: 36&#125; node13 := &amp;BinaryTree&#123;data: 56&#125; node12 := &amp;BinaryTree&#123;49, node15, node16&#125; node11 := &amp;BinaryTree&#123;data: 37, left: node14&#125; node10 := &amp;BinaryTree&#123;data: 29&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;51, node12, node13&#125; node7 := &amp;BinaryTree&#123;35, node10, node11&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; root = DeleteBST(root, 47) NewNode := root.left.left fmt.Print(NewNode.data, " ") //打印代替删除位置的新节点 fmt.Print(NewNode.left.data, NewNode.right.data)&#125;&gt; Output:command-line-arguments48 35 51 8.7 平衡二叉树(AVL树)# 平衡因子(BF)=左子树的深度-右子树的深度 旋转： 123456789//右旋func RRotate(k2 *BinaryTree) *BinaryTree &#123; k1 := k2.left y := k1.right k1.right = k2 k2.left = y return k1&#125; 双旋转： 12345//左右旋转func LRRotate(k3 *BinaryTree) *BinaryTree &#123; k3.left = LRotate(k3.left) return RRotate(k3)&#125; 将任意二叉树一次性调整AVL 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185package mainimport ( "fmt")type BinaryTree struct &#123; data int bf int //Balance Factor left *BinaryTree right *BinaryTree&#125;//右旋func R_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.left b := a.right a.right = root root.left = b return a&#125;//左旋func L_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.right b := a.left a.left = root root.right = b return a&#125;//左右旋转func LR_Rotate(root *BinaryTree) *BinaryTree &#123; root.left = L_Rotate(root.left) return R_Rotate(root)&#125;//右左旋转func RL_Rotate(root *BinaryTree) *BinaryTree &#123; root.right = R_Rotate(root.right) return L_Rotate(root)&#125;//将任意二叉树转化成AVLfunc Balance(root *BinaryTree) *BinaryTree &#123; a := &amp;BinaryTree&#123;left: root&#125; //给二叉树生成一个父母节点 _, isAVL := Bal(root) //调整二叉树的子树并判断二叉树是否平衡 for !isAVL &#123; Bal(a) //处理a的左子树，即二叉树 _, isAVL = Bal(a.left) //判断二叉树是否平衡 &#125; return a.left //返回二叉树&#125;//调整子树func Bal(root *BinaryTree) (int, bool) &#123; if root == nil &#123; return 0, true &#125; leftHeight, leftIsBalanced := Bal(root.left) rightHeight, rightIsBalanced := Bal(root.right) if !leftIsBalanced &#123; root.left = Rotate(root.left) //调整左子树 leftHeight = UpdateBF(root.left) //刷新左子树的BF和高度 &#125; if !rightIsBalanced &#123; root.right = Rotate(root.right) rightHeight = UpdateBF(root.right) &#125; root.bf = leftHeight - rightHeight //计算本身的BF if Abs(root.bf) &lt;= 1 &#123; return Max(leftHeight, rightHeight) + 1, true &#125; return Max(leftHeight, rightHeight) + 1, false&#125;//对不平衡树进行旋转调整func Rotate(root *BinaryTree) *BinaryTree &#123; if root.bf &gt; 0 &#123; //左边太重，需要右旋 if root.left.bf &lt; 0 &#123; return LR_Rotate(root) &#125; return R_Rotate(root) &#125; if root.right.bf &gt; 0 &#123; return RL_Rotate(root) &#125; return L_Rotate(root)&#125;func UpdateBF(root *BinaryTree) int &#123; if root == nil &#123; return 0 &#125; leftHeight := UpdateBF(root.left) rightHeight := UpdateBF(root.right) root.bf = leftHeight - rightHeight return Max(leftHeight, rightHeight) + 1&#125;func Max(a, b int) int &#123; if a &gt; b &#123; return a &#125; return b&#125;func Abs(a int) int &#123; if a &gt; 0 &#123; return a &#125; return -a&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func PrintBF(root *BinaryTree) &#123; if root == nil &#123; return &#125; PrintBF(root.left) fmt.Print(root.bf, " ") PrintBF(root.right)&#125;func main() &#123; root := &amp;BinaryTree&#123;data: 1&#125; InsertBST(root, 7) InsertBST(root, 2) InsertBST(root, 4) InsertBST(root, 8) InsertBST(root, 3) InsertBST(root, 10) InsertBST(root, 5) InsertBST(root, 9) InsertBST(root, 6) UpdateBF(root) PrintBF(root) //二叉树的BF fmt.Println() PrintBF(Balance(root)) //平衡调整后的二叉树的BF&#125;&gt; Output:command-line-arguments-5 -3 0 -1 -1 0 1 -2 0 1 0 0 0 -1 -1 0 0 0 0 0 9.2.1 排序的稳定性# 9.2.2 内排序和外排序# 内排序是在排序的整个过程中，待排序的所有记录全部在内存中。外排序的整个过程则需要在内外存之间交换数据。 9.3.2 冒泡排序算法(Bubble Sort)# 冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改 变，所以冒泡排序是一种稳定排序算法。 12345678910111213141516171819202122232425262728package mainimport ( "fmt")package mainimport ( "fmt")func BubbleSort(a []int) &#123; length := len(a) for i := 1; i &lt; length-1; i++ &#123; //需要交换(length-2)次，从后往前排 for j := 1; j &lt; length-i; j++ &#123; //当i=1时，j可以取到(length-2) if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort(a) fmt.Println(a)&#125; 递归实现. for 循环找出最大值排到末尾，去掉末尾把对新的序列递归 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot;)func RecurBubble(a []int) &#123; length := len(a) if length &lt; 3 &#123; //递归跳出条件 return &#125; for j := 1; j &lt;= length-2; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; a = a[0 : length-1] //不包括第 length-1 个元素 RecurBubble(a)&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; RecurBubble(a) fmt.Println(a)&#125; 9.3.3 冒泡排序优化# 123456789101112131415161718192021222324252627package mainimport ( "fmt")func BubbleSort2(a []int) &#123; flag := true // 有数据交换 length := len(a) for i := 1; i &lt; length-1 &amp;&amp; flag; i++ &#123; flag = false for j := 1; j &lt; length-i; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] flag = true &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort2(a) fmt.Println(a)&#125; 9.4.1 简单选择排序(Simple Selection Sort)# 复杂度与冒泡排序同为$O(n^{2})$,但性能更优(数据交换次数更少)。选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; var min int length := len(a) for i := 1; i &lt; length-1; i++ &#123; //插入次数(length-2)，从前往后排；把后面序列中较小的数插 min = i // 循环找出序列中的最小数的下标 for j := i + 1; j &lt; length; j++ &#123; //j取到i后的所有数 if a[j] &lt; a[min] &#123; //之后有更小的数 min = j &#125; &#125; if i != min &#123; //下标改变，交换，防止数据丢失 a[i], a[min] = a[min], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 反过来排 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot;)func SelectionSort(a []int) &#123; var max int length := len(a) for i := length - 1; i &gt; 0; i-- &#123; 从大到小排 max = i for j := 1; j &lt; i; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != i &#123; a[i], a[max] = a[max], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 递归 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; length := len(a) if length &lt; 3 &#123; return &#125; max := length - 1 for j := 1; j &lt; length-1; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != length-1 &#123; a[length-1], a[max] = a[max], a[length-1] &#125; SelectionSort(a[:length-1])&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 9.5.1 直接插入排序(Straight Insertion Sort)# 插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开 始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳 定的。 复杂度同为为$O(n^{2})$，性能：插入排序&gt;选择排序&gt;冒泡排序 123456789101112131415161718192021222324252627package mainimport ( "fmt")func InsertionSort(a []int) &#123; length := len(a) var j int for i := 2; i &lt; length; i++ &#123; //第二个数到最后一个数 if a[i] &lt; a[i-1] &#123; //第i个数比前面的数小，需要插入 a[0] = a[i] //哨兵 for j = i - 1; a[j] &gt; a[0]; j-- &#123; //j取 i-1 到 1 a[j+1] = a[j] //将大于第i个数的数后移一位，留出空位 &#125; a[j+1] = a[0] //将第i个数放入空位 &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; InsertionSort(a) fmt.Println(a)&#125; 9.6 希尔排序(Shell Sort)# 希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 12345678910111213141516171819202122232425262728293031package mainimport ( "fmt")func ShellSort(a []int) &#123; var i, j int length := len(a) - 1 //去掉第0位 inc := length //增量 for inc &gt; 1 &#123; inc = inc/3 + 1 for i = 1 + inc; i &lt;= length; i++ &#123; //第(1+inc)个数到最后一个数 if a[i] &lt; a[i-inc] &#123; a[0] = a[i] for j = i - inc; j &gt; 0 &amp;&amp; a[j] &gt; a[0]; j -= inc &#123; a[j+inc] = a[j] &#125; a[j+inc] = a[0] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; ShellSort(a) fmt.Println(a)&#125; 9.7 堆排序# 时间复杂度$O(nlogn)$ 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func HeapSort(a []int) &#123; length := len(a) - 1 //循环后a[1]为最大值 for i := length / 2; i &gt; 0; i-- &#123; //(length/2)是最后一个节点的父节点到根节点 HeapAdjust(a, i, length) &#125; for i := length; i &gt; 1; i-- &#123; //从最后节点到第二个节点 a[1], a[i] = a[i], a[1] //排序第i位 HeapAdjust(a, 1, i-1) //将1到i-1中的最大数放到a[1] &#125;&#125;func HeapAdjust(a []int, s, m int) &#123; var temp, j int temp = a[s] for j = 2 * s; j &lt;= m; j *= 2 &#123; //以s为父节点开始 if j &lt; m &amp;&amp; a[j] &lt; a[j+1] &#123; //取出较大的孩子节点 j = j + 1 &#125; if temp &gt;= a[j] &#123; //父节点已经最大 break &#125; a[s] = a[j] //将最大的值替换给父节点 s = j //将当前节点作为父节点，进行下一轮操作 &#125; a[s] = temp&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; HeapAdjust(a, 1, 9) fmt.Println(a)&#125; 9.8 归并排序# 归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有 序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结 果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 递归方法 Merge()归并排序示意图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")// 将a排序到bfunc MergeSort(a []int) []int &#123; length := len(a) b := make([]int, length) MSort(a, b, 1, length-1) return b&#125;func MSort(a, b []int, s, t int) &#123; if s == t &#123; b[s] = a[s] //将a复制到到b &#125; else &#123; m := (s + t) / 2 MSort(a, b, s, m) MSort(a, b, m+1, t) Merge(b, s, m, t) //将b归并排序 &#125;&#125;func Merge(SR []int, i, m, n int) &#123; TR := make([]int, len(SR)) //归并的序列暂存到TR s := i //保存起始位置 j := m + 1 k := i //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p] &#123; SR[p] = TR[p] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16&#125; fmt.Println(MergeSort(a))&#125; 非递归方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt")func MergeSort2(a []int) &#123; length := len(a) - 1 for k := 1; k &lt; length; &#123; MergePass(a, k, length) k = k * 2 &#125;&#125;func MergePass(a []int, s, n int) &#123; i := 1 for i &lt;= n-2*s+1 &#123; Merge2(a, i, i+s-1, i+2*s-1) //i+2*s-1&lt;=n i = i + 2*s &#125; if i &lt; n-s+1 &#123; //n&gt;i+s-1,归并最后两个子块 Merge2(a, i, i+s-1, n) &#125;&#125;func Merge2(SR []int, i, m, n int) &#123; TR := make([]int, n-i+1) //与Merge相比栈空间更小 s := i //保存起始位置 j := m + 1 k := 0 //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p-s] &#123; SR[p] = TR[p-s] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16, 3, 41, 7, 55, 21&#125; MergeSort2(a) fmt.Println(a)&#125; 9.9 快速排序# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport ( "fmt")func QuickSort(a []int) &#123; Qsort(a, 1, len(a)-1)&#125;func Qsort(a []int, low, high int) &#123; if low &lt; high &#123; pivot := Partition(a, low, high) Qsort(a, low, pivot-1) Qsort(a, pivot+1, high) &#125;&#125;func Partition(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low], a[high] = a[high], a[low] //将a[hign]放到pivoValue左边 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[low], a[high] = a[high], a[low] //将a[low]放到pivoValue右边 &#125; return low&#125;func Partition2(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low] = a[high] //将a[hign]放到较低的位置 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[high] = a[low] //将a[low]放到较高的位置 &#125; a[low] = pivotValue return low&#125;func main() &#123; a := []int&#123;0, 50, 10, 90, 30, 70, 40, 80, 60, 20&#125; QuickSort(a) fmt.Println(a)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go内存模型]]></title>
    <url>%2F2018%2F11%2F14%2F2018-11-14%2F</url>
    <content type="text"><![CDATA[1. 什么是 Go内存模型？ 2. Happens Before 3. Synchronization 3.1 Initialization 3.2 Goroutine creation 3.3 Goroutine destruction 3.4 Channel communication 3.5 Locks 3.6 Once 4. Incorrect synchronization 本文主要翻译自官方文档 The Go Memory Model 1. 什么是 Go内存模型？# 我们知道不同的 goroutine 可以对同一个变量进行读写操作。Go内存模型指定了在什么样的条件下可以保证一个 goroutine 写入到变量的值可以被另外一个 goroutine 正确的读取。 2. Happens Before# 在单个 goroutine 中，读、写操作按照程序设计的顺序进行。需要注意的是，在不改变 goroutine 程序行为的前提下，这些读、写顺序在编译的过程中可能会被重排。因此导致对相同变量的读、写操作在不同的 goroutine 看来执行顺序可能不同。例如，如果在某个 goroutine 中执行 a = 1; b = 2;，另一个 goroutine 可能观察到变量 b 比 a 先被赋值。 Happens Before 是针对Go语言编程中内存操作的一种局部排序。 如果 $e_{1}$ happens before $e_{2}$，那么也可以说 $e_{2}$ happens after $e_{1}$。进一步，如果 $e_{1}$ 既不 happens before $e_{2}$，也不 happens after $e_{2}$，那么我们称 $e_{1}$ 和 $e_{2}$ happen concurrently (并发)。 在单个 goroutine 中，Happens Before顺序就是程序设计的顺序 $v$：某个变量 $w$: 对$v$的写 $w'$: 对$v$的写，不同于$w$ $r$: 对$v$的读 $w$可以被$r$获取的条件： $r$ 不 happen before $w$. (包括 happen after 和 happen concurrently) 不存在另一个 $w'$ happens after $w$ but before $r$. $w$保证能被$r$获取的条件(该条件不允许$w'$与$w$或者$r$并发，因此比上面的条件更强): $w$ happens before $r$. 任何其它的 $w'$ 要么 happens before $w$，要么 happens after $r$. 当有多个 goroutine 可以访问$v$时，必须利用同步事件(synchronization events)来建立 happens before 以保证 $r$能够获取想要的$w$。 在初始化过程中，赋给$v$以其类型的零值的操作可以看作是内存模型中的一种$w$ 3. Synchronization# 3.1 Initialization# 程序的初始化在一个 goroutine 中进行，并且在该 goroutine 中还可以创建其它的 goroutine 如果包 $p$导入了包$q$，那么包$q$在被导入之前就完成了初始化，函数main.main在所有的init函数完成后开始执行，见astaxie的main函数和init函数一文 3.2 Goroutine creation# 启动一个新的 goroutine 的 Go声明发生在该 goroutine开始执行之前 12345678910111213141516package mainvar a stringfunc f() &#123; print(a)&#125;func hello() &#123; a = "hello, world" go f()&#125;func main() &#123; hello()&#125; 调用hello()将会在未来某个时间点( 可能在hello()返回之后 )打印hello, world 3.3 Goroutine destruction# 无法保证 goroutine 在其创建程序中的某个位置退出 123456var a stringfunc hello() &#123; go func() &#123; a = "hello" &#125;() print(a)&#125; 对 a 的写(赋值)没有进行任何同步操作，无法被其它 goroutine 获取，在激进的编译器中甚至可能会删除整个 go 声明。 3.4 Channel communication# 通道通信(channel communication)是同步两个 goroutine 的主要方法。 send 发生在完成相应的 receive 之前 程序： 12345678910111213141516var c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" c &lt;- 0 // send&#125;func main() &#123; go f() &lt;-c // receive print(a)&#125;&gt; Output:command-line-argumentshello, world 会保证打印 hello, world，因为： 对 a 的写 happens before 通道 c 的 send 通道 c 的 send happens before 通道 c 的 receive 通道 c 的 receive happens before print(a)，因此 , 对 a 的写 happens before print(a), 即保证 main() 获取了 goroutine 对 a的写 channel 的关闭发生在完成 receive(此时得到的是通道类型的零值)之前 123456789101112131415161718package mainvar c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" close(c) // 关闭&#125;func main() &#123; go f() print(a, "\n", &lt;-c) // receive&#125;&gt;Output:command-line-argumentshello, world0 无缓存通道的 receive 发生在完成 send 之前 调换 c &lt;- 0 // send 和 &lt;-c // receive的位置，得到程序 123456789101112131415var c = make(chan int)var a stringfunc f() &#123; a = "hello, world" &lt;-c //receive&#125;func main() &#123; go f() c &lt;- 0 // send print(a)&#125;&gt; Output:command-line-argumentshello, world 仍然保证打印 hello, world 但如果channel具有缓存，例如当c = make(chan int, 1)，那么程序无法保证打印 hello, world 当通道的容量为$c$时，第 $k$ 次 receive 发生在完成第 $k+c$ 次 send 之前 下面的程序给 work 的每个条目(函数类型)启动一个 goroutine，由于通道limit的容量为3，因此最多允许3个 goroutine 调用调用了函数w() 1234567891011var limit = make(chan int, 3)func main() &#123; for _, w := range work &#123; go func(w func()) &#123; limit &lt;- 1 w() &lt;-limit &#125;(w) &#125;&#125; 3.5 Locks# sync 包实现了两种 lock 数据类型, sync.Mutex和 sync.RWMutex. 对任意的 sync.Mutex 或者 sync.RWMutex变量 l且$n&lt;m$，第$n$次调用 l.Unlock() 发生在 第 $m$次调用 l.Lock()返回之前 程序 1234567891011121314151617181920212223package mainimport ( "sync")var l sync.Mutexvar a stringfunc f() &#123; a = "hello, world" l.Unlock() //第一次 l.Unlock()&#125;func main() &#123; l.Lock() go f() l.Lock() //第二次 l.Lock() print(a)&#125;&gt; Output:command-line-argumentshello, world 保证打印hello, world，因为， 第一次 l.Unlock() happens before 第二次 l.Lock() 返回 第二次 l.Lock() 返回 happens before print(a) 对于任意的l.RLock，存在$k$满足： 第 $k$ 次调用 l.Unlock happens before l.RLock； 与l.RLock对应的l.RUnlock happens before 第 $k+1$次调用 l.Lock 3.6 Once# 对某个函数f()，可以有多个线程通过once.Do(f)来对其调用，但仅有线程能够调用执行函数f()，其它的调用会被阻塞知道f()返回。 程序 123456789101112131415161718192021222324252627282930313233package mainimport ( "sync" "time")var a stringvar once sync.Oncefunc setup() &#123; a = "hello, world"&#125;func SETUP() &#123; a = "HELLO, WORLD"&#125;func doprint() &#123; once.Do(setup) //注意不要括号 once.Do(SETUP) print(a, "\n")&#125;func main() &#123; go doprint() go doprint() time.Sleep(time.Second)&#125;&gt; Output:command-line-argumentshello, worldhello, world 会打印两次 hello, world，但是仅在第一次调用 doprint 时执行了 setup 4. Incorrect synchronization# 程序 12345678910111213141516171819202122232425package mainvar a, b intfunc f() &#123; a = 1 b = 2&#125;func g() &#123; print(b, "\n") print(a)&#125;func main() &#123; go f() g()&#125;&gt; Output: //大多数输出结果00&gt; Output: //少数输出结果01 也可能先打印2，然后打印0 程序 1234567891011121314151617181920212223242526272829303132package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world \n" done = true&#125;func doprint() &#123; if !done &#123; setup() &#125; print(a)&#125;func twoprint() &#123; go doprint() go doprint()&#125;func main() &#123; twoprint()&#125;//有3种输出的可能&gt; Output:hello, world hello, world &gt; Output:hello, world &gt; Output: 下面的程序，由于不能保证main()先获取对done的写，因此print()可能打印空字符串。甚至main()完全没有获取对done的写，此时main()进入死循环 12345678910111213141516171819202122232425package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; print(a)&#125;&gt; Output:hello, world&gt; Elapsed: 3.703s //等待了较长的时间&gt; Result: Success&gt; Output:hello, world&gt; Elapsed: 0.704s &gt; Result: Success 类似的程序如下 1234567891011121314151617181920package maintype T struct &#123; msg string&#125;var g *Tfunc setup() &#123; t := new(T) t.msg = "hello, world" g = t&#125;func main() &#123; go setup() for g == nil &#123; &#125; print(g.msg)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建IPFS 私有网络]]></title>
    <url>%2F2018%2F11%2F05%2F2018-11-5%2F</url>
    <content type="text"><![CDATA[在servers上安装 Go 环境 生成 ifps 节点 创建共享密钥 添加启动节点 启动私有网络 本例为建立包含三个节点的IPFS私有网络，节点分别为： server a: root@45.32.28.71 server b: root@207.148.109.110 本地 mac 在servers上安装 Go 环境# 1234567891011cd ~ $wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz$tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz //解压到得到的 go 目录，放到 /usr/local 目录下$vim .bashrcexport GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN$source .bashrc$go version go version go1.11.2 linux/amd64 //安装成功 mac 上的安装类似。 生成 ifps 节点# 在三台机器上执行 12345678910111213141516171819202122232425262728$go get -u -d github.com/ipfs/go-ipfs $cd $GOPATH/src/github.com/ipfs/go-ipfs$make installCommand &apos;make&apos; not found, but can be installed with:sudo apt install makesudo apt install make-guile$apt update \\ 需要安装 make ， 先检查安装包...$apt upgrade \\ 更新安装包...$apt install make \\ 安装 make...$make install/usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exec: &quot;gcc&quot;: executable file not found in $PATHcmd/ipfs/Rules.mk:37: recipe for target &apos;cmd/ipfs-install&apos; failedmake: *** [cmd/ipfs-install] Error 2$apt install gcc...$gcc -v...gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)$make install...$ipfs init... 记下每个节点的ID，比如本例 server a 的ID: QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 server b 的ID: QmRyxoe9JpkDZuMK4G7PkXUy7nGv8VdM98d6Vr2wxFSa3V mac 的ID: QmWKKVUy9XqWEGhrikJW8ugHuFzKJJGP5DCGFyvzUJFjzL 创建共享密钥# 先在任意一台机器上创建密钥，然后拷贝到剩余节点。本例在mac上创建 12$go get -u github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen$ipfs-swarm-key-gen &gt; ~/.ipfs/swarm.key 手动拷贝 1$vim ~/.ipfs/swarm.key \\ 打开swarm.key, 拷贝内容 在servers上新建swarm.key 1$vim ~/.ipfs/swarm.key \\ 将拷贝的内容粘贴 使用 scp 命令 12$scp ~/.ipfs/swarm.key root@45.32.28.71:~/.ipfs/$scp ~/.ipfs/swarm.key root@207.148.109.110:~/.ipfs/ 添加启动节点# pfs init后的默认启动节点是连接ipfs公网的节点。建立私有网络需要在每一个节点上删掉默认启动节点 1$ipfs bootstrap rm --all 将网络中任意其他节点作为启动节点。例如将 server a 作为mac的启动节点 1$ipfs bootstrap add/ip4/45.32.28.71/tcp/4001/ipfs/QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 启动私有网络# 给三个节点添加了启动节点后，启动所有节点，便建立起了含有三个节点的IPFS私有网络。分别执行 1$ipfs daemon 可以使用 bootstrap list```查看节点所包含的启动节点，使用```ipfs swarm peers```查看节点连接了哪些其他节点。使用```ipfs add file```上传文件到节点，比如给mac节点上传pdf文件，并得到该文件的ID12```$ipfs add ~/files/GO语言编程.pdf 该文件的ID：QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi。现在与mac建立了连接的server就可以下载该文件了，在server上执行 1$ipfs get QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi \\在当前目录会多出一个新的文件便是get到的文件]]></content>
      <tags>
        <tag>IPFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A Study for the Reed-Solomon Code]]></title>
    <url>%2F2018%2F10%2F18%2F2018-10-18%2F</url>
    <content type="text"><![CDATA[Introduction Galois Field Galois Field Arithmetic Addition and Subtraction Multiplication and Division RS Code Coding Matrix Method Generator Polynomial Method RS Code in Distributed Storage Systems 5.1 Rotated Reed-Solomon code Local Reconstruction Code (LRC) References Introduction# Reed-Solomon (RS) code is an error-correcting code first proposed by Reed and Solomon in 1960, which is the most frequently applied digital error correction code around the word. The applications include data storage(hard drives, CD/DVD/Blue Ray), data transmission and common commercial activities(bar codes, QR codes) . RS code has the advantage of high capability of correcting random or burst errors since it encodes groups of bits instead of one bit at a time. Redundant datas are generated so that the original data can be reconstructed with part of the stored or received data loss. People often back up important files which can be regarded as kind of data loss protection with redundant data. However, backup is just a copy of the original datas while the redundant data generated in the RS code is a fusion of the all the original data parts, which is more efficient for storage and error correction. In this article, I have run through the procedure of the RS code and hope it is usefull for you to understand what is going on with this erasure code. Its application in the distributed strorage system are briefly introduced at the end. Part of implementations in pure Go are also provided whose source files can be found on the Githup website . Galois Field# The finite field is also called Galois field which has finite elements and the property that arithmetic operations on field elements always have a result in the field. In the sequel, we illustrate two kind of representations of the finite elements and its arithmetic operations. Proposition 1. For any prime $ p $ and any natual number$ r $ there exists a finite field with $ p^{r} $ elements and vice versa. With the proposition 1, the Galois Field is denoted as $ GF(p^{r}) $. In fact, the nature of RS encoding is mapping $ k $ elments of $ GF(2^{r}) $ into another $ n $ elements of $ GF(2^{r}) $ and $k+2\leq n\leq 2^{r} $. This Galois fields can be represented with the help of $ \mathbf{Z}{2}[x] $, the set of polynomials with coefficients in the field of two elements $ \mathbf{Z}{2} $, namely the polynomial representation as $$0,1,x,x+1,x{2},..,x{r-1}+x^{r-2}+...+1 \tag{1}$$ This representation can also be seen as a $r$-bit digit or binary vector. Proposition 2. $ GF(q) $ has cyclic the multiplicative group $ {\alpha, \alpha{2},...,\alpha{q-1}=1}$, where $ \alpha $ is the primitive element. Thus, $ GF(2^{r}) $ has the exponential representation as $$0, 1(=\alpha^{255}), \alpha, \alpha^{2},..., \alpha{2{r}-2} \tag{2}$$ which is a better choice for the '$ \times $' and '$ / $' operation. Even a binary matrix can be used to represente the elements. For example, we can establish a bijection between the vector representation and matrix representation over $ GF(2^{4}) $ as follows where the first column is the vector representation and the columns satisfy $column(i)=2\times column(i-1)$. This matrix representation transforms arithmetic over $ GF(2^{4}) $ into arithmetic over $ GF(2) $ which only has XOR, AND operations. Galois Field Arithmetic# In this section, we discuss arithmetic in $ GF(2^{8}) $, whose element corresponds a byte data. Addition and Subtraction# Addition and subtraction are operated under the polynomial representation (also a byte in $ GF(2^{8}) $) and both are equivalent to XOR operation 1234567func galAdd(a, b byte) byte &#123; return a ^ b&#125;func galSub(a, b byte) byte &#123; return a ^ b&#125; Multiplication and Division# The multiplication is operated with the exponential representation $(2)$, before that we should establish a bijection (injection and surjection) between the two representations. Suppose $$\alpha^{i} -&gt; 2^{i}$$ where $0\leq i \leq 2^{8}-2=254$. According to proposition 2, $\forall j\geq 255,\alpha{j}=\alpha{j-255}$. Proposition 3.$ GF(2^{8}) $ has the irreducible polynomial $ f(x)=x{8}+x{4}+x{3}+x{2}+1 $ which has no factors of smaller polynomials. The irreducible polynomial is necessary to establish the bijection since some $2^{i}$ term are no longer in $GF(2^{8})$. Let $ f(\alpha) =0$, we have $$\alpha{8}=\alpha{4}+\alpha{3}+\alpha{2}+1=2{4}+2{3}+2^{2}+1=00011101$$ or 0x1d . For convenience, we record the bijection with a table, namely called exponent table, whose indexs is the exponents of elements in exponential representation and value is elements in byte representation. 1var expTable = [255]byte&#123;0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, ..., 0x8e&#125; Use logTable[expTable[$i$]]=$i$, the logarithmic table is generated, 12345var logTable = []byte&#123; 0, 0, 1, 25, 2, 50, 26, 198, ... 116, 214, 244, 234, 168, 80, 88, 175,&#125; With these tables, the $\times$ and $/$ functions in $GF(2^8)$ are easily defined, 12345678910111213141516171819202122232425262728293031func galMultiply(a, b byte) byte &#123; if a == 0 || b == 0 &#123; return 0 &#125; logA := int(logTable[a]) logB := int(logTable[b]) sum := logA+logB if sum&gt;254 &#123; sum -= 255 &#125; return expTable[sum]&#125;func galDivide(a, b byte) byte &#123; if a == 0 &#123; return 0 &#125; if b == 0 &#123; panic("Argument 'divisor' is 0") &#125; logA := int(logTable[a]) logB := int(logTable[b]) logResult := logA - logB if logResult &lt; 0 &#123; logResult += 255 &#125; return expTable[logResult]&#125; Based on the result above, the power and inverse functions can be further obtained. In fact, the method to establish the bijection is not unique. The original paper of Reed and Solomon in 1960 provides another method with finite difference equation which has better computability. RS Code# Coding Matrix Method# 1. Orignal approach: For arbitrary $ k $ 8-bit symbols,$ m_{0}$, $m_{1}$, $...$, $m_{k-1} $, we have the message polynomial $$m(x)=m_{0}+m_{1}x+...+m_{k-1}x^{k-1},$$ with this $ m(x) $, $ 2^{8} $ codewords, i.e. $ m(0)$,$m(1)$,$...$, $m(\alpha^{r-2}) $ are obtained and the the encoded messages, which will be transmitted or stored, are $ n $ of the codewords (professionally called stripe). Using linear algebra, the stripe are denoted collectively as follows $$ \begin{bmatrix} m(\alpha_{1})\ m(\alpha_{2})\ ...\ m(\alpha_{n}) \end{bmatrix} = \begin{bmatrix} 1 &amp; \alpha_{1} &amp; ... &amp; \alpha_{1}^{k-1} \ 1 &amp; \alpha_{2} &amp; ...&amp;\alpha_{2}^{k-1} \ ... &amp; ... &amp; ...&amp;... \ 1 &amp; \alpha_{n} &amp; ...&amp;\alpha_{n}^{k-1} \end{bmatrix} \begin{bmatrix} m_{0}\ m_{1}\ ...\ m_{k-1} \end{bmatrix}\tag{3} $$ Note that we only discuss one byte a shard (the messages are splited into multiple shards for encoding) here, in practice one input shard contains thousands of bytes, in this case the output shard contains same size of byte as input shard and the vectors in $(3)$ becomes matrice. Coding procedure : 1.Split the whole message into same size data shards; 2. Build the Vandermonde matrix (coding matrix); 3. Multiplies the coding matrix by data shards to produce code shards. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (r reedSolomon) Split(data []byte) ([][]byte, error) &#123; if len(data) == 0 &#123; return nil, ErrShortData &#125; // Calculate number of bytes per data shard. perShard := (len(data) + r.DataShards - 1) / r.DataShards if cap(data) &gt; len(data) &#123; data = data[:cap(data)] &#125; // Only allocate memory if necessary if len(data) &lt; (r.Shards * perShard) &#123; // Pad data to r.Shards*perShard. padding := make([]byte, (r.Shards*perShard)-len(data)) data = append(data, padding...) &#125; // Split into equal-length shards. dst := make([][]byte, r.Shards) for i := range dst &#123; dst[i] = data[:perShard] data = data[perShard:] &#125; return dst, nil&#125;func vandermonde(rows, cols int) (matrix, error) &#123; result, err := newMatrix(rows, cols) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; for c := range row &#123; result[r][c] = galExp(byte(r), c) &#125; &#125; return result, nil&#125;// Multiplies a subset of rows from a coding matrix by a full set of// input shards to produce some output shards.// 'matrixRows' is The rows from the matrix to use.// 'inputs' An array of byte arrays, each of which is one input shard.// The number of inputs used is determined by the length of each matrix row.// outputs Byte arrays where the computed shards are stored.func (r reedSolomon) codeSomeShards(matrixRows, inputs, outputs [][]byte) &#123; for c := 0; c &lt; r.DataShards; c++ &#123; in := inputs[c] for iRow := 0; iRow &lt; outputCount; iRow++ &#123; if c == 0 &#123; galMulSlice(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; else &#123; galMulSliceXor(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; &#125; &#125;&#125; Since any $ k $ rows of Vandermonde matrix are linearly independent, with arbitrary $ k $ correct code shards, the original $ k $ data shards can be reconstructed by multiplying the corresponding inverse matrix. However, in practice, we usually do not know which one is correct or corrupted for the $ n $ received codewords. In this case, the plurality of votes method is necessary and $$ \left(\begin{array}{c} n-s\k \end{array} \right)&gt;\left(\begin{array}{c} s+k-1\k \end{array} \right) $$ or $$ s&lt;\frac{n-k+1}{2} $$ where $s$ is number of unkown errors, therefore $ n=k+2s $ always satisfies the in-equation. Another approach is to use the Berlekamp-Welsh Algorithm which avoids the heavy computation of votes: Berlekamp-Welsh decoder: 1. Send $m(0),m(1),...,m(n)$, receive $m'(0),m'(1),...,m'(n)$, and most $s$ of them such that $m(i)\neq m'(i)$； 2. $E(x)=x{s}+b_{s-1}x{s-1}+...+b_{0}$, $Q(x)=a_{k+s-1}x{k+s-1}+a_{k+s-2}x{k+s-2}+...+a_{0}$ 3. Solve the coefficients of co$E(x)$,$Q(x)$ with $ Q(i)=m'(i)E(i)$ 4. Derive $m(x)=Q(x)/E(x)$. And $\forall m(i)\neq m'(i)$,$E(i)=0$. The implicite principle: $Q'(x)/E'(x)$ and $Q(x)/E(x)$ agree on at least $k+s$ points. $E'(x)$ and $E(x)$ both have at most $s$ zero points. Elimilate $E'(x)$ and $E(x)$,$Q'(x)/E'(x)$ and $Q(x)/E(x)$ are degree at least $k-1$ and agree on at least $k$ points, thus $Q'(x)/E'(x)=Q(x)/E(x)=m(x)$. 2. Systematic coding matrix: In the original approach, all the code shards have been encoded. While in the systematic encoding, the original data shards become part of the code shards and only the parity shards should be encoded. In other words, the stripe contains the original datas and parity codewords together no longer codewords only. The coding matrix is composed of the top square identity matrix and the parity matrix. There are three methods of building the coding matrix in this systematic way are provided: Elementary transform on the Vandermonde matrix as the procedure 1. 123456789101112131415161718func buildMatrix(dataShards, totalShards int) (matrix, error) &#123; vm, err := vandermonde(totalShards, dataShards) if err != nil &#123; return nil, err &#125; top, err := vm.SubMatrix(0, 0, dataShards, dataShards) if err != nil &#123; return nil, err &#125; topInv, err := top.Invert() if err != nil &#123; return nil, err &#125; return vm.Multiply(topInv)&#125; Parity matrix is Vandermonde matrix. 1234567891011121314151617181920func buildMatrixPAR1(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Vandermonde // matrix starting at 1 instead of 0. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = galExp(byte(c+1), r-dataShards) &#125; &#125; &#125; return result, nil&#125; Parity matrix is Cauchy matrix. Cauchy matrices are easier to invert than general matrices [8]. 12345678910111213141516171819func buildMatrixCauchy(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Cauchy matrix. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = invTable[(byte(r ^ c))] &#125; &#125; &#125; return result, nil&#125; Generator Polynomial Method# Define the generator polynomial: $$ g(x)=(x-\alpha)(x-\alpha{2})\dots(x-\alpha{2s}) $$ and the codeword polynomial can be directly computed as $$c(x)=m(x)g(x)$$ For the systematic form, which is more often used in practice, we define $$ b(x)=x^{2s}m(x) \quad mod\quad g(x) $$ then the codeword polynomial becomes $$ c(x)=x^{2s}m(x)-b(x) $$ where $-b(x)$ is the parity codeword polynomial. All the polynomial operation above is processed over $GF(2^8)$. It is also observed that the correction of received message can be checked by testing its divisibility by g(x), and there is no need to decode for the systematic encoding if the answer is affirmative. Otherwise, we denote $r(x)=c(x)+e(x)$ and suppose there are $ v(\leq s) $ errors Syndrome based decoder: 1.Calculate the $2s$ Syndromes: $S_{j}=r(\alpha{j})=e(\alpha{j})$ 2. Solve $$ \begin{bmatrix} S_{1} &amp; S_{2}&amp; ... &amp; S_{v} \ S_{2} &amp; S_{3} &amp; ...&amp;S_{v+1} \ ... &amp; ... &amp; ...&amp;... \ S_{v} &amp; S_{v+1} &amp; ...&amp;S_{2v-1} \end{bmatrix} \begin{bmatrix} \Lambda_{v}\ \Lambda_{v-1}\ ...\ \Lambda_{1} \end{bmatrix}=\begin{bmatrix} -S_{v} \ -S_{v+1}\ ...\ -S_{2v}\tag{4} \end{bmatrix} $$ and use Chien search solve $\Lambda(x)=\Lambda_{v}x^{v} +\Lambda_{v-1}x^{v-1}+...+1=0$ to derive the $v$ roots, denoted as,$x_{1},..,x_{v}$. 3. Use Forney algorithm to solve $$ \begin{bmatrix} x_{1}^{-1} &amp; x_{2}^{-1}&amp; ... &amp; x_{v}^{-1} \ x_{1}^{-2} &amp; x_{2}^{-2} &amp; ...&amp;x_{v}^{-2} \ ... &amp; ... &amp; ...&amp;... \ x_{1}^{-2s} &amp; x_{2}^{-2s} &amp; ...&amp;x_{v}^{-2s} \end{bmatrix} \begin{bmatrix} e_{i_{1}}\ e_{i_{2}}\ ...\ e_{i_{v}} \end{bmatrix}=\begin{bmatrix} S_{1} \ S_{2}\ ...\ S_{2s}\tag{5} \end{bmatrix} $$ 4. The index $i_{j}$ of $e_{i_{j}}$ are determined by looking up the logarithmic table as earlier mentioned 5. Compute $e(x)=\sum_{j=1}{v}e_{i_{j}}x{i_{j}}$ and $c(x) = r(x)-e(x)$. It is worth mentioning that all the syndromes are zeros if $r(x)=c(x)$, this can be used to check if the received message is corrupted or if the message was completely constructed. RS encoding is relatively straightforward for the generator approach, but decoding needs complicated algebraic computation, especially for the step 2. Because the real value of $v$ is unknown and the normal way has to use the trial value untill the matrix in $(4)$ is nonsingular. Other algebraic methods for the evaluation of this error location polynomial $\Lambda(x)$ include Berlekamp–Massey algorithm and Extended Euclidean algorithm. This syndrome based decoder can be implemented with different hardware unit such as matrix vector multiplication unit, remainder unit, and performs hard-decision decoding up to $s$ errors. Hard-decision decoding decides the bit according to the a threshold, where each bit is definitely one or zero. While soft-decision decoding requires additional reliability information to improve the decision, which has better coding gain for the white Guassian channel [2]. RS Code in Distributed Storage Systems# The RS code are stored in different disks in the distributed storage systems, and the performance arasure code in distributed storage systems involves disk I/O and repair bandwidth overhead. 5.1 Rotated Reed-Solomon code# In the conventional RS code, all the parity blocds are encoded with data blocks in the same strip, while in the rotated reed-solomon code, parity blocks may be generated with different stripes as in the following figure, when the disk 5 in the figure fails, this method reduceS 3 operations of reading the data blocks than the conventional RS code [5]. Local Reconstruction Code (LRC)# LRC introduces local parity codes which requires slightly more storage space than conventional RS code, but significantly reduce the number of participating data discs for encoding, thus it is beneficial to the reduction of bandwidth and disc I/O overhead. The figure of pyramid code is shown as follows [6] However, repair of the global redundancy still needs to access all data discs, another LRC approach in [7] further introduces parity code ($ S_{3} $ in the figure) for the global parity codes ($P_{1}$,$P_{2}$,$P_{3}$,$P_{4}$) to avoid this undesirable situation. By choosing the coefficients of $c_{1}^{'}$, $c_{2}^{'}$, $c_{3}^{'}$, $c_{4}^{'}$ and $c_{5}^{'}$, $c_{6}^{'}$ properly, the parity code of $ S_{3} $ can be calculated by the existing parity codes $ S_{1} $ and $ S_{2} $. Thus parity code $ S_{3} $ does not have to occupy additional storage. Observation: Copy is kind of LRC. References# [1] I. Reed and G. Solomon, BPolynomial codes over certain finite fields,[ J. Soc. Ind. Appl. Math., vol. 8, no. 2, pp. 300–304, Jun. 1960. [2] Wicker and Bhargava, Reed-Solomon Codes and Their Applications, 1994. [3] James S. Plank and Lihao Xu, Optimizing Cauchy Reed-Solomon Codes for Fault-Tolerant Network Storage Applications. [4] Reed–Solomon codes for coders. [5] Khan O, Burns R C, Plank J S, et al. Rethinking erasure codes for cloud file systems: minimizing I/O for recovery and degraded reads. [6] Huang Cheng, Chen Minghua, Li Jin. Pyramid codes: flexible schemes to trade space for access efficiency in reliable data storage systems. [7] Sathiamoorthy M, Asteris M, Papailiopoulos D, et al. Xoring elephants: novel erasure codes for big data. [8] J. Blomer, M. Kalfane, R. Karp, M. Karpinski, M. Luby, and D. Zuckerman, An XOR-Based Erasure-Resilient Coding Scheme.]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>RS Code</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang编程基础]]></title>
    <url>%2F2018%2F08%2F20%2F2018-8-20%2F</url>
    <content type="text"><![CDATA[在Ubuntu安装: 数据类型: 基本类型： 聚集类型 (aggregate types)： 数组 结构 引用类型 指针 切片（slice） 字典（map） 函数 通道（channel） 接口类型（interface）： 控制流 （for if switch defer goto）： 创建工程目录： Tips: 其他： 参考资料： 在Ubuntu安装:# 123456789&gt;cd ~ &gt;wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz&gt;tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz // 解压到得到的 go 目录，放到 /usr/local 目录下&gt;vim .bashrc // 写入以下内容export GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN&gt;source .bashrc 数据类型:# 基本类型：# 数值 整型：int； int8； int16； int32(rune，Unicode)； int64； uint； uint8(byte)； uint16； uint32； uint64； uintptr int, uint, uintptr 在 32 位系统上是 32 位，在 64位 系统上是 64位 浮点型：float32； float64 复数型：complex64； complex128 字符串：使用双引号 &quot;a&quot; 布尔: true； false 常量：三种基本类型 12345const( kb = 1024 e = 2.71828182845904523536028747135266249775724709369995957496696763 F = false) 在 if语句中，若检验条件为i &gt;= 0，则i 的类型不宜为 uint 型（uint 数据始终 &gt;= 0）。尽管内置函数 len() 返回值是非负整数，但它际返回 int 型， 1234medals := []string&#123;"gold", "silver", "bronze"&#125;for i := len(medals)-1; i &gt;= 0; i--&#123; fmt.Println(medals[i]) // "bronze", "silver", "gold"&#125; 基本类型与操作符构成表达式 取余 % 只用于整型；余数与被除数符号相同，5%3=2； -5%3=-2 5.0/4=1.25；5/4.0=1.25；5/4=1 &amp;&amp; 若左边的表达式结果为 false，不检验右边的表达式；&amp; 始终检验两边的表达式 与或^ ; 一元前缀^ 聚集类型 (aggregate types)：# 数组# 12345var a [3]intr := [...]int&#123;99: 1&#125; // 索引为99的元素，r[99]， 等于 1，其他默认 0p := new([10]int) // 将生成的数组的指针赋给 p, 为 *[10]int 类型p[0]=1 // 给 p 指向的数组的索引为0的元素赋值 1 数组的长度也是数组类型的一部分，因此 [3]int 和 [4]int 是不同类型的数组，不能进行比较或赋值。 结构# （1）结构的字段（field） 1234567891011121314151617181920212223type person struct&#123; // 定义 person 类型 gender string age int&#125;func main()&#123; student := person&#123;&#125; student.age = 16 student.gender = "male" // or student := person&#123; gender : "male", age : 16, //逗号不能省 &#125; // or student := person&#123;"male", 16&#125; teacher := &amp;person&#123; //取指针 gender : "female", age : 30, &#125; teacher.age = 36 //指针 teacher 仍然可以进行点操作&#125; 指针也可以进行点操作。 匿名结构，字段匿名 1234567891011121314student := struct&#123; // 匿名结构 gender : string age : int&#125;&#123; gender : "male", age : "17",&#125;type person struct&#123; string int&#125;// 按照顺序初始化student := person&#123;"male", 10&#125; 结构嵌套， 12345678910111213141516171819202122232425262728type person struct&#123; gender string age int parents struct&#123; // 嵌套一个匿名结构 dad, mom : string &#125;&#125;type address struct&#123; state, city string&#125;type person2 struct&#123; gender string age int address // 嵌套你一个结构address&#125;func main()&#123; student := person&#123;gender : "female", age : 10&#125; student.parents.dad = "Tom" student.parents.mom = "Lily" student2 := person2&#123;gender:"female", age:10, address : address&#123;county:"LA" state:"California"&#125; &#125; student2.address.state = "Massachusetts" // or student2.state = "Massachusetts" &#125; （2）结构的方法（method） 函数与方法 123456789101112131415161718192021222324package mainimport ( "fmt" "math")type Point struct&#123; X, Y float64 &#125;func Distance(p, q Point) float64 &#123; //函数 return math.Hypot(q.X-p.X, q.Y-p.Y)&#125;func (p Point) Distance(q Point) float64 &#123; // 方法，在函数名前增加一个形参（receiver） 类似于Java的this 和python的 self， return math.Hypot(q.X-p.X, q.Y-p.Y) // 接收者的名称通常取它的类型名称的第一个字母&#125;func main() &#123; p := Point&#123;1, 2&#125; q := Point&#123;4, 6&#125; fmt.Println(Distance(p, q)) // 打印 5， 调用函数 fmt.Println(p.Distance(q)) // 调用方法&#125; 当需要使用方法对值（value of type T，相对于方法来讲就是实参，argument） 的字段进行修改时，使用接收者为指针的方法或者叫指针方法 1234func (p *Point) ScaleBy(factor float64) &#123; // 接收者参数p的类型是指针类型 p.X *= factor // p在这里是指针，等价于 (*p).X p.Y *= factor&#125; 同一个 struct 的方法和字段占据相同的命名空间（name space），因此两者的名称不能重复； 指针方法看作高权限方法。 对方法的调用, 值（实参） 和 接收者（形参）类型要相同 12345678Point&#123;1, 2&#125;.Distance(q) // Point Pointpptr.ScaleBy(2) // *Point *Pointpptr.Distance(q) // 隐含 (*pptr)p.ScaleBy(2) // 隐含 (&amp;p) Point&#123;1, 2&#125;.ScaleBy(2) //错误！！！(&amp;Point&#123;1, 2&#125;).ScaleBy(2) 不仅仅是 struct 123456789101112131415161718package mainimport ( "fmt")type INT intfunc main() &#123; var a INT a = 1 a.Print() // 打印 2&#125;func (a *INT) Print() &#123; *a = 2 fmt.Println(*a)&#125; 方法是与命名类型(named type)相关联的函数。 引用类型# 指针# 1234var p *inti := 20p = &amp;i*p = 10 // i 的值为 10 切片（slice）# 123456789101112131415var s []int // 声明切片 sa := [5]int&#123;1, 2, 3, 4, 5&#125;s = a[:2] // [1, 2]， len(s)等于2，cap(s)等于5s = a[0:1] // [1]，len(s)等于1，cap(s)等于5s = a[3:] // [4, 5]，len(s)等于2，cap(s)等于2s := make([]int, 2, 4) //make([]type, len, cap) ，切片长度为2，底层数组的长度为4s = append(s, 1) // s 的地址不变s = append(s, 2, 3) // 生成新的数组，地址改变，容量翻倍，也就是cap(s)等于4*2=8s1 := []int&#123;1, 2, 3&#125;s2 := []int&#123;4, 5&#125;copy(s1, s2) //把 s2 复制到 s1，s1 为 [4, 5, 3]s1 = []int&#123;1, 2, 3&#125;copy(s2, s1) // s2 为 [1, 2] 切片的本质是对底层数组的引用；切片的容量（cap）是切片的始索引到底层数组的末索引的长度。 字典（map）# 123456var m map[int]string // key int 型；value string 型m = make(map[int]string)m2 := make(map[int]string)m[0] = "OK"delete(m, 0) // 删除 m 中键为0的键值对 嵌套， 123m := make(map[int]map[int]string) // value map型m[1] = make(map[int]string)m[1][2] = "YES" 函数# func main(int, []string) int means， function main takes an int and a slice of strings and returns an int 函数作为类型， 1var f func(func(int,int) int, int) func(int, int) int 不定长变参，闭包 12345678910111213141516171819202122232425262728package mainimport ( "fmt")func main()&#123; var_args(1) var_args(1, 2, 3) f := closure(10) fmt.Println(f(1)) fmt.Println(f(2)) &#125;func var_args(args ...int)&#123; fmt.Println(args)&#125;func closure(x int) func(int) int&#123; // 返回匿名函数 return func(y int) int&#123; return x + y &#125;&#125;输出：[1][1 2 3]1112 通道（channel）# channel 是 goroutine 沟通的桥梁，通过 make 创建，close 关闭 12345678910111213141516package mainimport ( "fmt")func main() &#123; c := make(chan bool) go func() &#123; fmt.Println("I from goroutine !") c &lt;- true &#125;() &lt;-c&#125; channel 作为函数形参 123456789101112131415161718package mainimport ( "fmt")func main() &#123; c := make(chan bool) go Hello(c) &lt;-c&#125;func Hello(c chan bool) &#123; fmt.Println("Hello, I from goroutine!") c &lt;- true &#125; 多个 goroutine，多个channel 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt" "runtime")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) // 开启多核 c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; // 启动多个 goroutin go Decomposition(c, i, 100000007) &#125; for i := 0; i &lt; 5; i++ &#123; // 多个 channel 阻塞 &lt;-c &#125;&#125;func Decomposition(c chan bool, index int, n int) &#123; // 质数分解 for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", index, n) c &lt;- true&#125;输出： 0: 1000000072: 1000000071: 1000000074: 1000000073: 100000007从输出结果的顺序可以看出 goroutine 并非先启动先执行 使用同步包来代替 channel 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( "fmt" "runtime" "sync")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) wg := sync.WaitGroup&#123;&#125; wg.Add(5) // 添加 5 个 任务（goroutine） for i := 0; i &lt; 5; i++ &#123; go Decomposition(&amp;wg, i, 100000007) &#125; wg.Wait() // 等到任务数减到 0 &#125;func Decomposition(wg *sync.WaitGroup, m int, n int) &#123; for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", m, n) wg.Done() // 任务数减 1&#125;输出：0: 1000000072: 1000000074: 1000000071: 1000000073: 100000007 selec{}语句， 如果有多个case 读取数据，select会随机选择一个case执行，其他不执行； 如果没有case读取数据，就执行default； 如果没有case读取数据，且没有default，select将阻塞，直到某个case可以执行。 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func main() &#123; c1, c2, block := make(chan int), make(chan string), make(chan bool) go func() &#123; for &#123; select &#123; // 按随机顺序处理多个 case case message, open := &lt;-c1: if !open &#123; // 如果通道 c1 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c1:", message) case message, open := &lt;-c2: if !open &#123; // 如果通道 c2 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c2:", message) &#125; &#125; &#125;() c1 &lt;- 10 c2 &lt;- "hello" c1 &lt;- 20 c2 &lt;- "world" close(c1) // 关闭通道 c1 &lt;-block&#125;输出：A message from main by c1: 10A message from main by c2: helloA message from main by c1: 20A message from main by c2: world 12345678910111213141516171819package mainimport ( "fmt" "time")func main() &#123; select &#123; case &lt;-time.After(2000000 * time.Microsecond): fmt.Println("2 seconds") case &lt;-time.After(1999999 * time.Microsecond): fmt.Println("1.999999 seconds") &#125;&#125;输出：1.999999 seconds 接口类型（interface）：# （1）接口代表某些方法的集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( "fmt")type game interface &#123; Strike_of_Kings() int Battle_Grounds() int&#125;type contact interface &#123; Wechat() QQ()&#125;type smartphone interface&#123; // 接口嵌套， game contact&#125;type iphone struct &#123; version string price float32 user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func (iph *iphone) QQ() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;// iphone 不满足 contact 接口func (iph iphone) Battle_Grounds() int &#123; fmt.Println("There are 4 teammates at most in the Battle Grounds.") return 4&#125;func (iph iphone) Strike_of_Kings() int &#123; fmt.Println("There are 5 teammates at most in the Strike of Kings.") return 5&#125;// iphone 满足 game 接口func (iph *iphone) New_Version(version string) &#123; iph.version = version&#125;func all_round_game(game) &#123; // 接口作为形参 fmt.Println("Both Strike of_Kings and Battle Grounds have installed.")&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; my_phone.Wechat() fmt.Println(my_phone.Battle_Grounds()) all_round_game(my_phone) // my_phone 符合 game 接口，可作为该函数的实参 var _ game = iphone // 确保 iphone 实现了接口game &#125; （2）任何类型都满足空接口；空接口interface{}作为形参可以接受任何类型的实参 12345678910111213141516171819202122232425package mainimport ( "fmt")func main() &#123; m := make(map[int]interface&#123;&#125;) m[1] = "a" m[2] = 2 m[3] = false print_map(m)&#125;func print_map(m map[int]interface&#123;&#125;) &#123; for k, v := range m &#123; fmt.Println(k, ":", v) &#125;&#125;输出：1 : a2 : 23 : false []string 和 []interface{} 是不同的类型； 接口是一种抽象类型，可理解为是将所有具体类型按照方法集进行再分类； 指针方法集包含非指针方法集。 （3）接口值（interface value）包含 类型 （接口的动态类型）和 类型值 （接口的动态值） 两个部分，仅当两者均为nil 时，接口才为nil （4）反射 （reflection） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt" "reflect")type iphone struct &#123; version string price int user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; Info(my_phone)&#125;func Info(itf interface&#123;&#125;) &#123; t := reflect.TypeOf(itf) fmt.Println(t) for i := 0; i &lt; t.NumField(); i++ &#123; fmt.Println(t.Field(i)) &#125; fmt.Println("___________________") v := reflect.ValueOf(itf) fmt.Println(v) for i := 0; i &lt; v.NumField(); i++ &#123; fmt.Println(v.Field(i)) &#125;&#125;输出：main.iphone&#123;version main string 0 [0] false&#125;&#123;price main int 16 [1] false&#125;&#123;user main string 24 [2] false&#125;___________________&#123;X 8316 Xiaohe&#125;X8316Xiaohe 控制流 （for if switch defer goto）：# （1）for： 1234567891011for (inti statement)；condition；(post statement) &#123;&#125;for i := 0; i &lt; 10; i++ &#123;&#125; for ; i &lt; 10; &#123; // 去掉分号&#125; for i &lt; 10&#123; // while 语句&#125;for&#123; // 无限循环&#125; （2）if： 123456 if (init statement)；condition &#123;&#125; if (init statement)；condition &#123;&#125;else &#123;&#125; （3）switch： 12345678910111213switch (init statement)；some value &#123; case 0： case f()： ... default：&#125;switch &#123; case 布尔表达式1： case 布尔表达式2： ... default：&#125; 一旦符合条件自动终止，若希望继续检验下面的case，使用 fallthrough 语句。 （4）defer： defer 后必须跟函数引用 defer 语句被检验后，延迟函数获得变量的拷贝 123456func a() &#123; i := 0 defer fmt.Println(i) i++ return&#125; // defer 语句打印0 defer 语句被检验后，延迟匿名函数获得变量的地址 12345678910111213func b() (i int) &#123; defer func() &#123; i++ &#125;() return 1 // 将1 赋给 i&#125; // 返回 2。利用 defer 语句修改外围函数的命名返回值func c() &#123; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Print(i) &#125;() &#125; return&#125; // 打印 333 defer 语句被检验后，延迟函数的引用被推入堆栈，当外围函数返回后，按照后进先出的顺序被调用（即使外围函数发生错误，如 panic，延迟函数仍然会被调用） 12345func d() &#123; for i := 0; i &lt; 4; i++ &#123; defer fmt.Print(i) &#125;&#125; // 打印 3210 更多细节如，panic， recover（只能用在延迟函数中） 参考 defer blog。 （5）goto： 123456789101112131415161718192021222324LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; break LABEL // 跳出与LABEL同级的循环，即跳出无限循环 &#125; &#125; &#125;LABEL: for i := 0; i &lt; 10; i++ &#123; for &#123; continue LABEL &#125; &#125;LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; goto LABEL // 将再次进入无限循环 &#125; &#125; &#125; 通常标签放到 goto 的后面。 创建工程目录：# Go工程中共有三个部分： src：存放go源码文件 pkg：存放编译后的包文件 bin：存放编译后的可执行文件 **注意：**src目录需要自己创建，pkg和bin编译时会自动创建。 步骤： 新建工程目录，my_project，并在该目录下创建 src目录； 把my_project 添加到 GOPATH，GOPATH=/home/user/...;my_project（可以同时添加多个路径目录，Linux下用冒号:隔开，window下分号;隔开）; 在 src 下创建my_pkg 和 my_cmd; 包文件放入到 my_pkg 中，比如 test.go 1234567package my_pkgimport "fmt" func Test()&#123; fmt.Println("Hello,world!") fmt.Println("You used a function defined in my_package!")&#125; 在命令行src目录，执行 go install my_pkg 将创建 pkg 目录并声成 my_pkg.a 文件。 my_cmd 中放入 package main，比如 hello_world.go 12345678package mainimport( "my_pkg")func main()&#123; my_pkg.Test()&#125; 在命令行src目录，执行 go install my_cmd 将创建 bin 目录并生成可执行文件成 hello_world.exe 文件。 目录结构： src/ $\quad$ my_pkg/ $\qquad$ test.go $\quad$ my_cmd/ $\qquad$ hello_world.go Tips:# import 包A的时候，会自动调用包A的init()函数（i字母小写）。如果该包A又import了别的包B，会优先调用包B的init()函数，最后才调用main包的init()函数。 一个包的init()函数可以定义多个，每个都会被调用，调用的顺序按文件名排序。同一个文件也可以定义多个init函数。 其他：# fmt.printf verbs： %x %b：16进制，2进制显示；%t：显示 bool 结果；%T：显示值的类型；%v：显示值；%p：显示地址；\n：换行 Sublime text 3 上一个编辑处: alt+- 下一个编辑处: alt+shift+- GoSublime： GoSublime快捷键列表：ctrl+.+. (连击 .) 查看声明：ctrl+.+h 代码跳转：ctrl+shift+左键 package control：ctrl+shift+p Goland：退回上一次光标位置：ctrl+win+alt+左键 参考资料：# [1] 无闻;Go编程基础系列视频. [2] Alan A.A. Donovan; Brain W. Kernighan; The Go Programming Language; 2015.]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地项目上传到 Github 仓库、Git开发命令]]></title>
    <url>%2F2018%2F07%2F04%2F2018-7-4%2F</url>
    <content type="text"><![CDATA[生成本地版本库 （.git 文件夹） 创建 SSH key 创建 GitHub 仓库 上传到 GitHub 仓库 本地修改跟新到 GitHub 仓库 生成本地版本库 （.git 文件夹）# 123git initgit add .git commit -m "..." 操作如下， 创建 SSH key# 查看 c盘 用户目录是否包含 .ssh 目录。如果包含，打开 id_rsa.pub 文件并复制里面的内容（密钥） 如果不包含 .ssh 目录（上述操作会报错），通过如下命令创建 1ssh-keygen -t rsa -C "your email address" 其中 C 为大写。然后按照前面的方式复制密钥。 将密钥添加到 GitHub 创建 GitHub 仓库# ![](https://upload-images.jianshu.io/upload_images/1863961-d05408b0cfc2e198.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) ![](https://upload-images.jianshu.io/upload_images/1863961-f7edb952c890e069.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) 上传到 GitHub 仓库# 12git remote add origin git@github.com:jiangtaohe/test.gitgit push -u origin master 本地修改跟新到 GitHub 仓库# 若本地已经关联到仓库，git remote add origin 命令行去掉。 1234git remote add origin git@github.com:jiangtaohe/test.gitgit add .git commit -m "..."git push 1git add file file的修改添加到暂存区 1git commit file -m "备注信息" 创建新的版本库，并将file在暂存区中的修改添加到新的版本库中 1git stash 将工作区和暂存区的修改装箱后回到版本库初始状态(相当于撤销所有修改) 1git stash pop 将 git stash装箱的修改倒出 1git checkout -- file 撤销file工作区的修改 12git checkout --ours (--theirs) filegit add file file发生merge冲突时，完全采取本方(他方)的修改 1git fetch origin dev:local_dev 获取远程分支dev的代码，并在本地创建本地分支local_dev 1git pull origin dev 拉取远程分支dev与当前分支和并(merge) 1git reset --hard commit_id(前4位数) 切换到某个版本库 1git branch branch_name 新建分支 1git branch -d branch_name 删除分支 1git merge branch_name 合并分支 123git statusgit loggit reflog 1git remote -v 打印远程仓库名称和地址 1git remote set-url --add origin git@gitlab.com:jiangtaohe/test.git 增加一个远程仓库]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅历]]></title>
    <url>%2F2018%2F07%2F01%2F2018-7-1%2F</url>
    <content type="text"><![CDATA[有时人的成长在不知不觉中发生，且不论是生理上的还是心智上的。比如人的身高的变化，对于旁人看来是很大的改变，但对于当事人可能是相当无感的（除非你刻意的去测量，并画出折线图来，很少人会这么做吧）。与前者相比，心智的 变化更加隐蔽，你甚至都不好记录数据作出图表来，但并非一无所知，有些是可以从生活中窥见端倪。 少年时期的我非常讨厌吃苦瓜。你可能已经脑补出我第一次吃苦瓜时候的表情了。 “是人吃的吗？”，当然没有说出口，但我当时就那么想的。让我惊奇的是母亲竟吃得津津有味 (＃°Д°) 好像我吃了一口假的苦瓜。转念一想，既然这玩意儿都叫苦瓜了，那是必苦无疑了。那时的我品不来苦瓜的味道，自然理解不了母亲的有滋有味了。后来偶尔遇到苦瓜也会吃上一小片，“浅尝辄止”，毕竟还是那个味儿啊，干嘛亏待自己。直到上了大学后才有了改变。 话说我在大学吃了几年食堂，喜欢吃的都吃得腻了。某天心血来潮，要不来盘炒苦瓜吧。我突然发现这玩意儿不那么苦了，甚至感到别有一番风味。原以为跟苦瓜品种有关，所以后来回外婆家时，我特意让外婆做了道炒苦瓜，吃起来也是不那么苦。我意识到“物是人已非”，苦瓜还是年少时的苦瓜，而我却不一样了。这种变化当然有生理上的，但更多的是心智上的，而后者是自己的阅历在不断增长的结果。有些事情阅历够了自然就会了。 类似的还有对戏曲的理解。以前的我根本就看不了戏曲的，无感啊。随着年龄的增长，我对戏曲的态度也发生改变，虽然谈不上热爱，但多少也能品到其中的一些韵味。尤其是京剧，不愧为国粹，尽管没看过一个完整的剧目，也叫不出多少剧目的名字来，当我被表演者的一颦一簇、一唱一打所牵动的时候，我知道那就是好的戏曲，了不起的艺术！]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独憩]]></title>
    <url>%2F2018%2F06%2F19%2F2018-6-19%2F</url>
    <content type="text"><![CDATA[有时候我真地喜欢安静，独自一人，不被打扰，做一些没有意义的事情。 当下简单地唯水，笔，布而已。]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运动与冥想]]></title>
    <url>%2F2018%2F06%2F14%2F2018-6-14%2F</url>
    <content type="text"><![CDATA[近来又把跑步纳入日常。跑着跑着，跑出了一点心得，今以记之，算是对自己坚持锻炼的勉励。 一开始，我是跟着小伙伴一起跑来着，然后有几次自己跑。回想运动时候的状态，我发现自己跑运动地更充分，锻炼的效果也更好。据说跑步半个小时是一种很好的锻炼方式，前提是要保质保量。保质就要求全程保持在跑的状态，你可以跑快点或者慢点，但不要是 walking 。保量就是最少跑半个小时，当然你也可以按照路程（多少圈跑道）来计。值得注意的是，这个保质保量因人而异，你需要给自己设立合理的目标且不能够轻易就可达成。 专注于跑步有利于目标的达成。这也解释了为什么独自跑步的效果更好（与小伙伴相互鼓励当然也挺好），因为不用刻意去协调别人，你可以更快找到自己的节奏。当你持续地专注于自己的身体和感觉时，你可以体会到控制与活力，而维持标准动作可以加深这种体会。因此，不妨把跑步看作一次冥想训练，专注于自我，体会积极的力量也接受脑涨腿乏感觉，但不要让疲劳占据上风，否则你将动作变形，愈感举步维艰。 避免外部干扰因素有助于专注，比如握着手机，携带狗狗等尽量避免。 最后需要强调的是注意安全。当身体出现不适的时候，千万不要勉强。前两些天就有公众号报道某男子跑步过程中摔倒了两次仍要坚持，最终导致猝亡的杯具。还有上文提到独自运动有助于专注，但还是避免去人少的地方活动，尤其是女同学。学校的操场是绝佳的场所，因为有其他的同学还可以减少孤独感，对自己的坚持是很有帮助的。]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多宝塔碑精选]]></title>
    <url>%2F2018%2F06%2F10%2F2018-6-10%2F</url>
    <content type="text"><![CDATA[《多宝塔碑》精选三十七字。来源于搜狐“书法思考”，今藏以时习之。 横、竖：(三、王、十、半、中)# 撇、捺：(大、手、又、年、入)# 点：(心、涵、浮、并、尚、小、於、其、感)# 钩、挑：(宗、求、观、表、见、咸、食、以)# 折：(自、名、了、山、牙、矣、母、外、女)#]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 笔记]]></title>
    <url>%2F2018%2F05%2F28%2F2018-5-28%2F</url>
    <content type="text"><![CDATA[创建 flask instance（也就是一个应用）两种方式：1. (module) 在URL\my_app.py中加入 12from flask import Flaskapp = Flask(__name__) 2.(package) 在URL\app_folder\__init__.py中加入 12from flask import Flaskapp = Flask(&apos;app_folder&apos;) 阅读 Miguel Grinberg's book: Flask Web Developent SECOND EDITION 中的一个小应用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import os from datetime import datetime # python 标准库，datetime.utcnow()from flask import Flask, render_template, session, redirect, url_for, flash from flask_bootstrap import Bootstrap # flask 扩展from flask_moment import Moment # flask 扩展from flask_wtf import FlaskFormfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequiredfrom flask_sqlalchemy import SQLAlchemyfrom flask_migrate import Migratebasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__) # 创建应用app.config['SECRET_KEY'] = 'hard to guess string'app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(basedir, 'data.sqlite')app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = Falsebootstrap = Bootstrap(app) # templates 文件夹中 base.html 扩展了 bootstrap/base.htmlmoment = Moment(app) # 设置日期、时间的格式。moment.js 由 base.html导入db = SQLAlchemy(app) # 创建数据库migrate = Migrate(app, db)class Role(db.Model): __tablename__ = 'roles' # 表格名称 id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship('User', backref='role', lazy='dynamic') # 与 User 类关联。backref 给 User 类创建 role 属性，在生成 User 对象时通过 role 与一个 Role 对象关联。 def __repr__(self): # 直接输出对象或者通过 print 打印对象时，信息都按__repr__方法中定义的格式进行显示。 类似的 __str__ 只有在 print 打印时才生效。便于调试。 return '&lt;Role %r&gt;' % self.nameclass User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey('roles.id')) def __repr__(self): return '&lt;User %r&gt;' % self.usernameclass NameForm(FlaskForm): name = StringField('What is your name?', validators=[DataRequired()]) # DataRequired()要求提交时表单不为空 submit = SubmitField('Submit') # 表单的提交按钮。 在 render html 时，添加 type='Submit' 属性@app.shell_context_processordef make_shell_context(): # 运行 flask shell 时自动从 app(hello.py) 导入 db, User, Role return dict(db=db, User=User, Role=Role)@app.errorhandler(404) def page_not_found(e): # 404，500 为 html 错误类型 return render_template('404.html'), 404 # 返回元组@app.errorhandler(500)def internal_server_error(e): return render_template('500.html'), 500'''@app.route('/')def index(): return render_template('index.html', current_time=datetime.utcnow())'''@app.route('/user/&lt;name&gt;')def user(name): return render_template('user.html', name=name) # name=name， 前者代表 user.html 中的 name 变量，后者代表由用户在网址栏中输入的值，即&lt;name&gt;@app.route('/', methods=['GET', 'POST']) def index(): # Post/Redirect/Get pattern，inde()被调用两次 form = NameForm() # 生成表单实例 if form.validate_on_submit(): # 表单被提交且通过所有的 validators （这里只有 DataRequired()一个）时返回 True old_name = session.get('name') if old_name is not None and old_name != form.name.data: flash('Looks like you have changed your name!') # 当两次提交的内容不同时显示提示框。flash() 里的参数被 模板 base.html 中的 get_flashed_messages() 函数提取。 session['name'] = form.name.data # 保存表单提交的 data return redirect(url_for('index')) # url_for('index') 返回 root URL。redirect() 发出对 root URL 的 GET请求，作为对 POST 请求的回应。 return render_template('index.html', form=form, name=session.get('name')) # 对 redirect() 的 GET请求的回应。# 加入数据库@app.route('/', methods=['GET', 'POST'])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() # 查询表单提交的用户名 if user is None: # 如果不在数据库中就把它加入 user = User(username=form.name.data) db.session.add(user) db.session.commit() session['known'] = False else: session['known'] = True session['name'] = form.name.data return redirect(url_for('index')) return render_template('index.html', form=form, name=session.get('name'), known=session.get('known', False))]]></content>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to Create a Personal Blog]]></title>
    <url>%2F2018%2F05%2F22%2F2018-5-22%2F</url>
    <content type="text"><![CDATA[The Structure of The Blog Apply For a Github Account and Create a Repository Create hexo source file download and install create file select and add your theme 2.4 deploy the source file to the github repository When you see this blog post, you have already had some kind of motivation to create a personal blog, maybe it is to possess something, record your ideas or just to be cool. From my observation, most people who have a personal blog are the computer professionals. But this does not mean you have to create your blog with much computer knowledge. The rest of this post will show you the process can be easy and fun. The Structure of The Blog# From the structure, you almost know what to do next. You don't have to build a browser, since your PC has already had one. You just need to do the left two things, applying for a github account as the remote platform to store your blog files, creating the local source file which is the root of your blog. Apply For a Github Account and Create a Repository# Click Github to apply. Create hexo source file# Most of the source file is generated by Hexo which is a popular blog framework and is based on Node.js. We also need Git to deploy the source file to your newly created repository. download and install# Node.js Git Hexo is installed with the Git tool. After installing the Git, click your the right mouse button on the desktop and select the &quot;Git Bash Here&quot; option (means open the bash window in the current directory). Type the following commond to enter your home directory. 1cd ~ Input the following commond to install Hexo. 1npm install hexo-cli -g create file# Create hexo source file . You can make your own file name to replace &quot;hexo_source&quot;. 1hexo init hexo_source select and add your theme# Select a theme from hexo themes library . You can also use hexo-new-vno if you like the theme of my blog 😉. Then use the commond to add the theme file to your hexo source file you have already created. 12cd hexo_sourcegit clone https://github.com/monniya/hexo-theme-new-vno themes/new-vno You will see the new-vno file at ...\hexo_source\themes\new-vno if not wrong. In fact, hexo has a built-in theme landscape. Open ...\hexo_source\ _config.yml (you can use editors like atom, sublime etc.) and revise some arguments. 1234567891011121314151617181920title: 小禾の新世界subtitle: STAY HUNGRY, STAY FOOLISH!description: (～￣▽￣)～ 嗨 (✿●'◡'●)keywords:author: #your name as authorlanguage: zh-Hans timezone: email: #your email addressurl: https://your_user_name.github.ioroot: /your_user_name.github.io/plugins: hexo-generate-feed # you need input "npm install hexo-generate-feed" in the git bash window to install this plugin.theme: new-vnodeploy: type: git repo: https://github.com/your_user_name/your_user_name.github.io.git branch: master More details of configuration click here. And revise arguments in ...\hexo_source\themes\new-vno\ _config.yml to configure the theme. 12345678910111213menu: 归档: /archivesrss: /atom.xmldescription: RSSsocial: weibo: #your weibo address github: #your github address stack_overflow: facebook: twitter: google_plus: To write a blog, you just write a markdown file in .../hexo_source/source/ _posts folder. 1234567---title: How to Create a Personal Blogdate: 2018-05-22 21:37:37tags: hexo---My first blog post ...## The Structure of The Blog 2.4 deploy the source file to the github repository# Install the deploy tool. 1npm install hexo-deployer-git --save Start to deploy. 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d After the deploy you can visit your blog by typing &quot;your_user_name.github.io&quot; in the browser. You have already built the blog. Congratulations!]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
