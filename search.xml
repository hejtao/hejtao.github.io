<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flutter Notes]]></title>
    <url>%2F2019%2F12%2F28%2F2019-12-28%2F</url>
    <content type="text"><![CDATA[Fascinating Flutter Pages Dynamical Disco Notes Fascinating Flutter Pages# Dynamical Disco# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import 'package:flutter/material.dart';import 'dart:math';class DiscData &#123; static final _rng = Random(); double size; Color color; Alignment alignment; DiscData() &#123; color = Color.fromARGB( _rng.nextInt(200), _rng.nextInt(255), _rng.nextInt(255), _rng.nextInt(255), ); size = _rng.nextDouble() * 40 + 10; alignment = Alignment( _rng.nextDouble() * 2 - 1, _rng.nextDouble() * 2 - 1, ); &#125;&#125;void main()&#123; runApp( MaterialApp( debugShowCheckedModeBanner: false, home: Scaffold( body: Container( color: Color(0xFF15202D), child: SizedBox.expand( child: VariousDiscs(50), ), ), ), ), );&#125;class VariousDiscs extends StatefulWidget &#123; final numberOfDiscs; VariousDiscs(this.numberOfDiscs); @override _VariousDiscsState createState() =&gt; _VariousDiscsState();&#125;class _VariousDiscsState extends State&lt;VariousDiscs&gt; &#123; final _discs = &lt;DiscData&gt;[]; @override void initState() &#123; super.initState(); _makeDiscs(); &#125; void _makeDiscs() &#123; _discs.clear(); for (int i = 0; i &lt; widget.numberOfDiscs; i++) &#123; _discs.add(DiscData()); &#125; &#125; @override Widget build(BuildContext context) &#123; return GestureDetector( onTap: () =&gt; setState(() &#123; _makeDiscs(); &#125;), child: Stack( children: [ Center( child: Text( 'DISCO FACE', style: TextStyle(color: Colors.white, fontSize: 50), ), ), for (final disc in _discs) Positioned.fill( child: AnimatedAlign( duration: Duration(milliseconds: 500), curve: Curves.easeInOut, alignment: disc.alignment, child: AnimatedContainer( duration: Duration(milliseconds: 500), decoration: BoxDecoration( color: disc.color, shape: BoxShape.circle, ), height: disc.size, width: disc.size, ), ), ), ], ), ); &#125;&#125; Notes# 组建调试 12345@override Widget build(BuildContext context) &#123; debugPaintSizeEnabled = true; return Container(); &#125; ListView 支持 app body 的滚动, Column + SingleChildScrollView]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Notes]]></title>
    <url>%2F2019%2F12%2F01%2F2019-12-1%2F</url>
    <content type="text"><![CDATA[linux 文件移动、复制 文件权限 Linux查找命令 其它 vim linux# 文件移动、复制# mv a b：重命名 mv /home/music/往后余生.mp3 /home/loved_music/ ： 把往后余生剪切（移动）到 loved_music下 cp -a /home/jiangtao/* /home/huaxi ： 复制jiangtao下的所有文件到huaxi下 cp -a /home/jiangtao /home/huaxi ：文件夹拷贝，得到 /home/huaxi/jiangtao rm -rf /home/jiangtao/* ： 删除jiangtao下的所有内容。-r不管有多少级目录，一并删除；-f 强行删除，不作任何提示 rm -rf /home/jiangtao ：删除jiangtao目录 cat textfile：显示内容 cat -n textfile1 &gt; textfile2：把 textfile1 的文档内容加上行号后输入 textfile2 这个文档里 cat -b textfile1 textfile2 &gt;&gt; textfile3：把 textfile1 和 textfile2 的文档内容加上行号（空白行不加）之后将内容附加到textfile3 文档里 文件权限# chown (change ownership)将指定文件的拥有者改为指定的用户或组 123&gt;sudo chown -R $(whoami) /usr/local/Cellar&gt;sudo chown root:hejtao file.txt&gt;sudo chown hejtao:hejao file.txt -R: 处理指定目录以及其子目录下的所有文件 chmod abc file 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限 r=4(可读)，w=2(可写)，x=1(可读写) 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5。 chmod 765 file.txt 等价于 chmod u=rwx,g=rw,o=rx file.txt Linux查找命令# find . -type f -mmin -10 搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录 find . -name 'my*' -ls 搜索当前目录中，所有文件名以my开头的文件，并显示它们的详细信息 find . -type f -iname &quot;*.php&quot; find . -size -1M 小于1M的文件 find . -type d -not -iname &quot;*php&quot; 找不以php结尾的目录 find . -maxdepth 1 -type f -iname &quot;*.conf&quot; 当前和下一级目录 find . -type f -iname &quot;*.php&quot; -exec grep &quot;function&quot; {} + locate -i hello.txt 查找文件位置，-i 选项忽略大小写 locate ~/m 搜索用户主目录下，所有以m开头的文件 其它# echo 显示字符串，转义字符，变量；内容定向至文件 12345&gt;echo hello, world! &gt; hello 先清空在写入&gt;cat hellohello, world!&gt;echo hello, world! &gt;&gt; hello 换行后写入 grep ipfs . -r -n 在当前目录的多级文件进行（-r）递归搜索，并（-n）显示行号 grep -i -n &quot;function&quot; ./* ps -ax | grep ipfs : 显示系统中当前运行的包含 ipfs 的进程 一行输入多个命令,使用; 、&amp; 、| 1234&gt;echo i am hejtao\n ; echo hello hejtaoi am hejtaohello hejtao ifconfig: 查看和配置网络设备 mkdir rmdir touch new.txt新建文件 man查询命令的信息 停止命令 Ctrl + c 强制停止命令 Ctrl + z 清空窗口 clear 自动联想TAB 关闭sudo halt 重启 sudo reboot. ssh root@207.148.109.110 mosh root@207.148.109.110 scp ./Go语言编程_许式伟.pdf root@207.148.109.110:~/my_files 本地上传到vps 清屏 clear 屏幕翻页 ctrl l ls -l (long) -r(reverse) -s(size) ls &gt; outfile.txt 结果写入outfile.txt ls | tee outfile2.txt 显示结果，并将结果写入outfile2.txt apt-cache 断开ssh：ctrl d vim# 保存退出：shift zz 不保存退出：shift zq 删除本行： dd 复制本行：yy 行标下粘贴：p 行标上粘贴：P u 撤销上一步的操作,输入u两次，你的文本恢复原样 Ctrl+r 恢复上一步被撤销的操作 ggVG 全选 , 选中内容以后就可以d 删除选中内容 , y 复制选中内容到0号寄存器 gg 让光标移到首行，在vim才有效，vi中无效 V 是进入Visual(可视）模式 G 光标移到最后一行]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学通识50讲]]></title>
    <url>%2F2019%2F11%2F25%2F2019-11-25%2F</url>
    <content type="text"><![CDATA[发刊词：数学该怎么学？ 模块一 ｜ 数学的线索 01 ｜ 导论：数学通识课的体系和学习攻略 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理 03 ｜ 数学的预见性：如何用推理走出认知盲区 04 ｜ 数学思维：数学家如何从逻辑出发想问题 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学 07 ｜ 数学应用：华罗庚化繁为简的神来之笔 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要 09 ｜ 数列和级数（二）：传销骗局的数学原理 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密 模块二 ｜ 数学的概念 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大 12 ｜ 三次方程：数学史上的发明权之争 13 ｜ 虚数：虚构这个工具有什么用 14 ｜ 无穷：我们为什么难以理解无限的世界？ 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？ 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？ 17 ｜ 无穷小（三）：用动态和极限的眼光看世界 模块五 ｜ 微积分 30 ｜ 微积分（上）：如何从宏观变化了解微观趋势 发刊词：数学该怎么学？# 在上个世纪80年代，国内流行过一句口号：“学好数理化，走遍天下都不怕。”因为当时的教学体系还不完善，数理化这些基础学科比重大，而且容易培养出建设型人才，所以受到重视。当然，随着综合教育体系的完善，这个口号也就不再流行了。 ... &emsp;&emsp;但是，在今天来看，无论你的专业和工作是什么，你都会发现，数理化这些底层学科是不是牢固，真的决定了一个人的知识结构能搭多高，在专业上能走多远，尤其是数学。数学作为一切科学的基础，它化繁为简，直击本质的思考方式，让很多人获益。那些数学成绩好的人，做起事来总是一通百通，很容易脱颖而出。 但是事实上，很多学习数学的人会感觉自卑，并产生厌恶。这是为什么呢？当然不是数学本身的问题，也不是我们人的问题，而是因为我们和数学之间缺失了一个桥梁。数学是一种抽象的知识体系，而我们人要靠经验感知才能认识世界，这中间需要一个桥梁，这个桥梁一旦构建起来，每一个人都能受益于数学。 那么是否每一个人都有可能学好数学呢？公平地讲，数学往深了学确实很费脑力，对大多数人来讲有点难度，但是把平时用到的、能够提升我们思维的数学学好，是每个人都能做到的。接下来我就用一个例子谈谈怎么学数学。 2017年，一位原央视的主持人请我和中国科技馆前馆长王渝生先生，做一个有关数学的节目。在节目开始前，主持人对我说，她高考时数学不及格，是个学渣。我说，你能有今天这样的成就，显然不是学渣。数学没学好，不是你的问题，是教学的方法和考量学生的方法不对。 然后我就告诉她美国顶级的高中和大学是怎样教数学的。在美国最好的高中，把数学课由中国的一门课变为8～10门内容不同的课程，每门课还要开A、B、C三个难度不同的班。比如我们中国（从初中到高中）的几何，被分为平面几何A、B、C，解析几何A、B、C，等等各种难度的课程和班级。 入门的那几门数学课足够浅显，难度较低的班会讲得更浅，内容更精简。比如平面几何的A，讲清楚几何学的原理和用途，以及推理的思维方式就好，就不让学生再做那些比较难的证明题了。像点、线、面、三角形、四边形和多边形等概念，以及平行、垂直等关系，其实对任何人都不难，都能取得好成绩。 当然，由于你选择了简单的数学，也就没有浪费时间去攻克对自己来说很难的数学内容，就可以学更多自己喜欢的文学或历史，然后申请那些更适合自己的大学。 更重要的是，虽然你所学的数学课不多，也不深，但好歹掌握了基本概念，掌握了相应的思维方式，如果将来真想再继续学，还是有可能的。否则你学了一大堆理解不了，考试通不过的内容，不仅浪费时间，而且本来能学会的简单内容也全丢掉了。 不信我问你，还记得住计算圆球体积的公式，或者方程组的解法吗？那些都不是什么很难的内容，但是因为大家做不出数学题，考不出满意的分数，就从心里彻底放弃了这门课，以至于那些本应该记住的简单内容也干脆全忘光了。可以说，结果就是早早地就把通往数学的桥梁毁掉了，从此以后，再也没有体会过数学思维的乐趣，放弃了智识生活的可能。 那么在我的数学课中，我会教什么？大家又应该怎么学？学完以后应该怎么用呢？ 在教学方面，我会模仿美国的数学教学方式，为你做好三件事，也是我这门数学课的三个教学特色： 首先，我会为你重建这座通往数学的桥梁，帮你把那些熟悉的知识点各安其位，放进知识体系里。 我的讲法是把一门数学课从完整的体系变成一个个的知识点，讲透之后，再还原回体系。让你能够熟练地把握知识点和课程体系的关系，这门课的体系也就搭建好了。 以最难的几何学为例，再难的几何题，其实最终都可以拆成那五个最基本的公理。这五个公理，又可以推导出几何学的任何结论。就如同几种乐高积木可以搭出任何形状一样，我会在几何那个模块介绍给大家。 至于这个体系能构建得多大，则要看学生能够接受的程度，学生接受的程度高，就搭一些复杂的，接受程度低，就搭一些简单的。但是能够拆解和搭建哪怕是比较小的体系，通识教育的目的就达到了。 **其次，在介绍这些关键数学知识点的同时，我会讲清楚它们在数学上的位置，以及和各种知识体系的相关性。**这样不仅能够把各种知识打通，而且能够让你在自己的行业中超越绝大部分从业者。 我的《数学之美》出版后，很多人读后感慨，原来数学对信息处理帮助这么大。但其实那本书中介绍的全部内容，不过是一些知识点。而仅仅是理解了那些知识点的计算机从业者，就已经获得更强的竞争力了。 再比如，为什么大家熟知的勾股定理，在国际上通行的叫法是毕达哥拉斯定理？因为勾股定理只是经验，而毕达哥拉斯定理却完成了数学证明，但教科书出于发明权的考量并没有说明，结果就是把数学这门课的逻辑基础搞丢了。以至于很多人大学毕业工作多年依然搞不清物理上用实验证实的定律和数学上用逻辑证明的定理有什么差别。如果基础就打歪了，以后进入工作，很可能出大错。 **最后一点，也是最重要的，是通过学习数学，实现思维方式的跃进。**为了做到这一点，并不需要讲述太难的数学知识，而是需要讲透。 事实上，我们无论是讲透毕达哥拉斯定理，还是更难懂一些的欧拉公式，都可以在讲述的过程中将数学家超出凡人的思维方式讲清楚。毕竟对于大部分人来讲，一辈子用不到欧拉公式，如果他们不容易理解，用简单的例子把道理讲清楚就变得格外重要了。 至此，我为你搭建的桥梁就算建造好了，当然，还是需要你亲自从这头走到那头去，我们接下来谈谈你怎么做，才能跟着我学好数学： 一个学好数学最重要的办法是，不断训练自己的思维方式。 很多人喜欢读侦探小说和悬念小说，喜欢解决各种谜题，这其实是人类的一种天性，也是对头脑的一种训练。学数学能够提高我们这方面的能力，让自己成为一个“深入的思考者”（Deep Thinker）。 世界上有两种所谓的聪明人，一种是反应很快的人，被称为Quick Thinker，另一类则是Deep Thinker，也被称为Hard Thinker，无论是哪一种，其实都是可以后天训练的。训练快速反应最好的办法就是多听多看。但是训练Deep Thinker，就需要练习一环扣一环解套的本事了。 用数学做这种训练的好处是，它经过上千年的发展，已经有一整套训练材料了。所以学数学，就像打游戏晋级一样，一点点往前探索，一个个击破难题。 最后，请你查看课表（即目录），当然我还是想再从不同的维度上帮你提炼一下。 首先，我们会学到虚数、极限、微分、积分等等这样的具体知识点，掌握它们之间的关联，以及它们在人类认知方面的地位。这样我们就能理解人类是如何扩展自己的认知的。如果我们把自己成长的过程和人类成长的过程做一个对标，就能通过它们扩展我们自己的认知。 再往上一个维度，你还能了解数学在人类知识体系中的地位，比如数学和艺术的关系，和法律，和经济学的关系，等等。很多时候，数学不能直接解决我们的实际问题，但是它能够给我们提供一个思路。 在更高的维度上，我会通过介绍数学的发展史，帮你理解数学思维，也就是人类的认识是如何从直观到抽象，从静态到动态，从宏观到微观和宇观，从随意到确定，再到随机，等等。 好，如果你想重新认识一下数学，和我一起感受一次数学之美，那么欢迎你加入我的《数学通识50讲》。当然，除了数学通识，我还将开设一系列的通识课程，把每个人都需要掌握的人类知识精华，整理成课程，帮每个现代人装备自己的头脑，找到最适合这个世界的思维方式。 好，我们马上开始数学之旅！ 模块一 ｜ 数学的线索# 01 ｜ 导论：数学通识课的体系和学习攻略# 这一讲算是数学通识课的学习地图，我会带你俯瞰一下这门课的全貌，便于你系统地把握课程内容。 ... &emsp;&emsp;如果把人类的知识体系用学科来划分的话，数学可能是其最大的一个，因此要想在50讲左右的时间里介绍它的全貌是不可能的。 所幸的是，作为通识教育，你不需要学那么多，而且数学的各个分支，无论难易，从体系到研究方法，再到应用方法是共通的。 成年人接受数学通识教育，其实只要做到一点就够了，就是从理解初等数学到理解高等数学——（也就是）把自己对所有和数学相关的概念和方法的理解程度，从静态的、具体的，上升到动态的、规律性的。要达到这个目的，不需要讲很多内容，但需要一些线索。 下面我就简单介绍一下课程的内容和我选择它们来串联课程的理由。 第一模块讲的是数学究竟是怎么从一个猜想，得出推论，然后又产生实际应用的。 根据《时间简史》和《大设计》的共同作者蒙洛迪诺的讲法，人类早期的所有知识体系都是：“前科学”。这是好听的说法，难听的说法叫做“巫术式”的。 在所有早期文明中，唯一的例外是古希腊。但即使是在古希腊，我们所知的那些大学问家们比如泰勒斯、赫拉克利特、亚里士多德，他们的思维依然是前科学的，不是科学的，因为他们对客观世界的解释，加入了太多主观的想象。而在古希腊，真正具有划时代意义的人则是毕达哥拉斯。 毕达哥拉斯是将数学从经验上升到系统性学科的第一人。他确立了数学的起点，也就是必须遵循严格的逻辑证明才能得到结论的研究方法，这就让数学从早期那些需要靠测量和观测的学科，比如天文学、地理学和物理学中，脱身出来，成为所有基础学科之上，带有方法论性质的特殊学科。 因此，我们会先从毕达哥拉斯学起，他也是整个第一模块的主线。那么我会怎么讲这个模块呢？ 首先，我会讲毕达哥拉斯最出名的毕达哥拉斯定理，也就是我们所说的勾股定理。 我们还知道，毕达哥拉斯最被后人所诟病的地方是否认无理数的存在，并假装视而不见，还把提出这个问题的学生害死了。 对此，今天很多人说他无知，顽固，拒绝接受真理等等。但是要知道，在当时人们所知的有限的数学领域中，毕达哥拉斯是这个体系的教主，他需要这个建立在逻辑之上的体系的一致性和完备性，而逻辑上的一致性也是数学最基础的原则。 因此，他发现无理数的出现会破坏他所理解的数学体系的完备性，动摇数学大厦时，他就采取了教主们才会采用的激进行为。 毕达哥拉斯真正的错误在于，他不懂得要维系数学这个体系，需要定义“无理数”这样的新概念。无理数造成的数学危机解决之后，数学反而发展了，并没有像毕达哥拉斯想的那样崩溃。 毕达哥拉斯另一个了不起的成就，就是算出了黄金分割的比例。从黄金分割出发，毕达哥拉斯发现了数学和美学的关系，并且开始用数学指导音乐。 概括来讲，我们在第一模块“数学的线索”里面，以毕达哥拉斯为线索，一方面将很多数学知识点串联起来，向大家展示数学是什么样的体系，另一方面，我们把毕达哥拉斯作为例子，说明数学发展和体系构建常常经历的步骤。也就是，从特例到引理再到定理、推论，最后到应用的全过程。 但是数学的发展又非单一线索，从一个点出发可能产生了很多并列的推论，因此我们不得不在课程中把并行的内容按顺序来讲。比如在第一模块中，我们在讲完黄金分割的应用后，又会回来讲和它有关的等比数列。 当你知道数学定理是如何从猜想到推论再到应用的过程，我们就进入课程的第二个模块“数的概念”，通过讲述人类对数字这个概念的认识历程，我会给你一个思维工具——“从具体到抽象”，从而解释为什么你从小学数字，但其实对数字的认识并没有提高，以及学数学多年都不能为己所用的原因。 照理讲，我们的认知水平应该随着所学内容难度的提升而提升，但是通常不是如此。很多人学到大学关于数字的概念时，对数字的理解方式，还停留在小学阶段。 比如，对于无穷大和无穷小这样的概念，很多人依然以为它们只是巨大的数字和极小的数字。事实上它们和我们日常遇到的具体数字不同，代表着变化的趋势和变化的快慢。因此从小学到了大学，大家对数字的理解就应该从静态到动态，但遗憾的是，很多人并没有这样的认识。 当一个人用小学的思维方式，学习大学的数学内容，一定会觉得难以理解，于是对数学敬而远之。这并不能怪学习的人，而是怪很多数学课在设计时，没有把听众当作未来的主人，而只是把他们当作未来的工匠，教给他们一些具体知识让他们干活，而非更高级的思维认知。 因此，在第二模块中，我们会突出数学作为“抽象思维”工具的作用，比如人们从具体算术到抽象代数，用到解方程、虚数等等，为什么要学习它们？因为它们的角色是人类造出来的抽象工具，在现实生活中并不存在，但是有了它们，现实的问题就好解决了。数学通识教育，一个重要目的就是让大家习惯于使用这样的抽象工具。 **第三、第四模块的内容集中在我们熟知的几何和代数。**在几何的模块中，我们会以它为例子介绍什么是公理化的知识体系，它是如何建立的。 在代数的模块中，我们会重点介绍函数和向量。函数这个概念的发明，把我们人类的认知从个体上升为整体，从单点联系，上升为规律性的网状联系。 比如同一道题目，从小学到大学，理解是不同的，这是一个从单纯理解数字大小，到理解它方向性的过程。 在小学，如果我们看到一道题，说张三以50公斤的力拉箱子，李四以30公斤的力拉，拉箱子的力是多少？答案很简单，就是80公斤。但是到了初中，我们有了负数的概念，你就要问他们拉箱子的力是相同的还是相反的，如果是相反的，只有20公斤。 再往上学，我们就要问他们拉箱子的力夹角是多少度，在90度时和120度时，受力可是不同的，这就进入到了大学思维。 向量和线性代数，就是把数字从单纯的数值，变成了有方向的数值。所以，我认为这两大知识点，最能代表代数模块的内涵，可以帮助大家提升认知。 **第五模块是微积分，这已经是高等数学的内容了。**但是，我们其实在第二模块里已经不知不觉地把微积分中最难的内容提前讲了，因此在这个模块，大家反而会觉得简单。 对于微积分，它和初等数学的工具有什么不同呢？人们开始对把数学从关注静态的关系，变成了对动态规律，特别是瞬间规律的把握上。理解这一点，并且主动应用到工作中，是我们学习微积分的目的。那些很难的概念，解题技巧，其实毫不重要。 好，前面你学习了数学公理、数字、几何、代数和微积分，提纲挈领地回顾了数学发展的历史，这些分支有个特点，就是能给出问题唯一的答案。 但是到了近代，很多现实问题很难有完全确定的答案。于是，**为了研究不确定世界的规律性，概率和统计发展起来了。**数学的这个分支在今天我们充满不确定性的世界里非常重要，也是所谓的大数据思维的科学基础。 纵观数学发展的历程，以及我们应该具有的数学思维历程，我们可以看到这样的趋势，从个案到整体规律，从个别定理到完整的知识体系，从具体到抽象，从完全的确定性，到把握不确定性。 无论是在整个的课程中，还是每一个模块之内，我们都能看到这样人类认知升级的过程。当然，我觉得这也应该是我们自己的认知升级过程。 在课程的最后，我们会介绍数学和其它学科的关系。这样能够在完整的知识体系中，更好地理解数学。接下来，我们就先从毕达哥拉斯讲起，从数学的起点开始我们的数学之旅。 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理# 我们的第一个模块，会为大家介绍数学的线索，也就是它从猜想到定理再到应用的整个过程。我会以毕达哥拉斯定理为例来展开。 ... &emsp;&emsp;勾股定理大家都不陌生，它讲的是直角三角形两条直角边的平方之和等于斜边的平方。 但是，这个定理在国外都被称为毕达哥拉斯定理。毕达哥拉斯（Pythagoras，约公元前580年—约公元前500年）是古希腊著名的数学家和知识的集大成者。 相关阅读：《科技史纲60讲》15｜为什么其他文明没有诞生古希腊的科学？ 接下来有两个疑点，你的中学老师可能在刻意回避或者说没有讲清楚，而它们又实在太重要了。 第一个疑点：这个定理是否在毕达哥拉斯之前就被发现了？ 我们过去的教科书里讲，据汉朝的数学书《周髀算经》的记载，早在公元前1000年的时候，周公和商高这两个人就谈到了“勾三股四弦五”。他们的年代比毕达哥拉斯早，因此教科书中讲是中国人商高最早提出这个定理的，于是称之为勾股定理或者商高定理。 我们先不说《周髀算经》里所记载是否靠谱，就算靠谱，它也只是记载了一组勾股数（即直角三角形直角边和斜边都是整数的情况），并不能说明发现了其中的规律。因为比周公和商高早1500年，古埃及人在建造大金字塔时就已经按照勾股数在设计墓室的尺寸了。 如果再往前推，美索不达米亚人早在公元前18世纪左右就知道很多组的勾股数（包括勾三股四弦五），而且留下了实物证据。比如耶鲁大学的博物馆里就保存了一块记满勾股数的泥板。 接下来就产生了第二个疑点，古埃及和美索不达米亚为什么不去争夺这个定理的发现权呢？ 简单地讲，所有这些古代文明不过是举出了一些特例而已，甚至没有提出假说。我们在后面的课程中会看到，很多时候特例中反映出的规律和后来真正的定理可能是不同的。所以，这种特例就没有意义。 如果像美索不达米亚人那样举了很多特例，而且没有发现例外，是否可以认为他们最先发现这个定理呢？答案是否定的，因为光举例子还是不够的，还需要做出一个明确的规律性的描述，这种描述我们可以把它称为命题。 一个命题在没有证明之前，只能算是猜想，比如著名的哥德巴赫猜想。而总结出一个猜想和证明定理依然是两回事，当然这是比举几个例子进了一大步了。 再接下来，猜想如何证实呢？在这一点上数学和自然科学完全不同。那么我们就要说到数学和自然科学的三个本质差别，也是这一讲最重要的三个知识点，它们能够帮助我们理解数学特殊的方法和思维方式，或者说了解数学的推理世界与我们真实的测量世界的区别。 1.测量和逻辑推理的区别 我们知道几何学源于古埃及，当地人出于农业生产的考虑，对天文和土地进行度量，发明了几何学。但是，度量出来的几何其实和真正的数学还有很大的差距。 比如说，古代文明的人们确实观察到勾股数的现象，他们画一个直角三角形，勾三尺长、股四尺长时，弦长恰好就是五尺长，于是就有了勾三股四弦五的说法。 但是这里面存在一个大问题，我们说长度是三尺，其实并非数学上准确的长度，用尺子量出来的3，可能是3.01，也可能是2.99。这样一来勾三股四弦五就是一个比较模糊的说法了。 为了让你更好地理解这一点，我们不妨看这样一个例子。 图中左上方有一个8x8的方格，它的面积是64，这没有疑问吧？我按照图中所示的粗线将它剪成四部分，两黄两灰，再重新组合，就得到了一个13x5的长方形，它的面积是65。请问面积是64的正方形怎么重新组合一下面积就多出1，变成65了呢？ 当然我们知道64不等于65，这里面一定有问题。那么问题在哪儿呢？其实，问题就出在再拼接时，它们并不是严丝合缝的，只不过缝隙较小，大部分人看不出来罢了。 在数学上，观察的经验可以给我们启发，但是它不能成为我们得到数学结论的依据，数学上的结论只能从定义和公理出发，使用逻辑严格证明得到，不能通过经验总结出来。 讲回到勾股定理，一个工匠注意到勾三股四弦五这个现象，和提出一个具有普遍意义的定理是两回事。 我们通过观察还可以发现，如果勾3.5，股4.5，那么弦大约是5.7，这个“大约”的误差只有万分之一点六左右（弦长大约是5.700887），古代任何测量都发现不了。这时如果你说勾3.5股4.5弦5.7，从物理上来说基本正确，但是在数学上就错了。这是第一个差别，就是测量会出错，但推理不会。 那么，如果我们抛开误差的影响，是否可以认为早期文明的人们发现了勾股定理呢？也不能，只能说他们观察到一些现象，而非发现了定理。这涉及到数学和自然科学的第二个主要区别，证实和证明的区别了。 2.用事实证实和用逻辑证明的区别 在自然科学中，一个假说通过实验证实，就变成了定律。比如说与牛顿同时代英国的大科学家波义耳同法国科学家马略特一同发现：一个封闭容器中气体的压强和体积成反比。这很好理解，因为体积压得越小，内部的压强肯定越大。这两个人通过很多实验，都证实了这件事，于是这个定律就由他们两个人的名字命名了。 但是，如果有一个非常爱较真的人一定要抬杠，说你们证实了所有的情况（各种体积和压强的组合）吗，你们敢保证没有例外么？波义耳和马略特肯定会说，我们不敢保证没有例外，但是这个规律你平时使用肯定没有问题。 果然，后来人们真的发现当压强特别大时，这个定律就不管用了。但是没有关系，在大多数条件下，这个定理依然成立，今天人们在做产品时，依然可以用。 事实上，今天几乎所有的自然科学的定律和理论，不仅存在一个被推翻的可能性，而且有很多的例外。比如，证实引力波的实验，也只能保证99.9999%的可能性结论是对的。 但是，在数学上，用实验来验证一个假说（在数学上常常被称为猜想）是不被允许的，我们在后面介绍无穷大时，大家还会看到这甚至是做不到的。数学的结论只能从逻辑出发，通过归纳或者演绎得出来。它必须完全正确，没有例外，因为但凡有一个例外（也被称为反例），就要被完全否定掉。这里面最著名的例子就是哥德巴赫猜想。 今天人们利用计算机，在可以验证的范围内，都验证了这个猜想是对的，但是因为没有穷尽所有的可能，就不能说猜想被证明了。因此，我们依然不能在这个基础上，构建其它的数学定理。 所以，数学世界和测量世界第二个区别就是，数学理论必须要证明，保证没有例外。 3.科学结论相对性和数学结论绝对性的区别 为什么数学要那么严格，它的定理为什么不能有任何例外，更不能特殊情况特殊处理呢？因为数学上的每一个定理都是一块基石，后人需要在此基础上往前走，试图建立一块新的基石，然后数学的大厦就一点点建成了。在这个过程中不能有丝毫的缺陷，一旦有，整个数学大厦就轰然倒塌了。 还是以勾股定理为例，它的确立，其实教会了人们在平面计算距离的方法，在此基础之上，三角学才得以建立，笛卡尔的解析几何才得以确立，再往上才能建立起微积分等数学工具。此外我们这个模块后面会讲到的无理数的出现、黄金分割，都和它有关。 人类今天发明的各种科技，像无线通信、航天等等，依赖于这些定理。如果出现了一个违反毕达哥拉斯定理的反例，不仅是这个定理失效了，而且整个数学就完蛋了，我们的科技也就时灵时不灵了。因此，数学上的每一个定理，必须也只能通过逻辑推演来证明，用多少实例来验证都没有用。 理解了数学定理确立的过程，以及它随后产生的巨大影响，我们就清楚定理和定理证明在数学中的重要性了。正是因为这个原因，西方才将这个定理命名为毕达哥拉斯定理，以彰显他的贡献。是他明确提出这个定理，并且严格地证明了它，从此毕达哥拉斯定理才成为了数学上普遍的规律。 有了一个个的定理，数学就得以建立起来，而且这个建立在逻辑推理基础上的大厦很坚固。在数学上，当一个新的定理被证明后，就会产生很多自然的推论，每一个推论可能都是一个重大的发现，甚至能带来人类认识的升级。毕达哥拉斯定理的一个直接推论，就是无理数的存在。这个内容我们下一讲再讲。 要点总结： 数学和自然科学不同，它不相信测量，不是建立在实证基础之上，而是建立在逻辑基础之上的。数学也不接受大部分情况正确，但是包含例外的定理。这样整个数学大厦的基础才得以稳固。 数学定理确立的过程大致是这样的，一开始可能只是大家注意到几个特例，然后发现很多例证提出猜想，猜想经过证明就成为了定理，定理会有推论，在此基础上，会有新的定理和应用。 思考题： 在物理学中，从不同的角度理解光，会得到粒子说和波动说两种解释，数学从两个角度证明一个定理，会不会得到不同的结论？ 03 ｜ 数学的预见性：如何用推理走出认知盲区# 上一讲，我们通过毕达哥拉斯定理解释了数学的起点，它必须是从逻辑推理和证明得来的，而非测量和实验出来的。我们这一讲就看看以毕达哥拉斯定理为起点出发，人们又发现了什么。 ... &emsp;&emsp;在古希腊毕达哥拉斯（Pythagoras，约公元前580年—约公元前500年）所处的时代，人们认识到的数学上的数字都是有理数，它们都有我们平时所说的分数，具有A/B这样的形式，比如2/3，其中A和B都是整数，当然，整数本身可以被看成分母等于1的分数，比如5=5/1。 毕达哥拉斯有一个很怪的想法，他坚信世界的本源是数字，而数字必须是完美的。整数很完美，而且分数的分子分母也都是整数，不会是零碎的，因此也很完美，整数和分数所构成的有理数让毕达哥拉斯一直坚信自己的想法。 但是，一旦毕达哥拉斯定理被他证明以后，麻烦就来了。 我们上一讲讲过，数学的定理具有永真的特点，它一旦被证明，你就找不到反例。当人们在用毕达哥拉斯定理时，就发现了问题。假设某一个直角三角形的两条直角边长都是1，那么斜边该是多少呢？ 你可以根据毕达哥拉斯定理算一下，既然两条直角边都是1，它们各自的平方也是1，加起来是2，因此斜边的平方是2，这个斜边就是一个自己乘以自己等于2的数字，从大小来看，它应该在1和2之间。接下来请问，这个自己乘以自己等于2的数字是否是“完美”的有理数？ 根据毕达哥拉斯对所有的数字都是有理数的认识，它必须是啊！好，我们就假定存在一个数字是R，它能够写成R=A/B的形式，其中A、B都是互素的整数（互素指的是两个数写成分数的形式，不可再约分），那么现在假设这个数字R的平方恰好等于2。注意一下，这里面有三个条件，请一定牢记： A、B都是整数。 A、B互素，也就是不能再约分了。 A/B的平方等于2。 这三个条件能否同时满足呢？答案是不能。为了说明这一点，大家不妨跟着我做一个简单的逻辑训练。 好，这次我们用的方法，在数学上被称为反证法，就是先假定你说的条件都满足，然后我来找出矛盾之处，这样就能推翻原来的假设。 具体到上面这个问题，我们从上面第三个条件出发，就得知分子A的平方除以分母B的平方等于2： $ A^{2} / B^{2} = 2 $ 我们把B的平方移到等式的右边2那边，就是： $ A^{2} = 2 \times B^{2} $ 接下来我来问你，A是奇数还是偶数？你会说它当然是偶数，因为等式的右边是2乘以B的平方，都乘以2了，那A的平方结果肯定是偶数，奇数的平方不可能是偶数，所以A必须是偶数啊。既然A是偶数，我可以把A写成2乘以一个数，比如C，也就是A=2C这种形式，其中C是一个整数。 那么A的平方等于什么呢，等于4倍的C的平方，我就用这个4倍的C的平方代替A的平方，放在原来等式的左边，右边还是2乘以B的平方： $ 4 \times C^{2} = 2 \times B^{2} $ 这个等式的两边都可以用2去同时除一下，于是就成了两倍的C的平方等于B的平方： $ 2 \times C^{2} = B^{2} $ 这时我问你，B是偶数还是奇数？你会说当然是偶数，因为两倍的C的平方是偶数啊。 这下子问题来了，怎么A和B都是偶数呢，这不就和上面的第二个条件，也就是“A、B互素，不能再约分”矛盾了吗？ 那么到底哪里发生了错误呢？我们先要检查一下我们的推导过程，我们发现没有错误。因此，要么是数学错了，要么是认知错了。勾股定理的证明是通过严格的逻辑推导出来的，也不会有错，于是只能是我们的认知错了。 也就是说，存在一种数字，我们过去没有认识到，它们无法写成有理数的形式，即A/B，它们是无限的不循环小数，在这样的数中有一个自己乘以自己时等于2。我们今天把这个数字称为√2。这一类的数字其实很多，它们被统称为无理数。 据说毕达哥拉斯的学生希帕索斯最初发现了上述矛盾，于是就去和他的老师讲了。而毕达哥拉斯是个把数学看成宗教的人，出现无限的不循环小数在毕达哥拉斯看来是数学的漏洞，但他又无法把这件事解释圆满，这就是数学史上的第一次危机。 毕达哥拉斯决定把这位学生扔到海里杀死，好把这件事隐瞒下来。 当然，像√2这样的“无理数”存在的事实，却不可能一扔了之，无理数是客观存在的，毕达哥拉斯是隐瞒不住的，这件事成为了这位确立了数学在人类知识体系中地位的大学问家的一个污点。 另一方面，无理数的危机也带来了数学思想一次大的飞跃，它告诉人们，人类在对数字的认识上还具有局限性，需要有新的思想和理论来解释，认识本身不能有禁区，那些事先为科学设定的条条框框，最终都不得不被抛弃掉。 从这个例子中，我们能学到什么呢？ 首先，在遇到数学和现实的矛盾时，我们需要仔细检查推理的过程是否有疏漏，这种情况占大多数。 在排除了推导的错误后，接下来，两种情况必居其一： 要么，我们的眼睛和我们的认知欺骗了我们，就如同我们以为所有的数都是有理数，但其实不是。这是常有的事情。 要么，最初的假设错了或者说不够好。这种事情在历史上偶尔发生过，但是很少，我们后面在介绍非欧几何时会仔细讲到这种情况。这种情况我们通常不需要考虑。 既然在推导没有错误时，通常是我们的观察或者认知欺骗了我们，那么我们就应该把危机看成是转机。人类在科技历史上，很多重大的发明发现恰恰来自于上述的矛盾。 在数学史上，除了无理数被发现之外，几个重大的事件，比如无穷小概念的提出，对无穷大的重新认识，以及公理化集合论的确立，都和那些矛盾有关。这些矛盾有时看似造成了数学危机，但是，人们化解了危机之后，就拓展了认知，建立起新的理论。它们或者让数学本身进步了，或者在科学上做出重大的预言。 几年前约翰·霍普金斯大学的天体物理学家亚当·里斯（Adam Riess）教授给我讲的一堂课，我至今记忆犹深，他让我坚信了对数学本身的信心。里斯等人通过计算，发现宇宙的质量是负数，这怎么可能？难道是数学错了，还是我们对宇宙的理解完全错了？ 里斯在做了仔细的检查后首先排除了推理有误的可能性，然后他们不得不承认数学的结论是对的，出错的是我们眼睛（包括观测的仪器）。于是，他们认定宇宙中一定存在我们看不见，更不了解的东西，那些就是所谓的暗能量，亚当·里斯等人后来因此获得了诺贝尔奖。 在自然科学上，很多重大的发现，最初都不是直接和间接观测到的，而是根据数学推导出来的，比如说黑洞、引力波便是如此。在历史上，血液循环论、现代原子论最初都是建立在数学推导上的假说，然后才逐渐被实验验证了。 世界上有很多我们不能依靠直觉和生活经验理解的事物，但是我们可以从数学出发，经过一步步推导得到正确的结论，我们甚至不需要亲力亲为地做一遍就知道我们的结论一定是正确的。这就如同你不需要会踢足球，才能评论足球一样，你只需要把握住一些准则就可以了，而数学就是这样的准则。 要点总结： 从数学的定理出发，可以推导出很多针对现实世界的推论，从而改变我们对现实世界的看法，这就是数学的预见性。比如，毕达哥拉斯定理的一个直接结果指出了无理数的存在，它把人类对于数字的认识范围从有理数扩展到了无理数。 当然，可能有读者朋友会想，那些预见性可能和我们相去甚远，其实不然，后面我们会举一些和大家相关的例子，比如如何识破庞氏骗局，为什么不能做空股票，等等。 康德讲：“世界上只有两样东西是值得我们深深景仰的，一个是我们头上的灿烂星空，另一个是我们内心的崇高道德法则。”他所说的星空，其实包括数学这样的知识体系。对于很多云山雾罩的事情，我们只需要在逻辑上推演一遍，就能把问题的真相搞清楚了。 思考题： 我们都知道，整体要大于部分，因此10厘米长的线段上的点应该比5厘米长的多，但是如果我能用严格的逻辑证明它们上面的点一样多，你相信么？ 欢迎给我留言，并把文章分享出去，让更多的人感受到数学之美。我们下一讲再见。 04 ｜ 数学思维：数学家如何从逻辑出发想问题# 这一讲就来举一个发生在我们身边的例子，说明如何利用数学原理思考问题，并且久而久之在遇事时本能地用一个数学的头脑辅助判断。 ... &emsp;&emsp;当然，数学思维高深精妙，但是万法归一，最重要的那个原则就是，从逻辑出发想问题，这样就可以发现很多日常中被忽略的问题，从而找出真正答案。 我们先从最近的一次金融危机讲起。在金融危机之后，英国女王问全世界的经济学家们，你们这么多人怎么没有一个预测到金融危机？这让学者们都很没面子。 经济学家们当时确实是过于乐观了，所以很多暂时不会出问题的隐患被隐瞒了下来，因此大家会觉得没问题。不过当时有一些其实并不懂经济学的人，利用特殊的方法，嗅出了问题。 比如巴菲特从直觉出发，觉得那些金融衍生品刻意包装，一定是为了掩盖很多真相，坚决不参与那场赌博。像这样的投资人并不少，其中最著名的是一个叫贝尔（Michael Burry）的医生，他数学很好，而且雇了一些数学家替他做事，靠坚守数学上的一些基本道理，成为那场豪赌中获利最丰厚的赢家。 贝尔他们的逻辑其实很简单，就是我们常常说“复利”增长从数学上讲是无法长期为继的。比如说，财富每年增长7%，这个速度在很多人看来并不算快，但是如果两千多年前的陶朱公以及他的后人能维持这个财富增长速度，哪怕当年他只留下一个铜板，今天他的传人所拥有的铜钱的数量要超过宇宙中的原子的数量，这在现实中当然不可能。 做投资的人都清楚，在一开始投资基数较小的时候，能够维持指数增长，一旦基数变大，就做不到了，还不切实际地想维持，就是拆东墙补西墙的庞氏骗局了。 很多人觉得自己足够聪明不会上庞氏骗局的当。但是变相的庞氏骗局要识破就没那么容易了。2008年金融危机中的罪魁祸首CDS，就是奸商们包装的一个不容易看懂的庞氏骗局，接下来我们就来说说它。 我们知道2008年金融危机的原因是美国房屋的次级贷款出了大问题，那它和CDS有什么关系呢？别着急，我们从次级贷款说起，然后你就明白什么是CDS了。 让我们先回到克林顿当总统的时代。那时，克林顿政府为了让本来付不起首付的穷人也能买房子，允许银行提供购房首付的贷款。比如100万的房子，通常需要贷款80万，首付20万，但是假如有一个人叫林肯，他没钱支付首付，当时除了允许他把房子先抵押了，从A银行获得正常的80万贷款，还允许他以较高的利息从B银行获得首付20万的贷款。 如果房价一直上涨，这没有问题，因为即使林肯付不起月供了，A银行也可以通过变卖房子收回自己的80万贷款，剩余的钱，还够B银行也能拿回自己的20万。B银行提供的就是次级贷款，由于它的风险显然比A银行大，因此利率也高，这样如果有个别几个人的贷款拿不回，它也能从其他购房者偿还的利息中填补漏洞。 当然，B银行还有一个更稳妥的做法，就是从高利息（比如每年10%）中拿出一部分（比如1%），向C保险公司购买贷款者违约的保险。 保险公司C根据历史数据发现房屋贷款收不回来的情况很少，只占房贷的2%左右，而它从B银行可以连续挣15年的钱（不考虑复利的因素），15年下来，担保10亿的房产就能收入1.5亿，成本只有2000万，这利润率高达650%的事情保险公司自然就答应了。 接下来，投资银行D看到C公司做了这样一笔好买卖，非常眼红，就和C商量将这10亿美元的保险生意卖给自己，并愿意留给C公司20%的好处，即3000万美元。C公司想，1.5亿虽然多，但是要承担15年的保险义务，不如一次性得到3000万实在，就答应了。 D公司是投资银行，更精明，将C公司为B银行作担保的业务，包装成证券，叫做CDS（信用违约交换），加价3000万美元卖给了另一家投资银行E。E公司可能将各种类似的CDS又打了一个包，以新的证券形式在市场上市了。 就这样，在经过无数次包装后，CDS的内部结构大部分人已经看不懂了，但是人们总觉得自己可以从下家身上赚到钱。于是一同把CDS炒到了50万亿美元这么大的规模，这甚至超过当时美国房市本身的总值。 这个骗局的本质是什么呢？就是大家炒来炒去，都是在赌一件事，就是今后15~30年，房价会一直快速上涨。 然而，房价不可能永远快速上涨，特别是在经济本身没有上涨的前提下。一旦有大量房主还不上钱，或者不愿意还钱，这些CDS就变得一钱不值。更糟糕的是，给购房者提供次级贷款的银行，后面的保险公司以及很多购买了CDS的投资银行也都完蛋了，整个金融体制就垮了。 这件事可以通过数学算出来，其实不只是刚才提到的贝尔，当时有不少人在CDS的骗局破灭之前，发现了问题，后来挣到了大笔的钱。只不过贝尔挣钱的比例太高，他的故事后来被拍成了电影《大空头》，他从此成为了名人。 接下来我们就说说什么叫做具有数学的思维。它不是指算小账算得清楚，而是说善于基于数学知识，使用逻辑发现问题，或者预见到不得不做的事情。我们在生活中，有时不得不面对非常复杂的问题，里面有很多噪音难以一一滤出，这时就需要掌握一种工具让我们能够不受噪音影响作出正确的判断。而数学常常是我们可以信赖的工具。 下面我和你分享一个我的经历。有一次在一个由政府组织的关于“一带一路”的座谈会上，几位领导问我，“吴教授，咱们关起门来讲，中国输出了那么多资本，最后钱能回来么？” 我说，挣得回来，挣不回来，我不知道，因为这里面牵扯太多的因素。但是资本输出和帮助其它国家富裕这两件事都必须做，我可以从数学证明这两件事的必要性。他们很好奇这件事和数学有什么关系，于是我继续讲： 中国在过去的四十年里，实现了每年8%的指数增长，除了中国人勤劳勇敢。另外有两个数学上的原因，一是因为最初的基数小，能够持续高速增长。二是过去国内市场空白一片，供不应求，国际上其它国家人均财富，比中国高很多，相比中国过去的生产能力，购买力近乎无限。 但是40年后的今天，中国人均GDP已经达到了世界的平均水平，总的经济体量已经世界第二，占全世界的18%。那么中国还能不能维持过去的增长速度呢？从数学上讲，根本做不到。 我们就假定中国经济能够按照每年6%的速度增长，这个速度虽然比过去慢了一点，但是比全世界3%的平均水平快很多。再过40年，中国GDP大约能增长10倍。而全世界经济增长的速度只有3%左右，再扣除中国的贡献，中国以外的国家和地区的增速只有2.34%左右，这样增长40年，只能增长1.5倍左右，那时中国GDP大约占到全世界50%。 这时候矛盾就出现了，中国以外有全世界4/5以上的人口，总的财富仅仅和中国一样多。那时，全世界都没有足够的财富买得起中国不断制造的产品和不断提供的服务。这时只有两个办法，一个是提高世界其它地区的购买力和经济增长，另一个是让中国经济增长降到世界的平均水平。 后者显然不是我们想要的，于是借钱给其它国家购买中国的产品和服务，当然中国可以换得一些战略资源，同时让世界其它国家也维持足够高的经济增长，以便它们能维持购买力，并且还得起钱，就是中国不得不做的事情了。而这就是“一带一路”要实现的目标。至于投资和贷款能否拿得回来，那要看操作的水平了。 在历史上，19世纪的英国，二战后的美国，以及80年代的日本，都是资本输出国，因为你不输出资本，大家就买不起你的东西，而你也就无法维持体面的经济增长。中国10年前不提“一带一路”的事情，一是因为还没有必要性，二是因为自己的钱不多；近几年才提出，是因为今天中国正好从处在人均GDP低于世界平均水平到变成高于平均水平的转折点上。因此在商业和资本两个层面全球化就变得迫在眉睫了。 我们在生活中，常常说“算笔账”这三个字。其背后其实就是说基于一些事实，用数学这个工具来考量，发现问题。为什么数学思维可以很容易地发现问题呢？因为我们常常用到在数学证明中的工具：矛盾律。 就是说一个事物不能既有A属性，又没有A属性。比如我们上一讲在证明√2是无理数时说到，如果它是有理数P/Q，那么P和Q这两个整数，既不能同时是素数，又必须同时是偶数，这就违背了矛盾律。同样，中国既不可能拥有全世界所有的财富，还让世界其它地区买得起中国的商品，这也违背了矛盾律。 要点总结： 通过数学的思维方式，发现生活中的问题，看清我们必须采取的行动，这就是学习数学的意义所在。这既可以被看成是认知的升级，也可以被认为是掌握了数学原理之后的灵活应用。 当然，数学有很多它做不到的事情，下一讲我们进一步讲讲数学思维的边界。 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理# 我们前面讲了数学的预见性，以及数学思维的用处，但是这讲我想和你谈谈数学的局限性，大家可能会有一个疑问，就是这种局限性是来自于我们自己的数学知识不够，还是来源于数学本身的局限性呢？ ... &emsp;&emsp;应该讲这两方面的原因都有，第一部分因素在大家听完这门课后会补上很多，不用担心；第二部分则是我们这一讲要讲的内容。我们有必要了解数学本身的局限性，才能更好地使用它的原理和思维方式。今天我们还是从毕达哥拉斯定理的推广说起。 在几何上有很多整数组满足毕达哥拉斯定理，它们就是勾股数，比如（3，4，5），（5，12，13）等。从代数上解释勾股数，就是方程 $ a{2}+b{2}=c^{2} $ 的整数解。 当然，人类总是很好奇，人们就在想，如果上面方程中的平方变成立方，甚至任意N次方，它还有整数解吗？比如，是否有三个整数a，b，c，使得，$ a{3}+b{3}=c^3 $ ？ 这个问题困扰了人类几千年。后来有一个叫费马的数学爱好者就提出一个假说，说除了平方的情况，其他更高次方的方程都找不到整数解，它被称为费马大定理（或者费马最后定理）。 虽然它被称为定理，但数学家们只是把它看成是猜想，或者假说，因为没有证明。我们前面讲到，猜想，哪怕用很多数据验证过了，只要没有证明，就无法成为数学大厦中的一块砖，就无法在它的基础上搭建新的东西。 因此，在费马之后的几百年里，很多数学家都试图证明它，但是都不得要领。费马自己说他已经证明了这个定理，只是那张纸不够大写不下，但后人认为是费马搞错了。 于是费马大定理就成了一道跨越了三个多世纪的超级难题。直到1994年，才由著名的英国旅美数学家怀尔斯证明出来，而这个过程也是一波三折。 1986年，怀尔斯在做了十多年的准备后，觉得证明费马大定理的时间成熟了，终于决定将全部精力投入到该定理的证明上了。为了确保别人不受他的启发率先证明了这个著名的定理，他决定在证明出这个定理以前不发表任何关键性的论文。 但是，如果一个人苦思冥想，推导的逻辑错了自己也看不出来，为了避免这种情况的发生，怀尔斯利用在普林斯顿大学教课的机会，不断地将自己部分的想法作为课程的内容讲出来，让博士生们来挑错。 1993年6月底，怀尔斯觉得自己准备好了，便回到他的故乡英国剑桥，在剑桥大学著名的牛顿研究所举行三场报告会。为了产生爆炸性的新闻效果，怀尔斯甚至没有预告报告会的真实目的。因此，前两场报告其实人不多，但是这两场报告之后，大家都明白接下来他要证明费马大定理了。 于是在举行最后一场报告时，牛顿研究所里挤满了人，据估计可能只有1/4的人能听懂讲座，其余的人来这里是为了见证一个历史性的时刻。 很多听众带来了照相机，而研究所所长也事先准备好了一瓶香槟酒。当怀尔斯写完费马大定理的证明时，很平静地说道：“我想我就在这里结束”，会场上爆发出一阵持久的鼓掌声。这场报告会被誉为了20世纪该研究所最重要的报告会。 不过故事到此并没有结束，数学家们在检查怀尔斯长达170页证明的逻辑之后，发现了一个小漏洞。怀尔斯开始认为这个小漏洞很快能补上，但是后来才发现这个小漏洞会颠覆整个证明的过程。 怀尔斯又独立地工作了半年，但毫无进展，在他准备放弃之前，向普林斯顿大学的另一个数学家讲述了自己的困境。对方告诉他，他需要一位信得过的，可以讨论问题的助手帮忙。 经过一段时间的考虑和物色，怀尔斯请了剑桥大学年轻的数学家泰勒来一同工作，最后在泰勒的帮助下怀尔斯补上了那个小漏洞。由于有了上一次带有乌龙性质的经历，怀尔斯这次有点怀疑自己是在做梦。于是他到外面转了20分钟，发现自己没有在做梦，这才喜出望外。 由于怀尔斯在证明这个定理时已经超过了40岁，无法获得菲尔兹奖，因此国际数学大会破例给他颁发了一个特别贡献奖，这也是迄今为止唯一一个特别贡献奖。关于费马大定理证明过程的更多细节，大家可以听罗辑思维的第85期节目。 那么证明这个古老的数学难题有什么意义呢？这个定理证明过程本身导致了很多数学研究成果的出现，特别是对于椭圆方程的研究。今天区块链技术用到的椭圆加密方法，就是以它为基础的。 在怀尔斯之前，有一批数学家，特别是日本的谷山丰，对这一系列理论做出了重大的贡献，怀尔斯的成功是在他们的工作基础之上的。今天的比特币可以讲完全是谷山丰理论的一次有意义的应用。而在怀尔斯之后，泰勒等人还在不断发展这方面的理论。 对于三个世纪数学家们证明费马大定理的过程，我和大家分享我的三点体会： 今天的数学（指纯粹数学，不是应用数学）真的很难，想在这方面取得突破性贡献不容易，怀尔斯从10岁开始就立志解决这个问题，他努力了30年。他最后的证明长达200页。但是，有了理论，使用它做有意义的事情，还是容易得多。比特币就是一个很好的例子。 数学是世界上最严密的知识体系，任何的推导不能有丝毫的纰漏。怀尔斯差点因为一个小的疏忽毁掉了整个工作，希望通过这一点，大家对数学的严密性有所体会。 数学走到今天这一步，是在一个个定理的基础上一点点搭建起来的，而今天的成就，又为明天的发展奠定了基础，这样数学就获得了可叠加的进步。 毕达哥拉斯定理是，a的平方+b的平方=c的平方的情形。费马大定理是，a的N次方+b的N次方=c的N次方的情形。因此，前者是起点，后者是一个普遍情况的延伸。接下来，如果我们沿着毕达哥拉斯定理和费马大定理继续往前拓展，会是什么情况呢？ 比如任意一个多项式方程 $ 2x^{2} + 3 y^{3} = z^{4} $ ，或者 $ x^{2} + 3 y^{3} - w^{5} = z^{4} $ ，请问它们有没有整数解？这个问题就是著名的希尔伯特第十问题（简称第十问题）。 对于任意一个多项式方程，我们能否在有限步内，判定它是否有解？ 对于一些特例，我们知道有整数解，比如 $ x^{2} + y^{2} = z^{2} $ 就有；对于另一些特例，我们知道没有整数解，比如费马大定理所描述的情况。 但是，对于更多的，一般性的不确定方程，我们不仅不知道怎么解，甚至无法判断一个方程有没有整数解。因此，1900年在巴黎举行的国际数学大会上，希尔伯特在提出23个著名的数学问题时，把它列为了第十个。 第十问题其实隐含了一个更为深刻的认识论问题，就是对于大部分数学问题，我们能否找到答案？到目前为止，我们所能解决的数学问题其实只是所有数学问题中很小的一部分。 当然，很多人会说尚未找到答案不等于没有答案。第十问题实际上在直接挑战数学的边界，也就是说，通过数学的方法，我们可能根本无法判断一些问题的答案存在与否。如果连答案是否存在都不知道，就更不用说通过数学的方法解决它们了。 这样就为数学划定了一个明确的边界。从1900年之后，特别是在二战之后，欧美不少数学家致力于解决这个问题，因为这也涉及到计算机所能处理问题的边界。 第十问题的解决颇具戏剧性。在上个世纪60年代，被认为最可能解决这个难题的是美国著名的女数学家朱莉娅·罗宾逊，她从博士一毕业就致力于研究这个问题，也取得了很多突破性的进展。 虽然罗宾逊因为这方面的贡献成为了美国科学院第一位女院士，美国数学学会第一位女会长，她离解决这个问题最终还是差几步。1970年，俄罗斯天才的数学家尤里·马季亚谢维奇在大学毕业后一年就解决了这个问题，证明了这类问题是无解的，从此在世界上一举成名。 纯数学这个学科除了需要一些运气之外，比拼的是人的智力，智力到哪个程度，成就就到哪个水平，这倒不是宿命论，而是说明人要根据自己的特长选择做事。 第十问题的解决其实扑灭了人类的一丝希望，但是也让人类老老实实地在边界内做事情。人类过去常常希望找到一个工程问题的解析解，即答案是以一个公式的形式存在，这样套入任何数字，就得到了具体的答案。 但是，很多问题最后证明找不到严格推导出来的解析解，当然这也不妨碍大家在工程上可以使用近似的数值解，解决实际问题。认清这一点，做事的方法也就改变了。 搞流体力学和控制理论的人都知道，那里面有很多复杂的非线性方程要解决。在上个世纪，美苏两国走了两条不同的道路。前苏联因为数学水平较高，而计算机技术很落后，因此他们习惯于下硬功夫做很难的数学题，找到非线性问题的解析解。 而在美国方面，数学水平高的人没有前苏联多，但是计算机技术先进，因此他们习惯于把很麻烦的非线性问题变成很多计算量大，但是却很简单的线性问题（或者其它数值计算问题），找到工程上能接受的近似解。 那么谁取得的效果好呢？从结果来看，美国似乎更好些。关于什么是线性方程，我们后面会讲到，这里大家记住线性方程简单，非线性方程非常复杂即可。 要点总结： 我们介绍了费马大定理的来龙去脉，它往前和毕达哥拉斯定理的关系，往后和希尔伯特第十问题的关系。我也和大家分享了我对这个定理被证明过程的体会。 我们通过希尔伯特第十问题介绍了数学的边界，这是一个硬的边界，大家不要试图逾越。但是数学的边界有些时候不是我们解决问题的边界，因为世界上除了数学的方法，还有其他方法。 到目前为止，我们以毕达哥拉斯定理的产生和发展为线索，介绍了数学猜想到数学公理的推导过程，接下来的两讲，我们还是以毕达哥拉斯这个人为线索，谈谈数学的应用，以及在其它知识体系中的位置。 我们下一讲再见。 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学# 今天大家对毕达哥拉斯的了解，除了勾股定理，还有就是黄金分割。而他用数学指导艺术和音乐，也确立了数学在其它知识体系和人类文明成就中的中心地位。这一讲，我们就从黄金分割出发，进一步理解数学的用途。这个用途不仅仅是在思维方面，也能实实在在指导我们的工作。 ... &emsp;&emsp;我们先来看一张照片，感受一下黄金分割。 这是雅典卫城的帕特农神庙，它无论是在艺术史上，还是建筑史上地位都很高，如果你度量一下它正面的宽与高，正好符合我们所说的黄金分割。 黄金分割大家并不陌生，你可能还会说出它的比例大约是1:0.618，也就是1.618。其实不仅帕特农神庙本身和里面很多雕塑的关键比例符合黄金分割，著名的雕塑《断臂的维纳斯》，它的身高和腿长的比例，腿和上身的比例也都符合黄金分割。符合这个黄金比例的雕塑或建筑就看上去很顺眼，很美观。 那么黄金分割是如何确定的呢，这个比例为什么看起来顺眼呢？简单地讲，它的美感来自几何图形的相似性。 比如我画了一个符合黄金分割的长方形，它的长度是X，宽度是Y。如果我们用剪刀从中剪掉一个边长为Y的正方形（也就是图中灰色的部分），剩下来的长方形，长宽之比依然会符合黄金分割。 当然，我们还可以继续剪掉一个正方形（图中绿色的部分），剩下的长方形（图中透明的部分）的长宽依然会符合黄金分割的比例。也就是说，如果我们这样不断地切下去，剩余部分都是成同一比例的。 黄金分割的这个比例很容易算出来。根据黄金分割上述的相似性质，我们可以很容易算出来X/Y的比例是1.618左右，更精确地讲，是√5加上1之后的和除以2，这是一个无理数，通常用希腊字母Ф来表示。 黄金分割为什么漂亮？除了在几何上层层相似，这个相似性之外，它也反映了自然界的物理学特征。如果我们把刚才图中的长方形不断做切割，然后将每个被切掉的正方形的边用圆弧替代，就得到了这样一个螺旋线。由于这个螺旋线每转动同样的角度，得到的圆弧是等比例的，因此它也被称为等角螺线。如果你对比这个螺旋线和下面的蜗牛壳，是否觉得很相似？ 不仅蜗牛壳如此，龙卷风的性质乃至像银河系这样星系的形状都是如此。需要指出的是，这不是巧合，而是因为任何东西如果从中心出发，同比例放大，必然得到这样的形状。 或许正是因为黄金分割反映了宇宙自身的一个常数，我们对它才特别有亲切感，所以哪个建筑或者画作如果有意无意满足了这个条件，它就显得特别美。除了帕特农神庙，埃菲尔铁塔等建筑的主要尺寸的比例，也正好符合黄金分割，甚至符合等角螺旋线。 类似的，《蒙娜丽莎》的主要结构部分也可以对应一条等角螺旋线。需要说明的是，无论是帕特农神庙的设计者，还是达·芬奇或者埃菲尔，他们都知道黄金分割，并且刻意使用了这个比例。 最先提出黄金分割的人是谁呢？古埃及人似乎早在4500年前就知道了这个比例的存在，因为大金字塔从任何一个面看上去，其正切面的斜边长和金字塔高度之比正好是黄金分割的比例。 当然，没有证据表明他们算出了精确的比例公式，因为他们不知道有无理数存在。 今天一般认为，算出黄金分割公式的还是毕达哥拉斯。虽然相传毕达哥拉斯是在一次听到一个铁匠打铁和谐而动听的声音后，研究出了黄金分割，但是我觉得这种说法缺乏依据。 大家更认可的说法是，毕达哥拉斯学派的人在做正五边形和五角星的图形时，发现了黄金分割的比例。在正五角星中，每一个等腰三角形的斜边和底边的比例都是黄金分割1.618。 我们刚才说毕达哥拉斯还可能是从铁匠的打铁声中获得了黄金分割的启发，但是无从考证，不过毕达哥拉斯学派利用数学指导音乐是真实的事情。毕达哥拉斯认为，要产生让人愉快的音乐，就不能随机在连续的音调中选择音阶，而需要根据数学上的比例设计： 首先，人们发现两根琴弦，如果它们的长度比是2:1，它们所奏出来的音节就相差一个8度，如果我们用简谱来记录，也就是1-2-3-4-5-6-7-i，高音1的音高是中音1的两倍。在这一个8度中最高音和最低音的频率之比也就是为2:1。 接下来，将这8度又一分为二，按照4:3和3:2的比例，分出一个4度音和一个5度音，它们分别对应1-2-3-4和4-5-6-7-i。注意，由于4/3 x 3/2 = 2:1，因此一个4度音和一个5度音会还原成一个8度音。 最后，每个4度音分成两个整声调，即分出2和3，5度音分为三个整声调，即分出5，6，7。这样就是按照比例设计的了。 如果不按照比例分配音节是什么结果呢？我们听到的声音就如同噪音，而不是有规律的乐音。今天对耳蜗的解刨学研究发现，耳蜗的形状其实也是螺旋线的，和黄金分割的螺旋线非常吻合。这可能是按照黄金分割设定音律后，声音悦耳的原因。 毕达哥拉斯和他的学派对音乐和美学的影响一直影响到柏拉图和亚里士多德，以及后来诸多文艺复兴的学者。 数学不仅和音乐密切相关，也对建筑和绘画艺术产生了重大的影响。我们看从文艺复兴时期开始，到19世纪浪漫主义时期的西方油画，都会惊叹于它们的逼真。这个逼真的效果从哪里来？它源于艺术家们使用单点透视的方法，成功地将三维形象绘制到一个二维平面上。当然，这个绘画技术不是一天发明的。 其实，早在古希腊时期，人们就发现了远处景物显得小，近处的显得大这样的特点，并且将这种特点反映到绘画中了，他们把这种方法叫做短缩法。但是，古希腊人并不知道物体在离开我们远去时，该遵循什么数学法则进行缩小。 到了文艺复兴时期，佛罗伦萨的画家乌切洛沉溺于使用几何学技术将绘画变得逼真，在他为美第奇家族绘制的《圣罗马诺之战》中，我们可以看到明显采用透视法炫技的痕迹。 大家可以仔细看看地上倒下的战士和旁边的长矛，都指向远方的消失点。他用透视法为绘画构建了立体的舞台。不过，如果你仔细看，会觉得这幅画中有不少别扭的地方，因为这幅画好像不止一个透视的方向。 那么是谁真正解决了透视法中的数学问题，并且将这种技巧给予了广大艺术家的呢？他是文艺复兴时期大名鼎鼎的建筑师和工程师布鲁内莱斯基，今天佛罗伦萨的圣母百花大教堂就是他的杰作。关于这座在建筑史上划时代建筑的建造过程，我们在《科技史纲60讲》中已经介绍了，这里就不再赘述了。 布鲁内莱斯基所发明的单点透视法，完全符合我们视觉应有的几何学原理，具体讲就是相似三角形的原理，因此按照这样的方法画出来的画就非常逼真。下面我们就从视觉中的几何学原理出发，简单介绍一下单点透视法。 假定我们前方100米和500米处各有一棵大树，它们都是50米高。我们知道近处的树在我们的眼睛里显得高，远处的显得小。那么看起来，它们的比例到底该是几比几呢？简单地讲，就是应该和距离成反比，即100米处50米高的树，放到500米处，应该显得只有10米高。如果放到无穷远处，则应该是0米高，也就是地平线上的一个点。对于其他的距离，我们看到的高度也是同样和距离成反比。这样，如果我们把各个距离之处50米高的大树连城一条线，就是我们得到的透视的视觉效果了。 下图是我在电视剧《权力的游戏》的外景地（北爱尔兰）拍的照片。从照片可以看出，所有相同大小的景物，按照远近的比例缩小，在远处汇聚到一点。 理解了我们视觉的数学原理，就可以利用它创造出不同的艺术效果。比如在现实世界里，我们看到的是单点透视，因为人的眼睛不可能同时往两边看，但是我们可以在艺术创作中采用两点和多点透视。 下图是两点透视的效果图，景物消失在一左一右两点上。我们通常目光只能集中在一个方向，看不了这么广的视角，但是你如果用鱼眼镜头拍照，就能拍出这样的效果。 我们在今后的课程中，还会讲到，艺术需要数学，也需要光学。印象派绘画的一大特点，就是很好地利用了当时人类在物理上对于色彩和亮度认识的进步。 要点总结： 最后总结一下今天的内容，其实我们是在回答数学的用途。 数学和艺术，以及其他的知识体系有着千丝万缕的联系，我们以黄金分割和透视法为例子介绍了这种关系。了解一些基本的数学知识和方法对我们做其他事情有很多好处。当然，有些人会讲，我们学不会那些数学上的道理啊，没关系，有些方法你只要记住就好。 我们下一讲就从黄金分割出发，介绍优选法，大家只要掌握它的一些基本原则，就能直接使用了。 07 ｜ 数学应用：华罗庚化繁为简的神来之笔# 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要# 09 ｜ 数列和级数（二）：传销骗局的数学原理# 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密# 模块二 ｜ 数学的概念# 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大# 12 ｜ 三次方程：数学史上的发明权之争# 13 ｜ 虚数：虚构这个工具有什么用# 14 ｜ 无穷：我们为什么难以理解无限的世界？# 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？# 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？# 17 ｜ 无穷小（三）：用动态和极限的眼光看世界# 模块五 ｜ 微积分# 30 ｜ 微积分（上）：如何从宏观变化了解微观趋势# 我们在前面讲到，线性代数和微积分是高等数学中最重要的两门课，前者有很强的实用价值，后者能提高思维水平，虽然大家平时在工作中未必有机会直接使用它。就拿我来说，工作后用线性代数的机会可能是微积分的100倍。 ... 但是，学没学过微积分，思维方式会不同，眼中的世界也会有差别。因此，作为数学通识课，我们还是有必要解释微积分的思想，但是我们也就是停留在它的思想方法上，而非细节上。 微积分有两位主要的发明人，牛顿和莱布尼茨。牛顿发明微积分的一个重要原因是，他需要一个数学工具解决力学问题，比如如何计算速度。可能有人会说，这还不容易，在小学我们就教了，就是距离除以时间。 没有错，我们从小学到中学都是这么教的，但这只是一段时间𝛥t的平均速度。如果我要问你，在某一时刻的瞬间速度是多少？你就不知道了，或者只能拿平均速度来近似瞬间速度。或者说，拿宏观的规律近似微观的。 但是在很多场合，我们要了解的是瞬间速度，而不是平均速度。比如一个警察抓超速，依据的就是驾驶者的瞬间速度，而不是他一路开过来的平均速度。对于瞬间速度，牛顿之前的科学家并没有太多的了解，当然也不会计算了。 那么牛顿是怎么解决这个问题的呢？他采用了无限逼近的方法。具体的想法是这样的： 首先我们回到速度的定义，就是一段时间里的位移量𝛥S除以相应的时间𝛥t，我们可以写成速度v=𝛥S/𝛥t。我把这种关系用一个示意图表示出来： 在左边的图中，横轴是时间轴，纵轴是位移，那条曲线是位移随着时间变化的函数S(t)。我在图中标记了从t0开始的一段时间𝛥t，以及相应的位移量𝛥S，它们构成一个直角三角形的两条直角边。位移量除以时间，就是斜边的斜率。 当时间间隔𝛥t逐渐变小时，这个比值会变化，会越来越反映出在t0点附近的速度。我们在前面介绍了极限的概念，当𝛥t趋近于0时，那条反映速度的斜线，就是曲线在t0点的切线，牛顿就把那个切线的斜率，定义为在t0点的瞬间速度。我们不妨这么写，v(t0)=𝛥S/𝛥t，当𝛥t→0（趋近于0）时。 通过上述方式，牛顿就从平均速度出发，定义了瞬间速度，也就是说，某个时刻的瞬间速度，是这个时刻附近一个无穷小的时间内的平均速度。 如果我们用曲线来考察这种瞬间变化，那么瞬间速度就是距离函数曲线在某个点切线的斜率。由于在每一个时间点，切线的斜率是变化的，因此如果把各个点的切线斜率画出来，它也是一条函数曲线。 牛顿把这个由每个点切线斜率构成的函数，称为原来函数的流数，我们今天称之为导数。通常我们用y=f(x)表示原函数，用y=f’(x)表示它的导数。在上面的例子中，位移的变化函数S(t)是原函数，速度变化的函数v(t)则是原函数的导数，我们可以写成v(t)=S’(t)。 正如同速度反映的是距离的变化速率，一个函数的导数所反映的也是原函数变化的速率，比如在上面的图中，我们可以看出原函数增长越来越慢，因此它的导数，也就是增速，是逐渐下降的。 现在我们回顾一下函数这个概念，它反映的是一个变量随着另一个变量的变化，而导数这个概念，则反映函数变化的快慢。比如抛物线函数y=x^2，它在x=1这个点，导数是2，也就是说x增加一小份（无穷小），y要增加两小份。 相比之下，直线y=x在同一个点的增速就要慢一点，它的导数是1，也就是说x增加一小份，y也增加一小份，因此我们说抛物线在x=1这个点的变化比直线更快。· 对于同一根曲线，我们前后也能对比，比如抛物线在x=2这个点的导数是4，因此我们说，它在x=2时，比x=1时，变化更快。 我们过去也会说，某个函数变化快，某个函数变化慢，但是这些都是宏观的描述，没有量化度量。导数解决了这个问题。我们还说，某个函数，越变越快，这也只是宏观的、定性的分析。 有了导数的概念之后，我们就可以准确地度量任意一个函数在某一个点的变化。因此导数的本质是对变化快慢的准确量化度量。 导数是微积分中最重要的概念之一，从导数出发我们稍微往前走一小步，就进入到微积分的微分了。 什么是微分呢？它其实就是在前面有关速度的例子中，𝛥t趋近于零时，𝛥S的值。对此一般性的函数，我们用dx表示自变量趋于零的情况，用dy表示函数的微分。 如果我们对比一下导数的定义f’(x) = 𝛥y/𝛥x，其中𝛥x趋近于零，以及微分的定义dy =f’(x)dx，就可以看出它们讲的其实是一回事，因为𝛥x和𝛥y趋近于零之后，就是dx和dy。有时人们直接将导数写成f’(x) =dy/dx。 如果我们孤立地看微分dy，它是个无穷小，搞出这样一个新概念有什么必要呢？我们用一个具体的例子，也就是有关圆柱体积变化趋势的例子来说明。 我们知道，圆柱体的体积：V=𝛑R^2 h，如果我要问，这个体积随半径变化快，还是随高度变化快？在没有微分这个概念时，一般人根据直觉，会觉得随半径变化快，因为是平方关系，而它随高度变化只是线性关系。 但真实情况是什么样呢？我们可以把体积函数分别对半径和高度各做一次微分，得到下面两个结果： 体积对半径R微分：dV/dR=2𝛑Rh 体积对高度h微分：dV/dh=𝛑R^2 大家不必关心细节，了解一下这样两个结论： 由于半径增加所带来的体积增量，和圆柱体当前的半径成正比，也和它的高度成正比。 由于高度增加所带来的体积增量，和圆柱体当前半径的平方成正比，但和它的高度无关。 这时，你如果对比一下两个微分函数就会发现，哪个变化的速率快，还真不好说。假如R等于10，h也等于10，体积就随半径变化快。如果R=10，h只有1，那就是随着高度变化快。 假如你是一个工程师，要建造一个巨大的储油罐，无论你增大半径，还是增加高度，都有相当的工程难度。现在你的研发经费有限，只能在一个维度，增大储油罐的体积，你应该怎么做呢？ 如果你没有学过微积分，你可能会觉得该增加半径。但是听了今天的课程之后你就知道，在这个储油罐比较“扁平”时，应该增加高度。总的来讲，当高度没有达到半径的1/2时，都应该增加高度。 我们在工作和生活中，其实经常遇到这样的问题，一个函数取决于很多变量，这时我们不知道该在哪个方向改变，怎样才能以最快的速度进步。微分这个工具，其实给解决这一类的问题提供了很好的方法。它引出了一个梯度的概念，利用梯度，我们就能解决这个问题了。 梯度是微分的一个扩展。在上面的圆柱体问题中，对圆柱体函数，我们可以针对半径求微分dV/dR，也可以针对高度求微分dV/dh。如果我们把这两个微分的结果放到一起，就是梯度，也就是说圆柱体积函数的梯度是（2𝛑Rh，𝛑R^2）。 梯度的物理含义可以这样理解，如果你去登山，怎样沿着最陡的方向，最快地爬到山顶呢？梯度函数告诉你在任意一点，往不同方向走的上升速度是不一样的，因此你很容易找到前进的目标。在圆柱体函数中的梯度是上面那个式子，我们在前面得到的结论是，只要高度小于1/2的半径，就应该优先增加高度。 如果是一个长方体，情况又如何呢？我们先把体积函数写出来，体积等于长乘以宽乘以高度，即 V=LWH。接下来，我们可以用微分计算出它的梯度函数。 这里面过程我就省略了，我直接给出答案。这时体积的梯度为 （宽度乘以高度，长度乘以高度，长度乘以宽度），一共三个分量。这时你会发现，长宽高，哪个最小，就应该优先增加哪一个。 比如说，长为10，宽和高分别是4和6，这时梯度函数为（24，60，40），你应该增加宽度。这其实和我们的直觉是一致的，如果我们这样不断优化，最后的结果是长方体变成立方体时，体积达到最大。 不只是数学问题，其实很多时候，我们都面临在限制要素中作选择的问题。很多时候，我们总想全方位改进自己，但是人的精力和资源有限，因此在某一时刻，可能只能向一个方向努力。 希望梯度这个概念在你选择方向时能够给你启发。很多人从直觉出发，觉得该补短板，另一些人则觉得，该把长板变得更长。第一类人会和你讲木桶理论，第二类人会和你讲长板理论，每一类都有很多成功的例子，也有很多失败的教训。 于是很多人就不知道该用哪一个理论了。事实上你今天学了梯度理论后，就很容易作决断了，那就是在任何时刻算出梯度，然后沿着最陡，但是收益最大的路径前进就好。 在增加长方体体积时，显然是在采用补短板的策略，但是在增加圆柱体体积时，就看情况而定了，如果高度太低，它是严重的短板，需要弥补，但是只要它超过圆柱体半径的一半时，就要增加长板（半径）的优势了。 如果说你有一个目标函数，它可能受到多个变量的影响，那是你长期进步的趋势，但是在每一个时刻，你需要计算一下那个函数针对各个变量的微分，也就是梯度函数，找到进步最显著的方向去努力。这就是通过宏观趋势把握微观变化。 要点总结： 我们从导数出发，介绍了微分的概念，它是我们从函数的宏观趋势，把握每一个点细节变化的工具。然后我们介绍了多变量函数的微分，也就是梯度的概念，并且说明了如何在有大量不确定性，或者说大量的变量中找到前进方向的方法，具体讲就是往坡度最高的方向努力。 因此，微积分给我们的第一个思维提升就是练习从宏观趋势中把握微观变化的趋势，让我们认清每一步的方向。 下一讲，我们还讲微积分，透过微积分讨论企业增长里的奇点和连续性。我们下一讲再见。]]></content>
      <tags>
        <tag>吴军,数学,电子书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL是怎样运行的：从根儿上理解 MySQL]]></title>
    <url>%2F2019%2F09%2F20%2F2019-9-20%2F</url>
    <content type="text"><![CDATA[重新认识MySQL 客户端 + 服务器 启动服务器程序 UNIX Windows 启动客户端程序 客户端与服务器的通信 TCP/IP 命名管道和共享内存 UNIX域套接字文件 服务器处理客户端请求 存储引擎 启动选项和系统变量 在命令行上使用选项 配置文件中使用选项 Windows UNIX 系统变量 查看系统变量 设置系统变量 状态变量 字符集和比较规则 字符集的转换 InnoDB记录存 InnoDB页 InnoDB行格式 Compact行格式 行数据溢出 行溢出的临界点 InnoDB数据页 数据页结构 记录在页中的存储 记录头信息 Page Directory Page Header File Header File Trailer B+树索引 无索引查找 在页内查找 在多页中查找 索引 目录项 用页存放目录项 聚簇索引 二级索引 B+树索引的使用 合理使用索引 全值匹配 匹配左边的列 匹配列前缀 回表的代价 二级索引 + 回表 or 全表扫码 覆盖索引 合理地建立索引 MySQL的数据目录 数据库和文件系统的关系 数据目录 数据目录和安装目录的区别 查找数据目录 数据目录的结构 数据库在文件系统中的表示 表在文件系统中的表示 文件系统对数据库的影响 MySQL系统数据库简介 本文为敝人的学习记录，感兴趣的请在掘金小册购买同名原著 😎 重新认识MySQL# 客户端 + 服务器# MySQL服务器进程(也叫数据库实例) MySQL客户端进程 进程：进程号(PID，由操作系统随机分配)、进程名称 MySQL服务器进程的默认名称为mysqld， MySQL客户端进程的默认名称为mysql 启动服务器程序# UNIX# 使用安装目录下(比如 /usr/local/mysql/bin/): 1mysqld 1mysqld_safe mysqld_safe是一个启动脚本的命令，调用了mysqld，并启动一个监控进程(重启，日志) 12mysql.server startysql.server stop mysql.server是一个链接文件， 会调用mysqld_safe Windows# 使用安装目录下(比如 D:\Program Files\mysql-5.7.26-winx64\bin\) mysqld.exe 可执行文件 使用 Windows服务。把某个程序注册为Windows服务的格式： &quot;可执行文件路径&quot; --install [-manual] [服务名称] 123D:\Program Files\mysql-5.7.26-winx64\bin\mysqld --install [MySQL_Service]net start MySQL_Servicenet stop MySQL_Service 启动客户端程序# mysql -h主机名 -u用户名 -p密码 123mysql -hlocalhost -uroot -p123abcmysql -u root -pmysql --host=localhost --user=root --password=123abc 退出客户端 123quitexit\q 客户端与服务器的通信# 本质是两个进程间的通信 TCP/IP# 每台计算机都有一个唯一的IP地址 每个进程向操作系统申请一个端口号(0~65535) 通过IP地址 + 端口号来与某个进程通信 MySQL服务器进程的默认端口号为3306，自定义MySQL服务器进程的端口号如下 1mysqld -P3307 命名管道和共享内存# Windows系统中的进程间通信方式 命名管道 12345mysqld --enable-named-pipemysql --pipeormysql --protocol=pipe 共享内存 123mysqld --shared-memorymysql --protocol=memory UNIX域套接字文件# 1mysql --protocol=socket 服务器程序默认监听的套接字文件路径为/tmp/mysql.sock，指定套接字文件路径： 12mysqld --socket=/tmp/a.txtmysql -hlocalhost -uroot --socket=/tmp/a.txt -p 服务器处理客户端请求# 存储引擎# XA列代表是否支持分布式事务 Savepoints代表是否支持部分事务回滚 启动选项和系统变量# 在命令行上使用选项# 12mysqld --skip-networkingmysqld --default-storage-engine=MyISAM \\ 等号两边不能有空格 使用mysql --help可以看到mysql程序支持的启动选项 使用mysqld --verbose --help查看mysqld支持的启动选项 配置文件中使用选项# Windows# 12345678910111213%WINDIR%\my.ini%WINDIR%\my.cnf C:\my.iniC:\my.cnfBASEDIR\my.ini \\ MySQL安装路径BASEDIR\my.cnf defaults-extra-file 命令行指定的额外配置文件路径，如mysqld --defaults-extra-file=C:\Users\chiangtao ho\my_extra_file.txt%APPDATA%\MySQL\.mylogin.cnf 登录路径选项（仅限客户端） UNIX# 12345678910/etc/my.cnf /etc/mysql/my.cnf SYSCONFDIR/my.cnf $MYSQL_HOME/my.cnf 特定于服务器的选项（仅限服务器）defaults-extra-file ~/.my.cnf 用户特定选项~/.mylogin.cnf 用户特定的登录路径选项（仅限客户端） 系统变量# 查看系统变量# 12SHOW VARIABLES like 'max_connections';SHOW VARIABLES LIKE 'default%'; 系统变量的单词之间必须使用下划线_连接 设置系统变量# 变量的作用范围 GLOBAL：全局变量，影响服务器的整体操作 SESSION (LOCAL)：会话变量，影响某个客户端连接的操作 123456SET GLOBAL default_storage_engine = MyISAM;SET @@GLOBAL.default_storage_engine = MyISAM;SET SESSION default_storage_engine = MyISAM;SET @@SESSION.default_storage_engine = MyISAM;SET default_storage_engine = MyISAM; \\ 默认作用范围是LOCAL 那我们的SHOW VARIABLES语句默认查看的是SESSION作用范围的系统变量 并不是所有系统变量都具有GLOBAL和SESSION的作用范围 状态变量# 与系统变量类似，状态变量也有GLOBAL和SESSION两个作用范围的 1SHOW STATUS LIKE 'thread%'; 字符集和比较规则# 查看字符集 12SHOW CHARSET;SHOW CHARACTER SET; Default collation表示字符集默认的比较规则 Maxlen代表该字符集表示一个字符最多需要几个字节 查看比较规则 MySQL中utf8是utf8mb3的别名，所以在MySQL中utf8就意味着使用1~3个字节来表示一个字符，如果大家有使用4字节编码一个字符的情况，比如存储一些emoji表情，使用utf8mb4 MySQL有4个级别的字符集和比较规则，分别是： 服务器级别 character_set_server, collation_server 数据库级别 character_set_database, collation_database 表级别 列级别 编码和解码使用的字符集不一致将导致乱码 字符集的转换# character_set_client 服务器解码请求语句时使用的字符集 character_set_connection 服务器处理请求时会把请求字符串从character_set_client转为character_set_connection character_set_results 服务器向客户端返回数据时使用的字符集 通常把 character_set_client 、character_set_connection、character_set_results 这三个系统变量设置成和客户端使用的相同的字符集 12345SET NAMES 字符集名;SET character_set_client = 字符集名;SET character_set_connection = 字符集名;SET character_set_results = 字符集名; InnoDB记录存# InnoDB页# InnoDB是一个将表中的数据存储到磁盘上的存储引擎。磁盘读写的速度比内存的读写速度差了几个数量级，因此设计InnoDB时将数据划分为若干个页并以页作为磁盘和内存之间交互的基本单位，页的大小一般为 16 KB。 InnoDB行格式# 4种行格式: Compact Redundant Dynamic Compressed 1CREATE TABLE 表名 ROW_FORMAT=行格式名称 Compact行格式# 所有变长字段的真实数据占用的字节长度都被存放在变长字段长度列表 把值为NULL的列统一存储到NULL值列表中 记录头信息是由固定的5个字节组成 MySQL会为每个记录默认的添加一些列（隐藏列），包括：row_id（DB_ROW_ID）、transaction_id（DB_TRX_ID）、roll_pointer（DB_ROLL_PTR）。 行数据溢出# 对于MySQL的每条记录，除了BLOB或者TEXT类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。这个65535个字节除了列本身的数据之外，还包括一些其他的数据，即 真实数据本身 真实数据占用字节的长度标识（&lt;= 2 bytes） NULL值标识（&lt;= 1 byte），当列都有NOT NULL属性时为0 因此，上图中设置变长类型VARCHAR(M)（M表示允许的字符数量）M=65535时导致了溢出。 真实数据：65533 = 65529(c1)+ 4(c2) 长度标识：2 NULL值标识：1 共65536 &gt; 65535溢出。 更换字符集后溢出。 VARCHAR(M)类型的列就最多可以存储65533个字节，而一个页的大小一般是16KB，也就是16384字节，因此在Compact和Reduntant行格式中，在本记录只会存储该列的前768个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中；而在Dynamic和Compressed行格式中，记录中只存储其他页的地址。 行溢出的临界点# MySQL中规定一个页中至少要存放两行记录 每个页除了存放记录外，也需要存储一些额外的信息，这些额外信息加起来需要132个字节 每个记录的额外信息需要27字节 真实数据的长度标识 1B NULL值标识 1B 记录头信息 5B row_id 6B transaction_id 6B roll_pointer 7B 不溢出的临界条件：132 + 2×(27 + n) &lt; 16384 InnoDB数据页# 数据页结构# 记录在页中的存储# 记录头信息# 以 page_demo 表为例 123456CREATE TABLE page_demo( c1 INT, c2 INT, c3 VARCHAR(10000), PRIMARY KEY (c1)) CHARSET=ascii ROW_FORMAT=Compact; 由于指定 c1 为主键，所以在行格式中就没有隐藏列 row_id。 插入数据4条记录 1234INSERT INTO page_demo VALUES(1, 100, 'aaaa'), (2, 200, 'bbbb'), (3, 300, 'cccc'), (4, 400, 'dddd'); delete_mask 标记当前记录是否被删除，值为0的时候代表记录没有被删除，1则被删除了； 所有被删的记录会组成一个垃圾链表，新记录插入到表时可以覆盖这些被删除的记录占用的存储空间。 n_owned 见Page Directory heap_no 表示当前记录在本页中的位置，从上图中可以看出，插入的4条记录在本页中的位置分别是：2、3、4、5。最小记录和最大记录分别为0、1。 record_type 记录类型，共4种： 0：普通记录 1：B+树非叶节点记录 （或目录项记录，见目录项） 2：最小记录 3：最大记录 min_rec_mask 代表B+树的每层非叶节点中的最小记录 （或者主键值最小的目录项记录的min_rec_mask值为1） next_record 表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。例如第一条记录的next_record值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。记录按照主键从小到大的顺序形成了一个单链表 如果删除第二条记录 1DELETE FROM page_demo WHERE c1 = 2; 删除第2条记录前后的主要变化： 第2条记录的delete_mask值设置为1； 第2条记录的next_record值变为了0，意味着该记录没有下一条记录了； 第1条记录的next_record指向了第3条记录； 最大记录的n_owned值从5变成了4。 Page Directory# 设计页目录是为了方便快速查找记录，就像书的目录那样，创建 page directory 的步骤： 将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组； 每个组内最大的那条记录的头信息的 n_owned 表示组内记录的数量； 将每个组的最大的那条记录的地址偏移量（也称槽，slot）集中起来存放，构成 Page Directory； InnoDB规定最小记录所在的分组只能有 1 条记录，最大记录所在的分组的记录条数在 1~8 条之间，其它分组中记录的条数则在是 4~8 条之间。 利用页目录查找指定主键的记录的过程分为两步： 通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录； 通过记录的 next_record 属性遍历组中的各个记录。 Page Header# 存储数据的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等。 File Header# 不同类型的页都会以File Header作为第一个组成部分，它记录了针对各种页都通用的一些信息。 索引页（数据页）通过 file header 构成双向链表 File Trailer# 与file header一样对不同类型的页通用，主要用于校验页数据的完整性。 B+树索引# 无索引查找# 在页内查找# 以主键查找 依据页目录（槽）采用二分查找定位分组，再遍历分组 以主键以外的列查找 遍历页内的记录链表 在多页中查找# 定位记录所在的页 页内查找 索引# 建立索引是为了快速定位记录所在的数据页。 对数据页进行排序。即让下一个数据页的记录的主键值大于上一个页的记录的主键值，因此在插入新的记录时涉及数据页间的记录的调整 对页进行排序后，全部记录的主键值就构成了一个递增的序列，从而可以利用二分法实现快速查找。 对每个页设置目录项 目录项# 目录项包括 数据页中的记录的最小主键值，用key来表示； 页号，用page_no表示。 用页存放目录项# 用户记录都存放在B+树的叶节点上，而目录项都存放在非页节点上。 聚簇索引# 特性包括： 依据记录的主键值排序 页内的记录是按照主键的大小顺序排成一个单向链表 数据页根据主键大小顺序排成一个双向链表 存放目录项记录的页根据主键大小分为不同的层次 B+树的叶节点存储的是完整的记录，即记录的所有列的值（包括隐藏列） 二级索引# 依据记录的其它列（比如c1）的值排序形成的B+树。将聚簇索引的主键值换为c1的值，此外，叶节点存储的不是完整的记录而只有主键和c1。 通过二级索引来查找完整记录：通过二级索引找到主键值之后再通过聚簇索引查找完整记录。 B+树索引的使用# 合理使用索引# 考虑表 person_info 123456789CREATE TABLE person_info( id INT NOT NULL auto_increment, name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, PRIMARY KEY (id), KEY idx_name_birthday_phone (name, birthday, phone)); idx_name_birthday_phone 为二级索引 全值匹配# 1SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone = '15123983239'; 由于查询优化器的存在，调换name、birthday、phone这几个搜索列的顺序不影响查询的执行过程。 匹配左边的列# 1SELECT * FROM person_info WHERE name = 'Ashburn'; 可以使用索引idx_name_birthday_phone，而 1SELECT * FROM person_info WHERE birthday = '1990-09-27'; 不能使用索引idx_name_birthday_phone。 匹配列前缀# 比如查询名字以 As 开头的记录 1SELECT * FROM person_info WHERE name LIKE 'As%'; 回表的代价# 1SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow'; 二级索引搜索到的结果（即值在Asa～Barlow之间的记录）在磁盘中的存储是相连的，集中分布在一个或几个数据页中，因此可以很快从磁盘中读出，这种读取方式可以称为顺序I/O。而回表是根据不连续的id值到聚簇索引中读出完整的用户记录（可能分布在不同的数据页中），这种读取方式可以称为随机I/O。一般情况下，顺序I/O比随机I/O的性能高很多。 二级索引 + 回表 or 全表扫码# 需要回表的记录越多，使用二级索引的性能就越低，甚至不如使用聚簇索引全表扫码； 使用LIMIT限制回表次数，使优化器倾向于使用二级索引 + 回表的方式执行查询。 覆盖索引# 如果需要查询的列包含在二级索引中，就可以避免回表查询，这种只需要用到索引的查询方式称为索引覆盖。例如对于索引idx_name_birthday_phone 1SELECT name, birthday, phone FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow' 合理地建立索引# 只给搜索、排序、分组的列创建索引 即只给出现在 WHERE、ORDER BY、GROUP BY 子句中的列创建索引； 列的方差越大越适合建立索引 列的数据越分散，越适合索引查询。举个极端的例子，数据都相同的列，对这样的列建立索引毫无意义； 列的数据类型越小越适合建立索引 比较数据大小更快，占用的存储空间更小； 索引字符串的前缀 1234567CREATE TABLE person_info( name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, KEY idx_name_birthday_phone (name(10), birthday, phone)); 其中 name(10) 表示在建立的B+树索引中只保留记录的前10个字符的编码，但是该索引不支持 name 排序 1SELECT * FROM person_info ORDER BY name LIMIT 10; 让索引列在比较表达式中单独出现 12WHERE my_col * 2 &lt; 4WHERE my_col &lt; 4/2 如果列是以某个表达式或者函数调用形式出现是用不到索引的，比如上面的my_col * 2； 开启主键AUTO_INCREMENT属性 可减少页分裂和记录移位的次数。 MySQL的数据目录# 数据库和文件系统的关系# InnoDB、MyISAM等存储引擎都是把表存储在磁盘上。操作系统通过文件系统管理磁盘。 InnoDB、MyISAM等存储引擎 $ \Leftrightarrow $ 文件系统 $ \Leftrightarrow $ 磁盘 数据目录# 数据目录和安装目录的区别# 数据目录是用来存储MySQL在运行过程中产生的数据，要与MySQL的安装目录区别开来。 查找数据目录# 数据目录的结构# 数据库在文件系统中的表示# 每新建一个数据库，MySQL执行了： 在数据目录下创建一个和数据库名同名的子目录； 并在该子目录下创建一个db.opt文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则等。 查看数据库 查看数据目录 除了information_schema这个系统数据库外，其他的数据库在数据目录下都有对应的子目录。 表在文件系统中的表示# 每个表包含两部分信息： 表结构的定义 用表名.frm文件来描述表结构 表中的数据 InnoDB: 数据存在独立表空间(file-per-table tablespace)中，即 test.ibd 文件 MyISAM: 表名.MYD表示表的数据文件、表名.MYI表示表的索引文件 文件系统对数据库的影响# 数据库名和表名不得超过文件系统所允许的最大长度 特殊字符 MySQL会把数据库名和表名中除数字和拉丁字母外的所有字符在文件名里都映射成 @+编码值的形式，如test?.frm $ \rightarrow $ test@003f.frm 文件大小受文件系统限制 MySQL系统数据库简介# mysql 存储了MySQL的账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息、以及时区信息等 information_schema 这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如表、视图、触发器、列、索引等 performance_schema 这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，包括统计最近执行的语句，执行时间，内存使用情况等 sys 这个数据库主要是通过视图的形式把information_schema和performance_schema结合起来]]></content>
      <tags>
        <tag>MySQL, 长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL Notes]]></title>
    <url>%2F2019%2F09%2F05%2F2019-9-5%2F</url>
    <content type="text"><![CDATA[联表查询 字符替换 正则查询 导入SQL文件 排序 联表查询# 12345678SELECT library.id, library.name, r.reader_sum, b.book_sum FROM library INNER JOIN( SELECT library_id, count(*) AS reader_sum FROM reader WHERE library_group_id = 10 GROUP BY library_id ) AS rON r.library_id = library.id INNER JOIN( SELECT library_id, count( * ) AS book_sum FROM book WHERE library_group_id = 10 GROUP BY library_id ) AS bON b.library_id = library.id; 字符替换# 1UPDATE account SET grade = replace(grade,'級','级'); 正则查询# 12SELECT * FROM account WHERE grade REGEXP '級'; -- 查询包含SELECT name FROM person WHERE name REGEXP '^[aeiou]|ok$'; -- aeiou开头，或ok结尾 导入SQL文件# 1234SET @@global.max_allowed_packet = 1024*1024*1024;SET @@global.sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';SET @@sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; 排序# 1SELECT * FROM book WHERE library_id = 257 AND (title REGEXP "我" OR author REGEXP "我") ORDER BY LOCATE("我", CONCAT(title, author)), LENGTH(title), LENGTH(author); 1SELECT * FROM table WHERE id IN (3,6,9,1,2,5,8,7) ORDER BY field(id,3,6,9,1,2,5,8,7);]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麻省理工 MapReduce 实验]]></title>
    <url>%2F2019%2F04%2F30%2F2019-4-30%2F</url>
    <content type="text"><![CDATA[MapReduce执行概述 序言：熟悉源代码 Part I: Map/Reduce 输入和输出 Part II: Single-worker单词统计 Part III: 分布式 MapReduce 任务 Part IV: worker错误处理 原文链接 MapReduce执行概述# 论文地址 通过自动将输入数据划分为$M$个片段，Map调用分布在多台机器上。 不同片段的输入数据可以由不同的机器并行处理。 Reduce调用的分布式则通过使用分区函数(即 $hash(key)$ $mod$ $R$)将键空间划分为$R$个部分来实现，$R$的大小和分区函数由用户指定。上图显示了MapReduce操作的总体流程。 当用户程序调用MapReduce函数时，会发生以下操作序列(图中的编号标签对应于下面的数字)： 用户程序中的MapReduce库首先将输入文件拆分为16MB到64MB(用户可通过参数设置)的$M$个片段。 然后，它会在一组计算机上启动该程序的许多副本； master为副本之一，其余的是由master分配工作的workers。 有$M$个Map任务和$R$个Reduce任务需要分配。master为每个空闲的worker分配一个Map任务或Reduce任务； 被分配Map任务的worker读取相应输入片段。 它从输入片段中解析键/值对，并将键/值对传递给用户定义的Map函数。 Map函数生成的中间键/值对缓存在内存中； 内存中的键\值对被周期性地写入到本地磁盘，并通过分区函数划分为$R$个分区。 键\值对在本地磁盘的位置将被传回到master，master再将位置信息转发给Reduce worker； 当Reduce worker收到来自master的位置信息后，它使用远程过程调用(RPC)从Map worker的本地磁盘读取缓冲数据。 当Reduce worker读取了所有中间数据时，它会根据中间键进行排序，以便将所有相同的中间键组合在一起。 之所以需要排序是因为通常有许多不同的键映射到同一个reduce任务。 如果中间数据量太大而无法容纳在内存中，则使用外部排序； Reduce worker对排好序的中间数据进行遍历。对遇到的每个唯一中间键，它将键和相应的一组中间值传递给用户的Reduce函数。 Reduce函数的输出附加到此Reduce分区的最终输出文件。 完成所有Map任务和Reduce任务后，master会唤醒用户程序。 此时，用户程序中的MapReduce()将返回用户代码。 序言：熟悉源代码# 提供的Map/Reduce代码支持两种操作模式，即串行和分布式。 在前者中，map和reduce任务每次执行一个：首先是第一个map任务执行完成，然后是第二个，然后是第三个，等等。当所有map任务完成后，执行第一个reduce任务，然后是第二个，等等。这种模式虽然不快，但方便调试。 分布式模式运行着许多worker线程，这些线程先并行执行map任务，然后reduce任务。 这要快得多，但也难以调试。mapreduce包提供了一个简单的Map/Reduce库。 应用程序通常调用master.go中的Distributed()来启动分布式模式，而调用master.go中的Sequential()来获取调试的串行执行。 代码如下执行： 该应用程序提供了许多输入文件、一个map函数、一个reduce函数和reduce任务的数量（$nReduce$）； 创建master。 master启动一个RPC服务器(参见master_rpc.go)，并等待worker注册(使用RPC调用Register()，在master.go中定义)。 当任务变得可用时(在步骤4和5中)，schedule()(位于schedule.go)决定如何将这些任务分配给workers以及如何处理worker故障； master将每个输入文件视为一个 Map任务，并为每个Map任务至少调用一次(at-least-once)doMap()(common_map.go)，可以通过直接使用Sequential()或通过向worker (worker.go)发出DoTask RPC来实现。每次调用doMap()都会读取适当的文件，调用该文件中的map函数，并将生成的键/值对写入$nReduce$个中间文件。doMap() 对每个键哈希化以便挑选中间文件和 将会处理键的reduce任务。 完成所有map任务后，将会有$nMap \times nReduce$个文件。 每个文件名都包含一个前缀，map任务编号和reduce任务编号。 如果有两个map任务和三个reduce任务，map任务将创建如下六个中间文件： mrtmp.xxx-0-0 mrtmp.xxx-0-1 mrtmp.xxx-0-2 mrtmp.xxx-1-0 mrtmp.xxx-1-1 mrtmp.xxx-1-2 每个worker必须能够读取由任何其他worker写入的文件以及输入文件。 现实部署利用分布式存储系统(如GFS)来允许此读取，即使workers在不同的计算机上运行。 在本实验中，您将在同一台计算机上运行所有workers，并使用本地文件系统； 接下来master为每个reduce任务至少调用一次(at-least-once) doReduce()(common_reduce.go)。 与doMap()一样，可以直接或通过worker来完成。 用于reduce任务r的`doReduce()从每个map任务中收集第$r$个中间文件，并为这些文件中出现的每个键调用reduce函数。 reduce任务生成$nReduce$个结果文件； master调用mr.merge()(master_splitmerge.go)，将上一步生成的所有$nReduce$个文件合并为单个输出； master向每个woker发送Shutdown RPC，然后关闭自己的RPC服务器。 说明：在后续的练习中，您必须编写/修改doMap()，doReduce()和schedule()，它们分别位于common_map.go、common_reduce.go和schedule.go中。 您还必须在../main/wc.go中编写map函数和reduce函数。 Part I: Map/Reduce 输入和输出# 提供的Map/Reduce实现缺少部分代码。 在编写第一个Map/Reduce函数对之前，您需要修改sequential的实现代码。 特别是，提供的代码缺少两个关键部分：分配一个map任务输出的函数，以及收集一个reduce任务所有输入的函数。 这些任务分别由common_map.go中的doMap()函数和common_reduce.go中的doReduce()函数执行。 为了帮助您确定是否正确实现了doMap()和doReduce()，我们为您提供了一个Go测试套件(test_test.go)用于检查文件中实现。 例如测试修改后的sequence实现代码，请运行： go test -run Sequential or go test -v -run Sequential 解答： 该部分任务只需要补全common_map.go中的doMap()和common_reduce.go中的doReduce()的代码，补全的结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package mapreduceimport ( "hash/fnv" "io/ioutil" "encoding/json" "log" "os")func doMap( jobName string, // the name of the MapReduce job mapTask int, // which map task this is inFile string, nReduce int, // the number of reduce task that will be run ("R" in the paper) mapF func(filename string, content string) []KeyValue,) &#123; // // doMap manages one map task: it should read one of the input files // (inFile), call the user-defined map function (mapF) for that file's // content, and partition mapF's output into nReduce intermediate files. // // There is one intermediate file per reduce task. The file name // includes both the map task number and the reduce task number. Use // the filename generated by reduceName(jobName, mapTask, r) // as the intermediate file for reduce task r. Call ihash() (see // below) on each key, mod nReduce, to pick r for a key/value pair. // // mapF() is the map function provided by the application. The first // argument should be the input file name, though the map function // typically ignores it. The second argument should be the entire // input file content. mapF() returns a slice containing the // key/value pairs for reduce; see common.go for the definition of // KeyValue. // // Look at Go's ioutil and os packages for functions to read // and write files. // // Coming up with a scheme for how to format the key/value pairs on // disk can be tricky, especially when taking into account that both // keys and values could contain newlines, quotes, and any other // character you can think of. // // One format often used for serializing data to a byte stream that the // other end can correctly reconstruct is JSON. You are not required to // use JSON, but as the output of the reduce tasks *must* be JSON, // familiarizing yourself with it here may prove useful. You can write // out a data structure as a JSON string to a file using the commented // code below. The corresponding decoding functions can be found in // common_reduce.go. // // enc := json.NewEncoder(file) // for _, kv := ... &#123; // err := enc.Encode(&amp;kv) // // Remember to close the file after you have written all the values! // // Your code here (Part I). //读取输入文件 content, err := ioutil.ReadFile(inFile) if err != nil &#123; log.Fatal("doMap读取输入文件错误",err) &#125; //map操作 kvPairs := mapF(inFile, string(content)) //调用mapF，返回键值对 //将键值对写入到中间文件 tmpFiles := make([] *os.File, nReduce) //R个中间文件 encoders := make([] *json.Encoder, nReduce) for i := 0; i &lt; nReduce; i++ &#123; tmpFileName := reduceName(jobName, mapTask, i) //中间文件名,mrtmp.test-mapTask-i tmpFiles[i], err = os.Create(tmpFileName) //创建中间文件mrtmp.test-mapTask-i if err != nil &#123; log.Fatal("doMap生成中间文件错误", err) &#125; defer tmpFiles[i].Close() encoders[i] = json.NewEncoder(tmpFiles[i]) if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125; for _ , kv := range kvPairs &#123; hashKey := ihash(kv.Key) % nReduce //根据键将键值对分成R组 err := encoders[hashKey].Encode(&amp;kv) //将R个键值对写入R个中间文件 if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125;&#125;func ihash(s string) int &#123; h := fnv.New32a() h.Write([]byte(s)) return int(h.Sum32() &amp; 0x7fffffff)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package mapreduceimport ( "encoding/json" "log" "os" "sort")func doReduce( jobName string, // the name of the whole MapReduce job reduceTask int, // which reduce task this is outFile string, // write the output here nMap int, // the number of map tasks that were run ("M" in the paper) reduceF func(key string, values []string) string,) &#123; // // doReduce manages one reduce task: it should read the intermediate // files for the task, sort the intermediate key/value pairs by key, // call the user-defined reduce function (reduceF) for each key, and // write reduceF's output to disk. // // You'll need to read one intermediate file from each map task; // reduceName(jobName, m, reduceTask) yields the file // name from map task m. // // Your doMap() encoded the key/value pairs in the intermediate // files, so you will need to decode them. If you used JSON, you can // read and decode by creating a decoder and repeatedly calling // .Decode(&amp;kv) on it until it returns an error. // // You may find the first example in the golang sort package // documentation useful. // // reduceF() is the application's reduce function. You should // call it once per distinct key, with a slice of all the values // for that key. reduceF() returns the reduced value for that key. // // You should write the reduce output as JSON encoded KeyValue // objects to the file named outFile. We require you to use JSON // because that is what the merger than combines the output // from all the reduce tasks expects. There is nothing special about // JSON -- it is just the marshalling format we chose to use. Your // output code will look something like this: // // enc := json.NewEncoder(file) // for key := ... &#123; // enc.Encode(KeyValue&#123;key, reduceF(...)&#125;) // &#125; // file.Close() // // Your code here (Part I). //遍历属于自己的中间文件，将键值对合并到kvs中 kvs := make(map[string][]string) for i := 0; i &lt; nMap; i++ &#123; fileName := reduceName(jobName, i, reduceTask) file, err := os.Open(fileName) //打开中间文件mrtmp.test-i-reduceTask if err != nil &#123; log.Fatal("doReduce打开文件错误", err) &#125; dec := json.NewDecoder(file) for &#123; //每个中间文件可能包含多个键值对 var kv KeyValue err = dec.Decode(&amp;kv) //解码一个键值对 if err != nil &#123; break &#125; _, ok := kvs[kv.Key] if !ok &#123; //出现新的键则初始化kvs kvs[kv.Key] = []string&#123;&#125; &#125; kvs[kv.Key] = append(kvs[kv.Key], kv.Value) //加入与键对应的值 &#125; file.Close() &#125; //将键集合到一起并排序 var keys []string for k := range kvs &#123; keys = append(keys, k) &#125; sort.Strings(keys) //创建输出文件 out := mergeName(jobName, reduceTask) file, err := os.Create(out) if err != nil &#123; log.Fatal("doReduce创建输出文件错误", err) &#125; enc := json.NewEncoder(file) //reduce操作 for _, k := range keys &#123; res := reduceF(k, kvs[k]) //调用客户端的reduceF，进行reduce enc.Encode(KeyValue&#123;k, res&#125;) //reduce后的键值对写入到输出文件 &#125; file.Close()&#125; 运行go test -run Sequential，结果如下： Part II: Single-worker单词统计# 在该部分，您将要实现一个简单的Map/Reduce示例——单词统计。 具体是需要实现main/wc.go中的mapF()和reduceF()函数。 您的工作是插入代码，以便wc.go返回输入文件中每个单词出现的次数。 一个单词是任意连续的字母序列，其中字母可用Golang的unicode.IsLetter函数来判断。 在~/6.824/src/main目录中提供了一些路径名为pg-*.txt形式的输入文件， 可用如下命令给wc.go使用输入文件运行： go run wc.go master sequential pg-*.txt 查看MapReduce论文的第2部分。mapF()和reduceF()函数与论文第2.1节中的函数略有不同。mapF()将接收一个文件名和该文件的内容，并将内容分成单词最终输出一个mapreduce.KeyValue型切片。 对于单词统计可将单词作为键。对输出中的每个键都将调用一次reduceF()，其中包含mapF()为该键生成的所有值的切片。 reduceF()返回一个包含键出现总数的字符串。 提示1：关于Go的字符串处理，可以参读 Go Blog on strings 提示2：可以使用strings.FieldsFunc函数将字符串拆分成单词 提示3： 利用Go的strconv包可以很方便地将字符串转换成整型 使用如下命令来验证答案： go run wc.go master sequential pg-*.txt 答案： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt" "mapreduce" "os" "strconv" "strings" "unicode")//// The map function is called once for each file of input. The first// argument is the name of the input file, and the second is the// file's complete contents. You should ignore the input file name,// and look only at the contents argument. The return value is a slice// of key/value pairs.//func mapF(filename string, contents string) []mapreduce.KeyValue &#123; // Your code here (Part II). var res []mapreduce.KeyValue f := func(c rune) bool &#123; //不是字母 return !unicode.IsLetter(c) &#125; words := strings.FieldsFunc(contents, f) //在不是字母地方拆分字符串contents for _, key := range words &#123; res = append(res, mapreduce.KeyValue&#123;key, "1"&#125;) &#125; return res&#125;//// The reduce function is called once for each key generated by the// map tasks, with a list of all the values created for that key by// any map task.//func reduceF(key string, values []string) string &#123; // Your code here (Part II). count := 0 for _, value := range values &#123; num, _ := strconv.ParseInt(value, 10, 64) // 将字符串value（例如："157"）按照十进制转换成整型 count = count + int(num) &#125; return strconv.Itoa(count) //整型转换成字符串&#125;// Can be run in 3 ways:// 1) Sequential (e.g., go run wc.go master sequential x1.txt .. xN.txt)// 2) Master (e.g., go run wc.go master localhost:7777 x1.txt .. xN.txt)// 3) Worker (e.g., go run wc.go worker localhost:7777 localhost:7778 &amp;)func main() &#123; if len(os.Args) &lt; 4 &#123; fmt.Printf("%s: see usage comments in file\n", os.Args[0]) &#125; else if os.Args[1] == "master" &#123; var mr *mapreduce.Master if os.Args[2] == "sequential" &#123; mr = mapreduce.Sequential("wcseq", os.Args[3:], 3, mapF, reduceF) &#125; else &#123; mr = mapreduce.Distributed("wcseq", os.Args[3:], 3, os.Args[2]) &#125; mr.Wait() &#125; else &#123; mapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil) &#125;&#125; 运行go run wc.go master sequential pg-sherlock_holmes.txt和sort -n -k2 mrtmp.wcseq | tail -10的结果： Part III: 分布式 MapReduce 任务# 在当前的实现中，是通过串行的方式来执行Map任务和Reduce任务。 Map/Reduce最大的卖点之一是它可以自动地并行执行原始的串行代码而无需开发人员的任何额外工作。 在这一部分中，您将完成一个分布式MapReduce版本，即将工作拆分为在多核上运行的一组worker线程。 尽管不像真实的Map/Reduce部署被分布在多台机器上那样，但你本部分的实现中将使用RPC来模拟分布式计算。 mapreduce/master.go中的代码完成了管理MapReduce的大部分工作。 我们还为您提供了mapreduce/worker.go中worker线程的完整代码以及在mapreduce/common_rpc.go中处理RPC的一些代码。 你的任务是实现mapreduce/schedule.go中的schedule()函数。 master在MapReduce期间将两次调用schedule()，一次用于Map阶段，一次用于Reduce阶段。 schedule()的功能是将任务分发给可用的worker。 任务的数量通常比worker线程多，因此schedule()必须为每个worker分配一系列任务，一次一个。 schedule()应该等到所有任务都完成后再返回。 schedule()通过读取registerChan参数来了解一组worker。 该channel为每个worker生成一个包含worker的RPC地址的字符串。所有的worker都会出现在registerChan，其中一些worker可能在调用schedule()之前就存在，而另一些worker可能在schedule()运行时才启动。schedule()应该充分利用所有的worker，包括启动后出现的worker。 schedule()通过向worker发送Worker.DoTaskRPC来通知worker执行任务。 此RPC的参数由mapreduce/common_rpc.go中的DoTaskArgs定义。File元素仅由Map任务使用，代表要读取的文件的名称；schedule()可以在mapFiles中找到这些文件名。 使用mapreduce/common_rpc.go中的call()函数将RPC发送给worker。 第一个参数是worker的地址，从registerChan读取，第二个参数是Worker.DoTask， 第三个参数是DoTaskArgs结构，最后一个参数是nil。 您对在第III部分的解答仅涉及对schedule.go的修改；如果您在调试过程中修改了其他文件，请恢复其原始内容。请先测试再提交。 使用go test -run TestParallel来测试您的答案。 该命令将执行两个测试，TestParallelBasic和TestParallelCheck，后者验证您的schedule()是否使worker并行执行任务。 提示1：schedule()应该并行地向worker发送RPC，以便worker可以并发执行任务。 你会发现go语句对此很有用，参见Concurrency in Go。 提示2：schedule()必须等待worker完成一个任务后才能给它另下一个任务，Go的channel对此很有用。 提示3： sync.WaitGroup 提示4：追踪错误的最简单的方法是插入print语句（在common.go中可能是调用debug()），使用go test -run TestParallel &gt; out将输出收集到一个文件中，然后分析输出是否与你对代码的预期相符。 最后一步是最重要的。 提示5：检查您的代码是否有竞争的情况可在测试中运行race detector。 注意：我们提供的代码是在单个UNIX进程中将worker作为线程运行，并且可以在单台机器上使用多核。 要想在使用网络进行通信的多台机器上运行worker必须进行一些修改：RPC必须使用TCP而不是UNIX-domain套接字；需要有一种方法来启动所有机器上的worker进程；所有的机器都必须通过某种网络文件系统共享存储。 答案见Part IV。 Part IV: worker错误处理# 在这部分中，您将实现master处理失败的worker的功能。由于worker的状态不是持久的，该功能在MapReduce中相对容易实现。 如果worker在处理来自master的RPC时发生错误，master的call()最终会因超时而返回false。在这种情况下，master会将该任务重新分配给另一个worker。 RPC故障并不一定意味着worker没有执行任务；worker可能已执行任务但是返回结果丢失，或者worker可能仍在执行但master的RPC超时。因此，可能会发生两个worker接收相同任务、计算并产生输出的情况。 需要对map或reduce函数进行两次调用才能为给定输入生成相同的输出，因此如果后续处理读取一个输出或者读取另一个输出，则不会出现不一致。 此外，MapReduce框架确保map和reduce函数输出以原子方式出现：输出文件要么不存在，要么包含单个map或单个reduce函数执行的整个输出（提供的代码不涉及这部分）。 您的实现必须通过test_test.go中剩下的两个测试用例。 第一个用例测试一个worker的失败，而第二个测试用例测试对多个worker的失败的处理。 测试用例会定期启动新的worker，master可以使用这些worker来推进程序过程，但这些worker在处理完一些任务后会失败。 使用下面的命令来运行测试： go test -run Failure 在第IV部分，只涉及对schedule.go的修改。 如果您在调试过程中修改了其他文件，请恢复其原始内容，然后再进行测试、提交。 Part III、Part IV答案： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mapreduceimport "fmt"//// schedule() starts and waits for all tasks in the given phase (mapPhase// or reducePhase). the mapFiles argument holds the names of the files that// are the inputs to the map phase, one per map task. nReduce is the// number of reduce tasks. the registerChan argument yields a stream// of registered workers; each item is the worker's RPC address,// suitable for passing to call(). registerChan will yield all// existing registered workers (if any) and new ones as they register.//func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) &#123; var ntasks int var n_other int // number of inputs (for reduce) or outputs (for map) switch phase &#123; case mapPhase: ntasks = len(mapFiles) n_other = nReduce case reducePhase: ntasks = nReduce n_other = len(mapFiles) &#125; fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other) // All ntasks tasks have to be scheduled on workers. Once all tasks // have completed successfully, schedule() should return. // // Your code here (Part III, Part IV). // done := make(chan bool) for i := 0; i &lt; ntasks; i++ &#123; go func(num int) &#123; args := DoTaskArgs&#123;jobName, mapFiles[num], phase, num, n_other&#125; var worker string reply := new(struct&#123;&#125;) ok := false for ok != true &#123; worker = &lt;-registerChan ok = call(worker, "Worker.DoTask", args, reply) &#125; done &lt;- true //任务完成 registerChan &lt;- worker //该worker工作完毕，处于空闲，加入channel中以分配给其它任务 &#125;(i) &#125; for i := 0; i &lt; ntasks; i++ &#123; //等待所有任务完成 &lt;-done &#125; fmt.Printf("Schedule: %v done\n", phase)&#125; 运行go test -run TestParallel的结果：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[远程过程调用和线程(RPC and Thread)]]></title>
    <url>%2F2019%2F03%2F25%2F2019-3-25%2F</url>
    <content type="text"><![CDATA[MIT Distributed System Course: Lecture 2 Remote Procedure Call (RPC) 目标： 建立编程友好的客户端/服务器通信 RPC消息图： 客户端 服务器 请求---&gt; &lt;---响应 软件结构： client app handlers stubs dispatcher RPC lib RPC lib net ------------ net Go rpc包： 官方文档 import &quot;net/rpc rpc包提供对通过网络或其他I / O连接的对象的导出方法的访问。 服务器注册一个对象，并作为一种服务可见。 注册的对象其导出方法可以被远程访问。 服务器可以注册不同类型的多个对象（服务），但是注册相同类型的多个对象是错误的。 只有满足下列标准的方法（method）才能被远程访问： the method's type is exported. the method is exported. the method has two arguments, both exported (or builtin) types. the method's second argument is a pointer. the method has return type error. 实际上，该方法必须看起来像 1func (t *T) MethodName(argType T1, replyType *T2) error 其中T1和T2可以通过 encoding/gob包来编码。即便使用不同的编解码器，上述标准仍然适用。 第一个参数T1表示调用者提供的参数;第二个参数T2表示要返回给调用者的结果参数。服务器可以通过调用ServeConn来处理单个连接上的请求。更典型的例子有创建网络侦听器并调用Accept，创建HTTP侦听器并调用HandleHTTP和http.Serve。 希望使用该服务的客户端首先和服务器建立连接，然后在连接的基础上调用NewClient。可以使用Dial函数（DialHTTP）方便地执行原始网络连接（HTTP连接）的两个步骤。新建的客户端对象具备Call方法和Go方法。 Call方法等待远程调用完成，而Go方法使用Call结构的Done通道启动异步调用和发出完成信号。 除非设置了显式编解码器，否则一般使用encoding/gob包来传输数据。 一个服务器导出Arith类型的对象的例子： 123456789101112131415161718192021222324252627package serverimport "errors"type Args struct &#123; A, B int&#125;type Quotient struct &#123; Quo, Rem int&#125;type Arith intfunc (t *Arith) Multiply(args *Args, reply *int) error &#123; *reply = args.A * args.B return nil&#125;func (t *Arith) Divide(args *Args, quo *Quotient) error &#123; if args.B == 0 &#123; return errors.New("divide by zero") &#125; quo.Quo = args.A / args.B quo.Rem = args.A % args.B return nil&#125; 服务器端调用 HTTP service： 12345678arith := new(Arith)rpc.Register(arith)rpc.HandleHTTP()l, e := net.Listen("tcp", ":1234")if e != nil &#123; log.Fatal("listen error:", e)&#125;go http.Serve(l, nil) 现在，客户端拥有了一项服务Arith，该服务提供了Arith.Multiply和Arith.Divide方法。要调用这些方法，客户端得先拨通服务器： 1234client, err := rpc.DialHTTP("tcp", serverAddress + ":1234")if err != nil &#123; log.Fatal("dialing:", err)&#125; 然后进行远程调用： 12345678// Synchronous callargs := &amp;server.Args&#123;7,8&#125;var reply interr = client.Call("Arith.Multiply", args, &amp;reply)if err != nil &#123; log.Fatal("arith error:", err)&#125;fmt.Printf("Arith: %d*%d=%d", args.A, args.B, reply) 或者 12345// Asynchronous callquotient := new(Quotient)divCall := client.Go("Arith.Divide", args, quotient, nil)replyCall := &lt;-divCall.Done // will be equal to divCall// check errors, print, etc. 服务器通常会为客户端提供一个简单的、类型安全的封装。 net/rpc包已冻结，不会增加新的功能属性。 Go举例： 一个简单的key/value存储服务器——Put(key,value), Get(key)-&gt;value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package mainimport ( "fmt" "log" "net" "net/rpc" "sync")//// RPC request/reply definitions//const ( OK = "OK" ErrNoKey = "ErrNoKey")type Err stringtype PutArgs struct &#123; Key string Value string&#125;type PutReply struct &#123; Err Err&#125;type GetArgs struct &#123; Key string&#125;type GetReply struct &#123; Err Err Value string&#125;//// Client//func connect() *rpc.Client &#123; client, err := rpc.Dial("tcp", ":1234") if err != nil &#123; log.Fatal("dialing:", err) &#125; return client&#125;func get(key string) string &#123; client := connect() args := GetArgs&#123;Key: key&#125; reply := GetReply&#123;&#125; err := client.Call("KV.Get", &amp;args, &amp;reply) //远程调用KV.Get，等待它完成，并返回其错误状态。 if err != nil &#123; log.Fatal("error:", err) &#125; client.Close() log.Println(reply.Err) return reply.Value&#125;func put(key string, val string) &#123; client := connect() args := PutArgs&#123;Key: key, Value: val&#125; reply := PutReply&#123;&#125; err := client.Call("KV.Put", &amp;args, &amp;reply) //远程调用KV.Put if err != nil &#123; log.Fatal("error:", err) &#125; client.Close()&#125;//// Server//type KV struct &#123; mu sync.Mutex data map[string]string&#125;func server() &#123; kv := new(KV) kv.data = map[string]string&#123;&#125; rpcs := rpc.NewServer() rpcs.Register(kv) l, e := net.Listen("tcp", ":1234") if e != nil &#123; log.Fatal("listen error:", e) &#125; go func() &#123; for &#123; conn, err := l.Accept() if err == nil &#123; go rpcs.ServeConn(conn) &#125; else &#123; break &#125; &#125; l.Close() &#125;()&#125;func (kv *KV) Get(args *GetArgs, reply *GetReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() val, ok := kv.data[args.Key] if ok &#123; reply.Err = OK reply.Value = val &#125; else &#123; reply.Err = ErrNoKey reply.Value = "" &#125; return nil&#125;func (kv *KV) Put(args *PutArgs, reply *PutReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value reply.Err = OK return nil&#125;//// main//func main() &#123; server() put("passwd", "2w6C*kcXWWmzK$Jg") //客户端存储密码 fmt.Println(get("passwd")) //客户端获取密码&#125;command-line-arguments2019/04/02 18:34:11 OK2w6C*kcXWWmzK$Jg 共同：必须为每种RPC类型声明Args和Reply结构 Client: connect()的Dial()创建与服务器的TCP连接 Call()要求RPC库执行远程调用 指定server function name, args,reply library marshalls args, sends request, waits, unmarshally reply Call()的返回值表示是否收到回复 usually you'll also have a reply.Err indicating service-level failure server： Go要求您声明一个带有方法的对象作为RPC处理程序(RPC handler) 然后，您使用RPC库注册该对象 您接受TCP连接，并给它们提供RPC库 RPC库 读取每个请求 为此请求创建一个新的goroutine unmarshalls request 调用命名方法（调度） marshalls reply 在TCP连接上写回复 服务器的Get()和Put()处理程序 必须锁定，因为RPC库给每个请求创建goroutines 解读args; 修改reply 线程: 线程是一种有用的结构化工具 Go称他们为goroutines;其他人称他们为线程 他们可能很棘手 Why threads? 用它们实现并发，在分布式系统中自然地出现 I / O并发： 在等待来自其他服务器的响应时，处理下一个请求 多核： 线程在多个核心上并行运行 Thread =“执行线程” 线程允许一个程序（逻辑上）一次执行许多事情 线程共享内存 each thread includes some per-thread state，包括：程序计数器，寄存器，堆栈 程序中有多少个线程？ 由结构驱动 例如每个客户端一个线程，一个用于后台任务 多核并行 one active thread per core。Go的 runtime 自动地在可用内核上调度可运行的goroutine I / O并发 数量由延迟和容量决定 继续增加直到吞吐量停止增长 Go threads are pretty cheap 100或1000是好的，但可能达不到数百万的量级 创建线程比方法调用更昂贵 Threading challenges： 共享数据 一个线程读取另一个线程正在改变的数据？例如当两个线程执行count = count + 1时，this is a &quot;race&quot; -- and is usually a bug ——使用互斥锁（或其他同步） ——或避免共享 线程之间的协调 如何等待所有Map线程完成？ ——使用Go channel或WaitGroup 并发的粒度 粗粒度(coarse-grained) —— 简单，但并发/并行很少 细粒度 —— 更多的并发、竞争(race)和死锁 什么是爬虫？ 目标是获取所有网页，例如提供给索引器(indexer) 网页形成一个图(graph) 每个页面的多个链接 graph has cycles Crawler challenges 安排I / O并发 同时获取多个URL 增加每秒获取的URL 由于网络延迟远远超过网络容量 Fetch each URL only once 避免浪费网络带宽 对远程服务器很好 需要记住访问过的URL 知道什么时候完成 Crawler solutions： 串行爬虫： fetched map 避免重复、进入死循环 它是一个单一的映射，通过递归调用传递 一次只能爬取一页 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// 串行爬虫func Serial(url string, fetcher Fetcher, fetched map[string]bool) &#123; if fetched[url] &#123; // 已经爬取 return &#125; fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; for _, u := range urls &#123; Serial(u, fetcher, fetched) &#125; return&#125;func main() &#123; Serial("http://golang.org/", fetcher, make(map[string]bool))&#125; ConcurrentMutex爬虫： 为每个页面的爬取创建一个线程，因此可以并发爬取，爬取率更高 线程共享 fetched map Why the Mutex (== lock)? 没有锁： 两个网页包含指向同一URL的链接，导致两个线程同时获取这这个页面 T1、T2检查获取[url]，当两者都看到url尚未获取，两者都取，导致错误 同时读写（或写入+写入）是竞争 如果我注释掉Lock()/Unlock()调用会发生什么？ go run crawler.go go run -race crawler.go The lock causes the check and update to be atomic How does it decide it is done? sync.WaitGroup implicitly waits for children to finish recursive fetches 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt" "sync")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with shared state and Mutextype fetchState struct &#123; mu sync.Mutex fetched map[string]bool&#125;func makeState() *fetchState &#123; f := &amp;fetchState&#123;&#125; f.fetched = make(map[string]bool) return f&#125;func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) &#123; f.mu.Lock() if f.fetched[url] &#123; // 已经爬取 f.mu.Unlock() return &#125; f.fetched[url] = true f.mu.Unlock() urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; var done sync.WaitGroup for _, u := range urls &#123; done.Add(1) go func(u string) &#123; defer done.Done() //等价于defer done.Add(-1) ConcurrentMutex(u, fetcher, f) &#125;(u) &#125; done.Wait() //等待所有的goroutine完成 return&#125;func main() &#123; ConcurrentMutex("http://golang.org/", fetcher, makeState())&#125; ConcurrentChannel爬虫 Go channel： channel是一个对象,可能有很多个, ch：= make（chan int） channel允许一个线程将对象发送到另一个线程： ch &lt; - x，sender等待goroutine接收 y：= &lt; - ch; for y := range ch，receiver等待goroutine发送 可以用channel来进行通信和同步 多个线程可以在一个channel上发送和接收 在发送时握住锁可能很危险... ConcurrentChannel master（） master()创建一个worker goroutine来获取每个页面 worker()在channel上发送URL 多个worker在一个channel上发送 master()从channel中读取URL [图：主人，通道，工人] 无需锁定 fetched map，因为它不是共享的！ 有共享数据吗？ channel 通道上发送的切片和字符串 master()传递给worker()的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with channelsfunc worker(url string, ch chan []string, fetcher Fetcher) &#123; urls, err := fetcher.Fetch(url) if err != nil &#123; ch &lt;- []string&#123;&#125; &#125; else &#123; ch &lt;- urls &#125;&#125;func master(ch chan []string, fetcher Fetcher) &#123; n := 1 fetched := make(map[string]bool) for urls := range ch &#123; for _, u := range urls &#123; if fetched[u] == false &#123; fetched[u] = true n += 1 go worker(u, ch, fetcher) &#125; &#125; n -= 1 if n == 0 &#123; break &#125; &#125;&#125;func ConcurrentChannel(url string, fetcher Fetcher) &#123; ch := make(chan []string) go func() &#123; ch &lt;- []string&#123;url&#125; &#125;() master(ch, fetcher)&#125;func main() &#123; ConcurrentChannel("http://golang.org/", fetcher)&#125; **什么时候使用sharing和locks，而不是channels？** - 大多数问题都可以用任何一种方式解决 - 最有意义的取决于程序员的想法 state(状态) -- sharing and locks communication -- channels waiting for events -- channels - 使用Go的竞争检测器： [Data Race Detector](https://golang.org/doc/articles/race_detector.html) go test -race]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>RPC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx Notes]]></title>
    <url>%2F2019%2F03%2F22%2F2020-3-22%2F</url>
    <content type="text"><![CDATA[启动、停止和重启 启动、停止和重启# 12345678910111213141516nginxsystemctl start nginx.servicesystemctl start nginxps aux | grep nginxngxin -s quitnginx -s stopkillall nginxsystemctl stop nginx.servicesystemctl stop nginxnginx -s reloadsystemctl restart nginx.servicesystemctl restart nginxnetstat -tlnp]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go并发模式 (Cocurrency Pattern)]]></title>
    <url>%2F2019%2F02%2F10%2F2019-2-10%2F</url>
    <content type="text"><![CDATA[这篇博客的原创来自Go的官方博客，其中提供了丰富的关于Go的并发的相关资料。本文仅仅是对 Rob Pike 的演讲 Go Concurrency Patterns 和 Sameer Ajmani 的续集 Advanced Go Concurrency Patterns 的学习，相关内容的视频和ppt在网上都可以找到。 1. 函数返回 channel# 12345678910111213141516171819202122232425262728293031323334package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(3e3)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("boring!") // 通道作为返回的函数 for i := 0; i &lt; 5; i++ &#123; fmt.Printf("You say: %q\n", &lt;-c) &#125; fmt.Println("You're boring; I'm leaving.")&#125;输出：You say: "boring! 0"You say: "boring! 1"You say: "boring! 2"You say: "boring! 3"You say: "boring! 4"You're boring; I'm leaving. 2. 通道作为服务# 12345678910111213141516171819202122func main() &#123; joe := boring("Joe") ann := boring("Ann") for i := 0; i &lt; 5; i++ &#123; fmt.Println(&lt;-joe) fmt.Println(&lt;-ann) &#125; fmt.Println("You're both boring; I'm leaving.")&#125;输出：Joe 0Ann 0Joe 1Ann 1Joe 2Ann 2Joe 3Ann 3Joe 4Ann 4You're both boring; I'm leaving. 3.多重通道(扇入函数，fan-in function)# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &#125; &#125;() return c&#125;func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; fmt.Println("You're both boring; I'm leaving.")&#125; 4. 通道发送通道，使 goroutine 有序# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( "fmt" "math/rand" "time")type Message struct &#123; str string wait chan bool&#125;func boring(msg string) chan Message &#123; c := make(chan Message) waitForIt := make(chan bool) // 被所有 Message 共享 go func() &#123; for i := 0; ; i++ &#123; c &lt;- Message&#123;fmt.Sprintf("%s: %d", msg, i), waitForIt&#125; time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &lt;-waitForIt // 进入等待 &#125; &#125;() return c&#125;func fanIn(input1, input2 chan Message) chan Message &#123; c := make(chan Message) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 5; i++ &#123; msg1 := &lt;-c fmt.Println(msg1.str) msg2 := &lt;-c fmt.Println(msg2.str) // 当 Joe 和 Ann 的信息都收到后，才开放下一次消息接收 msg1.wait &lt;- true msg2.wait &lt;- true &#125;&#125; 5. select 语句# 使用 select 来写扇入函数，减少 goroutine 数量 123456789101112func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; select &#123; case s := &lt;-input1: c &lt;- s case s := &lt;-input2: c &lt;- s &#125; &#125; &#125;() return c&#125; select设置超时 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1500)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("Joe") for &#123; select &#123; case s := &lt;-c: fmt.Println(s) case &lt;-time.After(1 * time.Second): fmt.Println("You're too slow.") return &#125; &#125;&#125;输出：Joe 0Joe 1Joe 2Joe 3Joe 4You're too slow.]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL驱动]]></title>
    <url>%2F2018%2F12%2F31%2F2018-12-31%2F</url>
    <content type="text"><![CDATA[启动、以密码登入和创建数据库 windows: ubuntu: 编写Go文件 MySQL基础见菜鸟教程; 本文参考了astaxie/build-web-application-with-golang. 启动、以密码登入和创建数据库# windows:# 在bin目录下，运行(git-bash以管理员运行，加winpty) mysqld --remove 删除之前的mysql服务 mysqld -install mysql 安装windows服务，服务名称为mysql(任意取) mysqld --initialize-insecure 可无密码登陆root net start mysql 启动服务(关闭的命令是 net stop mysql) ubuntu:# service mysql start 启动服务 service mysql stop 关闭服务 service restart stop 重启服务 ps -ef | grep mysqld 查看mysql进程列表 执行如下SQL语句以密码登入 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; 或者编写 test.sql 创建 source test.sql 文件 编写Go文件# test.go 内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( "database/sql" "fmt" _ "github.com/go-sql-driver/mysql")func main() &#123; db, err := sql.Open("mysql", "root:123456@/test") //Linux用户名:MySQL密码@/数据库名test checkErr(err) stm, err := db.Prepare("DROP TABLE IF EXISTS userinfo;") //准备SQL语句，删除数据表 checkErr(err) _, err = stm.Exec() //Excute, 执行语句 checkErr(err) stm, err = db.Prepare(`CREATE TABLE userinfo ( uid INT(10) NOT NULL AUTO_INCREMENT, name VARCHAR(64) NOT NULL DEFAULT '匿名', city VARCHAR(64) NULL DEFAULT '不详', moment DATE NOT NULL DEFAULT '1949-10-10', PRIMARY KEY (uid) ) DEFAULT CHARSET=utf8;`) //创建数据表，设置utf8以支持中文字符 checkErr(err) _, err = stm.Exec() checkErr(err) //增加数据 stm, err = db.Prepare("INSERT userinfo SET name=?, city=?, moment=?") //准备SQL语句 checkErr(err) _, err = stm.Exec("诸葛亮", "山东临沂", "234-10-8") //Excute, 传入参数并执行 checkErr(err) _, err = stm.Exec("关羽", "山西运城", "220-1-1") checkErr(err) _, err = stm.Exec("荀彧", "河南许昌", "212-1-1") checkErr(err) stm, err = db.Prepare("INSERT userinfo SET city=?") checkErr(err) res, err := stm.Exec("河南禹州") id, err := res.LastInsertId() checkErr(err) fmt.Println("最后插入的用户序号为:", id) //查询数据 rows, err := db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; //删除数据 stm, err = db.Prepare("DELETE FROM userinfo WHERE uid=?") checkErr(err) res, err = stm.Exec(2) checkErr(err) fmt.Println("删除了第2行") //更改数据 stm, err = db.Prepare("UPDATE userinfo SET name=? WHERE uid=? OR uid=?") checkErr(err) res, err = stm.Exec("郭嘉", id-1, id) checkErr(err) affect, err := res.RowsAffected() checkErr(err) fmt.Println("总共有", affect, "行的信息发生了更改") //查询数据 rows, err = db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; db.Close()&#125;func checkErr(err error) &#123; if err != nil &#123; panic(err) &#125;&#125; 运行结果： 进入MySQL查看数据表：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构]]></title>
    <url>%2F2018%2F12%2F20%2F2018-12-20%2F</url>
    <content type="text"><![CDATA[3.4 顺序存储结构 3.6 链式存储结构 3.11 单链表结构与顺序存储结构 3.12 静态链表 3.13 循环链表 3.14 双向链表 4.2 栈 4.10 队列 4.12 循环队列 6.4 树的存储结构 6.5.2 特殊二叉树 6.6 二叉树性质 6.8 遍历二叉树 6.8.6 推导遍历结果 6.10 线索二叉树 6.11.1 树转换为二叉树 6.12 赫夫曼树 7.4.1 邻接矩阵(adjacency matrix) 7.4.2 邻接表 7.5.1 深度优先遍历(Depth First Search) 7.5.2 广度优先遍历(Breadth First Search) 8.4.1 二分查找 8.6 二叉查找树(Binary Sort Tree) 8.6.2 二叉查找树插入 8.6.3 二叉查找树删除 8.7 平衡二叉树(AVL树) 9.2.1 排序的稳定性 9.2.2 内排序和外排序 9.3.2 冒泡排序算法(Bubble Sort) 9.3.3 冒泡排序优化 9.4.1 简单选择排序(Simple Selection Sort) 9.5.1 直接插入排序(Straight Insertion Sort) 9.6 希尔排序(Shell Sort) 9.7 堆排序 9.8 归并排序 9.9 快速排序 3.4 顺序存储结构# 数值data(起始位置)；数组长度MaxSize；线性表长度length LOC($a_{i}$)=LOC($a_{1}$)+(i-1)c 3.6 链式存储结构# 单链表，每个节点只包含一个指针域 头指针，头节点，第一个节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( "fmt")type Node struct &#123; data string next *Node&#125;type LinkList struct &#123; length int head *Node rear *Node&#125;func NewLinkList(head *Node) *LinkList &#123; return &amp;LinkList&#123;0, head, head&#125;&#125;func (this *LinkList) Append(data string) &#123; if this.rear == nil &#123; return &#125; node := &amp;Node&#123;data: data&#125; this.rear.next = node this.rear = node this.length++&#125;func (this *LinkList) Reverse() *LinkList &#123; head := this.head if head == nil || head.next == nil &#123; return this &#125; var pre *Node = nil cur := head.next //head不为空时，当前为第1节点 this.rear = head.next //第1节点不为空时，作为最后节点 for cur != nil &#123; cur.next, pre, cur = pre, cur, cur.next //buf := cur.next //cur.next = pre //pre = cur //cur = buf &#125; head.next = pre //指向第最后一个节点 return this&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.Append("4") bl.Reverse() for node := bl.head; node != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125;&#125;&gt; Output:command-line-arguments 4 3 2 1 3.11 单链表结构与顺序存储结构# 内存分配；时间复杂度(查找，插入和删除)；空间复杂度 3.12 静态链表# 3.13 循环链表# 尾指针rear 头节点rear-&gt;next 第一个节点rear-&gt;next-&gt;next 合并： p=rearA-&gt;next q=rearB-&gt;next rearA-&gt;next=rearB-&gt;next-&gt;next rearB-&gt;next=p free(q) 3.14 双向链表# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")type Node struct &#123; data string pre *Node next *Node&#125;type BiLinkList struct &#123; length int head *Node rear *Node&#125;func NewBiLinkList(head *Node) *BiLinkList &#123; return &amp;BiLinkList&#123;0, head, head&#125;&#125;func (this *BiLinkList) Append(data string) &#123; node := &amp;Node&#123;data: data&#125; this.rear.next = node node.pre = this.rear this.rear = node this.length++&#125;func (this *BiLinkList) InsertNext(p *Node, e string) &#123; //省略判断 nd 不为空且属于链表 if p.next == nil &#123; this.Append(e) &#125; else &#123; s := &amp;Node&#123;data: e&#125; s.pre = p s.next = p.next p.next.pre = s p.next = s &#125; this.length++&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewBiLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.InsertNext(head.next.next, "2.5") //for i := 0; i &lt; bl.length; i++ &#123; // fmt.Print(head.next.data, " ") // head = head.next //&#125; for node := bl.head; node.next != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125; fmt.Print(bl.rear.data) //打印末节点&#125;&gt; Output:command-line-arguments 1 2 2.5 3 使用标准库 1234567891011121314151617181920212223package mainimport ( "container/list" "fmt")func main() &#123; bl := list.New() for i := 1; i &lt; 4; i++ &#123; bl.PushBack(i) &#125; head := bl.Front() rear := bl.Back() for p := head; p != rear; p = p.Next() &#123; fmt.Print(p.Value, " ") &#125; fmt.Print(rear.Value)&#125;&gt; Output:command-line-arguments1 2 3 4.2 栈# 123依次进栈，出栈次序不可能有312(12同时在栈中,2一定先出) s-&gt;top 栈顶指针 栈顶指针为-1表示控栈 s-&gt;data[s-&gt;top]栈顶元素 12345678910111213type Stack struct &#123; //用于存放 int 的栈 nums []int&#125;func (this *Stack) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Stack) Pop() int &#123; res := this.nums[len(this.nums)-1] this.nums = this.nums[:len(this.nums)-1] return res&#125; 4.10 队列# 12345678910111213type Queue struct &#123; //Queue 是用于存放 int 的队列 nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125; 4.12 循环队列# 队列满的条件: (rear+1)%QueueSize == front 队列长度:(rear-front+QueueSize)%QueueSize 6.4 树的存储结构# 双亲表示(数组)，孩子兄弟表示(数组)，孩子表示(数组+链表) 6.5.2 特殊二叉树# 斜树，满二叉树，完全二叉树 6.6 二叉树性质# 总结点数：$n=n_{0}+n_{1}+n_{2}$ 分支线总数： $n-1=n_{1}+2n_{2}$ 完全二叉树深度：$[log_{2}n]+1$ 完全二叉树按层序排号：节点$i$的左节点为$2i$ 6.8 遍历二叉树# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func main() &#123; node9 := &amp;BinaryTree&#123;data: "I"&#125; node8 := &amp;BinaryTree&#123;data: "H"&#125; node7 := &amp;BinaryTree&#123;data: "G"&#125; node6 := &amp;BinaryTree&#123;data: "F"&#125; node5 := &amp;BinaryTree&#123;data: "E", right: node9&#125; node4 := &amp;BinaryTree&#123;"D", node7, node8&#125; node3 := &amp;BinaryTree&#123;"C", node5, node6&#125; node2 := &amp;BinaryTree&#123;data: "B", left: node4&#125; root := &amp;BinaryTree&#123;"A", node2, node3&#125; PreOrderRec(root) fmt.Println() MidOrderRec(root) fmt.Println() PostOrderRec(root)&#125;&gt; Output:command-line-argumentsA B D G H C E I F G D H B A E I C F G H D B I E F C A 6.8.6 推导遍历结果# 前序遍历序列+中序遍历序列-&gt;二叉树 后序遍历序列+中序遍历序列-&gt;二叉树 前中后：BAC ABC ACB 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func PreMid2Tree(pre, mid []string) *BinaryTree &#123; //前序+中序推导二叉树 if len(pre) != len(mid) &#123; panic("两个切片的长度不相等") &#125; if len(mid) == 0 &#123; return nil &#125; root := &amp;BinaryTree&#123; //前序第一个元素为root data: pre[0], &#125; if len(mid) == 1 &#123; return root &#125; position := IndexOf(root.data, mid) //找出root在中序的位置 root.left = PreMid2Tree(pre[1:position+1], mid[:position]) //递归 root.right = PreMid2Tree(pre[position+1:], mid[position+1:]) return root&#125;func IndexOf(ele string, seq []string) int &#123; for i, v := range seq &#123; if v == ele &#123; return i &#125; &#125; panic("IndexOf错误，元素不存在")&#125;func main() &#123; bt := PreMid2Tree([]string&#123;"A", "B", "D", "G", "H", "C", "E", "I", "F"&#125;, []string&#123;"G", "D", "H", "B", "A", "E", "I", "C", "F"&#125;) PostOrderRec(bt)&#125;&gt; Output:command-line-argumentsG H D B I E F C A 6.10 线索二叉树# 将节点的空指针改为指向在遍历序列中的前驱或后继的指针。 12345678910111213141516171819202122232425262728293031type ThreadBiTree struct &#123; data string left *ThreadBiTree right *ThreadBiTree lTag *ThreadBiTree //一个bit位，区分是指向孩子还是线索 rTag *ThreadBiTree&#125;var pre *ThreadBiTree //保存前驱func MidThreading(bt *ThreadBiTree) &#123; //中序遍历线索化 if bt == nil &#123; return &#125; MidThreading(bt.left) if bt.left == nil &#123; //若bt有左空指针，则把pre设为bt的前驱，并设置标志位 bt.left = pre bt.lTag = 1 &#125; if bt.right == nil &#123; //若bt有右空指针，则把bt设为pre的后继，并设置标志位 pre.right = bt pre.rTag = 1 &#125; pre = bt MidThreading(bt.right)&#125; 6.11.1 树转换为二叉树# 兄弟连线；只保留第一个孩子的连线 6.12 赫夫曼树# 带权路径长度(WPL)最小的二叉树 WPL(a)= 51+152+403+304+104 WPL(b)= 53+153+402+302+102 构造 排序：A5, E10, B15, D30, C40 7.4.1 邻接矩阵(adjacency matrix)# 无向图： 有向图： 有向网： 无向网的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport ( "fmt")const ( INFINITY int32 = 65536 // 无穷)type Edge struct &#123; //边的顶点和权值 v0 string v1 string weight int32&#125;type Graph struct &#123; //无向网 v []string //顶点数组 e []Edge //边的权值&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjMatrix() [][]int32 &#123; vertexNum := len(this.v) adjM := make([][]int32, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int32, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; if j == i &#123; adjM[i][j] = 0 &#125; else &#123; adjM[i][j] = INFINITY &#125; &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = edge.weight adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = edge.weight //因为是无向图所以是对称矩阵 &#125; return adjM&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D"&#125; e := []Edge&#123; Edge&#123;"A", "B", 5&#125;, Edge&#123;"A", "C", 3&#125;, Edge&#123;"A", "D", 6&#125;, Edge&#123;"B", "C", 7&#125;, Edge&#123;"C", "D", 9&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向网 fmt.Println(graph.AdjMatrix()) // A B C D //A [ 0 5 3 6 ] //B [ 5 0 7 65536 ] //C [ 3 7 0 9 ] //D [ 6 65536 9 0 ]&#125;&gt; Output:command-line-arguments[[0 5 3 6] [5 0 7 65536] [3 7 0 9] [6 65536 9 0]] 7.4.2 邻接表# 无向图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func main() &#123; v := []string&#123;"v0", "v1", "v2", "v3"&#125; e := []Edge&#123; Edge&#123;"v0", "v1"&#125;, Edge&#123;"v0", "v2"&#125;, Edge&#123;"v0", "v3"&#125;, Edge&#123;"v1", "v2"&#125;, Edge&#123;"v2", "v3"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(node.adjvex, " ") &#125; fmt.Println() &#125;&#125;&gt; Output:command-line-argumentsv0 1 2 3 v1 0 2 v2 0 1 3 v3 0 2 有向网： 7.5.1 深度优先遍历(Depth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package mainimport ( "fmt")var flag []bool //全局变量type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;func (this *Graph) AdjMatrix() [][]int &#123; vertexNum := len(this.v) adjM := make([][]int, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; adjM[i][j] = 0 &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = 1 adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = 1 &#125; return adjM&#125;func IndexOfVertex(vs []string, v string) int &#123; for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func DFSTraverse(adjM [][]int) &#123; //输入无向图的邻接矩阵 vertexNum := len(adjM) flag = make([]bool, vertexNum) //初始化flag，注意这里不能用 := for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; for i := 0; i &lt; vertexNum; i++ &#123; //对未访问的节点执行深度搜索 if !flag[i] &#123; DFS(vertexNum, i, adjM) &#125; &#125;&#125;func DFS(vertexNum int, i int, adjM [][]int) &#123; flag[i] = true fmt.Print(i, " ") //打印被访问的节点序号 for j := 0; j &lt; vertexNum; j++ &#123; //对未被访问的邻节点递归 if adjM[i][j] == 1 &amp;&amp; !flag[j] &#123; DFS(vertexNum, j, adjM) &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjM := graph.AdjMatrix() for i := 0; i &lt; len(adjM); i++ &#123; fmt.Println(adjM[i]) &#125; fmt.Println("-------------------") DFSTraverse(adjM)&#125;&gt; Output:command-line-arguments[0 1 0 0 0 1 0 0 0][1 0 1 0 0 0 1 0 1][0 1 0 1 0 0 0 0 1][0 0 1 0 1 0 1 0 0][0 0 0 1 0 1 0 1 0][1 0 0 0 1 0 1 0 0][0 1 0 1 0 1 0 1 0][0 0 0 0 1 0 1 0 0][0 1 1 0 0 0 0 0 0]-------------------0 1 2 3 4 5 6 7 8 7.5.2 广度优先遍历(Breadth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;type Queue struct &#123; nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func BFSTraverse(adjL []LinkList) &#123; //输入邻接表 vertexNum := len(adjL) flag := make([]bool, vertexNum) //标记被访问的节点 for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; Q := new(Queue) //队列 for i := 0; i &lt; vertexNum; i++ &#123; if !flag[i] &#123; //如果顶点未被访问 flag[i] = true Q.Push(i) for len(Q.nums) &gt; 0 &#123; //队列不为空 j := Q.Pop() fmt.Print(adjL[j].head.data, " ") //打印节点 for node := adjL[j].head.firstedge; node != nil; node = node.next &#123; if flag[node.adjvex] == false &#123; flag[node.adjvex] = true Q.Push(node.adjvex) &#125; &#125; &#125; &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(adjL[node.adjvex].head.data, " ") &#125; fmt.Println() &#125; fmt.Println("-----------------") BFSTraverse(adjL)&#125;&gt; Output:command-line-argumentsA B F B A C G I C B D I D C G E E F D H F A G E G B F D H H G E I B C -----------------A B F C G I E D H 8.4.1 二分查找# 123456789101112131415161718192021222324252627282930313233package mainimport ( "fmt")func BiSearch(a []int, n, key int) int &#123; var low, high, mid int low = 1 high = n for low &lt;= high &#123; mid = (low + high) / 2 //mid = low + (high-low)(key-1)/(99-1) 插值 if key == a[mid] &#123; return mid &#125; else if key &lt; a[mid] &#123; high = mid - 1 &#125; else &#123; low = mid + 1 &#125; &#125; return 0&#125;func main() &#123; a := []int&#123;0, 1, 16, 24, 35, 47, 59, 62, 73, 88, 99&#125; fmt.Println(BiSearch(a, 10, 62))&#125;&gt; Output:command-line-arguments7 8.6 二叉查找树(Binary Sort Tree)# 左小右大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func SearchBST(root *BinaryTree, key int) bool &#123; if root == nil &#123; return false &#125; switch &#123; case key &lt; root.data: return SearchBST(root.left, key) case key &gt; root.data: return SearchBST(root.right, key) default: return true &#125;&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(SearchBST(root, 73), " ") fmt.Print(SearchBST(root, 99), " ") fmt.Print(SearchBST(root, 37), " ") fmt.Print(SearchBST(root, 48), " ") fmt.Print(SearchBST(root, 100))&#125;&gt; Output:command-line-argumentstrue true true false false 8.6.2 二叉查找树插入# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(root.right.right.left.data, root.right.right.left.right, " ") _, root = InsertBST(root, 95) fmt.Print(root.right.right.left.right.data)&#125;&gt; Output:command-line-arguments93 &lt;nil&gt; 95 8.6.3 二叉查找树删除# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;//删除data为key的节点，并返回该二叉树的根节点。func DeleteBST(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return nil &#125; switch &#123; case key &gt; root.data: //在右子树中 root.right = DeleteBST(root.right, key) case key &lt; root.data: //在左子树中 root.left = DeleteBST(root.left, key) default: //key == root.data if root.left == nil &amp;&amp; root.right == nil &#123; //该节点为叶节点 return nil &#125; else if root.left == nil &amp;&amp; root.right != nil &#123; //该节点仅有右子树 return root.right &#125; else if root.left != nil &amp;&amp; root.right == nil &#123; //该节点仅有左子树 return root.left &#125; else &#123; //该节点有左、右子树 success := FindMin(root.right) //找到key的后继节点,即48 root.right = DeleteBST(root.right, success) root.data = success &#125; &#125; return root&#125;//找到BST中data最小的节点func FindMin(root *BinaryTree) int &#123; if root.left == nil &#123; //最小值在根节点 return root.data &#125; return FindMin(root.left) //最小值在左子树&#125;func main() &#123; node16 := &amp;BinaryTree&#123;data: 50&#125; node15 := &amp;BinaryTree&#123;data: 48&#125; node14 := &amp;BinaryTree&#123;data: 36&#125; node13 := &amp;BinaryTree&#123;data: 56&#125; node12 := &amp;BinaryTree&#123;49, node15, node16&#125; node11 := &amp;BinaryTree&#123;data: 37, left: node14&#125; node10 := &amp;BinaryTree&#123;data: 29&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;51, node12, node13&#125; node7 := &amp;BinaryTree&#123;35, node10, node11&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; root = DeleteBST(root, 47) NewNode := root.left.left fmt.Print(NewNode.data, " ") //打印代替删除位置的新节点 fmt.Print(NewNode.left.data, NewNode.right.data)&#125;&gt; Output:command-line-arguments48 35 51 8.7 平衡二叉树(AVL树)# 平衡因子(BF)=左子树的深度-右子树的深度 旋转： 123456789//右旋func RRotate(k2 *BinaryTree) *BinaryTree &#123; k1 := k2.left y := k1.right k1.right = k2 k2.left = y return k1&#125; 双旋转： 12345//左右旋转func LRRotate(k3 *BinaryTree) *BinaryTree &#123; k3.left = LRotate(k3.left) return RRotate(k3)&#125; 将任意二叉树一次性调整AVL 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185package mainimport ( "fmt")type BinaryTree struct &#123; data int bf int //Balance Factor left *BinaryTree right *BinaryTree&#125;//右旋func R_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.left b := a.right a.right = root root.left = b return a&#125;//左旋func L_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.right b := a.left a.left = root root.right = b return a&#125;//左右旋转func LR_Rotate(root *BinaryTree) *BinaryTree &#123; root.left = L_Rotate(root.left) return R_Rotate(root)&#125;//右左旋转func RL_Rotate(root *BinaryTree) *BinaryTree &#123; root.right = R_Rotate(root.right) return L_Rotate(root)&#125;//将任意二叉树转化成AVLfunc Balance(root *BinaryTree) *BinaryTree &#123; a := &amp;BinaryTree&#123;left: root&#125; //给二叉树生成一个父母节点 _, isAVL := Bal(root) //调整二叉树的子树并判断二叉树是否平衡 for !isAVL &#123; Bal(a) //处理a的左子树，即二叉树 _, isAVL = Bal(a.left) //判断二叉树是否平衡 &#125; return a.left //返回二叉树&#125;//调整子树func Bal(root *BinaryTree) (int, bool) &#123; if root == nil &#123; return 0, true &#125; leftHeight, leftIsBalanced := Bal(root.left) rightHeight, rightIsBalanced := Bal(root.right) if !leftIsBalanced &#123; root.left = Rotate(root.left) //调整左子树 leftHeight = UpdateBF(root.left) //刷新左子树的BF和高度 &#125; if !rightIsBalanced &#123; root.right = Rotate(root.right) rightHeight = UpdateBF(root.right) &#125; root.bf = leftHeight - rightHeight //计算本身的BF if Abs(root.bf) &lt;= 1 &#123; return Max(leftHeight, rightHeight) + 1, true &#125; return Max(leftHeight, rightHeight) + 1, false&#125;//对不平衡树进行旋转调整func Rotate(root *BinaryTree) *BinaryTree &#123; if root.bf &gt; 0 &#123; //左边太重，需要右旋 if root.left.bf &lt; 0 &#123; return LR_Rotate(root) &#125; return R_Rotate(root) &#125; if root.right.bf &gt; 0 &#123; return RL_Rotate(root) &#125; return L_Rotate(root)&#125;func UpdateBF(root *BinaryTree) int &#123; if root == nil &#123; return 0 &#125; leftHeight := UpdateBF(root.left) rightHeight := UpdateBF(root.right) root.bf = leftHeight - rightHeight return Max(leftHeight, rightHeight) + 1&#125;func Max(a, b int) int &#123; if a &gt; b &#123; return a &#125; return b&#125;func Abs(a int) int &#123; if a &gt; 0 &#123; return a &#125; return -a&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func PrintBF(root *BinaryTree) &#123; if root == nil &#123; return &#125; PrintBF(root.left) fmt.Print(root.bf, " ") PrintBF(root.right)&#125;func main() &#123; root := &amp;BinaryTree&#123;data: 1&#125; InsertBST(root, 7) InsertBST(root, 2) InsertBST(root, 4) InsertBST(root, 8) InsertBST(root, 3) InsertBST(root, 10) InsertBST(root, 5) InsertBST(root, 9) InsertBST(root, 6) UpdateBF(root) PrintBF(root) //二叉树的BF fmt.Println() PrintBF(Balance(root)) //平衡调整后的二叉树的BF&#125;&gt; Output:command-line-arguments-5 -3 0 -1 -1 0 1 -2 0 1 0 0 0 -1 -1 0 0 0 0 0 9.2.1 排序的稳定性# 9.2.2 内排序和外排序# 内排序是在排序的整个过程中，待排序的所有记录全部在内存中。外排序的整个过程则需要在内外存之间交换数据。 9.3.2 冒泡排序算法(Bubble Sort)# 冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改 变，所以冒泡排序是一种稳定排序算法。 12345678910111213141516171819202122232425262728package mainimport ( "fmt")package mainimport ( "fmt")func BubbleSort(a []int) &#123; length := len(a) for i := 1; i &lt; length-1; i++ &#123; //需要交换(length-2)次，从后往前排 for j := 1; j &lt; length-i; j++ &#123; //当i=1时，j可以取到(length-2) if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort(a) fmt.Println(a)&#125; 递归实现. for 循环找出最大值排到末尾，去掉末尾把对新的序列递归 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot;)func RecurBubble(a []int) &#123; length := len(a) if length &lt; 3 &#123; //递归跳出条件 return &#125; for j := 1; j &lt;= length-2; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; a = a[0 : length-1] //不包括第 length-1 个元素 RecurBubble(a)&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; RecurBubble(a) fmt.Println(a)&#125; 9.3.3 冒泡排序优化# 123456789101112131415161718192021222324252627package mainimport ( "fmt")func BubbleSort2(a []int) &#123; flag := true // 有数据交换 length := len(a) for i := 1; i &lt; length-1 &amp;&amp; flag; i++ &#123; flag = false for j := 1; j &lt; length-i; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] flag = true &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort2(a) fmt.Println(a)&#125; 9.4.1 简单选择排序(Simple Selection Sort)# 复杂度与冒泡排序同为$O(n^{2})$,但性能更优(数据交换次数更少)。选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; var min int length := len(a) for i := 1; i &lt; length-1; i++ &#123; //插入次数(length-2)，从前往后排；把后面序列中较小的数插 min = i // 循环找出序列中的最小数的下标 for j := i + 1; j &lt; length; j++ &#123; //j取到i后的所有数 if a[j] &lt; a[min] &#123; //之后有更小的数 min = j &#125; &#125; if i != min &#123; //下标改变，交换，防止数据丢失 a[i], a[min] = a[min], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 反过来排 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot;)func SelectionSort(a []int) &#123; var max int length := len(a) for i := length - 1; i &gt; 0; i-- &#123; 从大到小排 max = i for j := 1; j &lt; i; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != i &#123; a[i], a[max] = a[max], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 递归 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; length := len(a) if length &lt; 3 &#123; return &#125; max := length - 1 for j := 1; j &lt; length-1; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != length-1 &#123; a[length-1], a[max] = a[max], a[length-1] &#125; SelectionSort(a[:length-1])&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 9.5.1 直接插入排序(Straight Insertion Sort)# 插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开 始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳 定的。 复杂度同为为$O(n^{2})$，性能：插入排序&gt;选择排序&gt;冒泡排序 123456789101112131415161718192021222324252627package mainimport ( "fmt")func InsertionSort(a []int) &#123; length := len(a) var j int for i := 2; i &lt; length; i++ &#123; //第二个数到最后一个数 if a[i] &lt; a[i-1] &#123; //第i个数比前面的数小，需要插入 a[0] = a[i] //哨兵 for j = i - 1; a[j] &gt; a[0]; j-- &#123; //j取 i-1 到 1 a[j+1] = a[j] //将大于第i个数的数后移一位，留出空位 &#125; a[j+1] = a[0] //将第i个数放入空位 &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; InsertionSort(a) fmt.Println(a)&#125; 9.6 希尔排序(Shell Sort)# 希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 12345678910111213141516171819202122232425262728293031package mainimport ( "fmt")func ShellSort(a []int) &#123; var i, j int length := len(a) - 1 //去掉第0位 inc := length //增量 for inc &gt; 1 &#123; inc = inc/3 + 1 for i = 1 + inc; i &lt;= length; i++ &#123; //第(1+inc)个数到最后一个数 if a[i] &lt; a[i-inc] &#123; a[0] = a[i] for j = i - inc; j &gt; 0 &amp;&amp; a[j] &gt; a[0]; j -= inc &#123; a[j+inc] = a[j] &#125; a[j+inc] = a[0] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; ShellSort(a) fmt.Println(a)&#125; 9.7 堆排序# 时间复杂度$O(nlogn)$ 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func HeapSort(a []int) &#123; length := len(a) - 1 //循环后a[1]为最大值 for i := length / 2; i &gt; 0; i-- &#123; //(length/2)是最后一个节点的父节点到根节点 HeapAdjust(a, i, length) &#125; for i := length; i &gt; 1; i-- &#123; //从最后节点到第二个节点 a[1], a[i] = a[i], a[1] //排序第i位 HeapAdjust(a, 1, i-1) //将1到i-1中的最大数放到a[1] &#125;&#125;func HeapAdjust(a []int, s, m int) &#123; var temp, j int temp = a[s] for j = 2 * s; j &lt;= m; j *= 2 &#123; //以s为父节点开始 if j &lt; m &amp;&amp; a[j] &lt; a[j+1] &#123; //取出较大的孩子节点 j = j + 1 &#125; if temp &gt;= a[j] &#123; //父节点已经最大 break &#125; a[s] = a[j] //将最大的值替换给父节点 s = j //将当前节点作为父节点，进行下一轮操作 &#125; a[s] = temp&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; HeapAdjust(a, 1, 9) fmt.Println(a)&#125; 9.8 归并排序# 归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有 序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结 果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 递归方法 Merge()归并排序示意图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")// 将a排序到bfunc MergeSort(a []int) []int &#123; length := len(a) b := make([]int, length) MSort(a, b, 1, length-1) return b&#125;func MSort(a, b []int, s, t int) &#123; if s == t &#123; b[s] = a[s] //将a复制到到b &#125; else &#123; m := (s + t) / 2 MSort(a, b, s, m) MSort(a, b, m+1, t) Merge(b, s, m, t) //将b归并排序 &#125;&#125;func Merge(SR []int, i, m, n int) &#123; TR := make([]int, len(SR)) //归并的序列暂存到TR s := i //保存起始位置 j := m + 1 k := i //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p] &#123; SR[p] = TR[p] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16&#125; fmt.Println(MergeSort(a))&#125; 非递归方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt")func MergeSort2(a []int) &#123; length := len(a) - 1 for k := 1; k &lt; length; &#123; MergePass(a, k, length) k = k * 2 &#125;&#125;func MergePass(a []int, s, n int) &#123; i := 1 for i &lt;= n-2*s+1 &#123; Merge2(a, i, i+s-1, i+2*s-1) //i+2*s-1&lt;=n i = i + 2*s &#125; if i &lt; n-s+1 &#123; //n&gt;i+s-1,归并最后两个子块 Merge2(a, i, i+s-1, n) &#125;&#125;func Merge2(SR []int, i, m, n int) &#123; TR := make([]int, n-i+1) //与Merge相比栈空间更小 s := i //保存起始位置 j := m + 1 k := 0 //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p-s] &#123; SR[p] = TR[p-s] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16, 3, 41, 7, 55, 21&#125; MergeSort2(a) fmt.Println(a)&#125; 9.9 快速排序# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport ( "fmt")func QuickSort(a []int) &#123; Qsort(a, 1, len(a)-1)&#125;func Qsort(a []int, low, high int) &#123; if low &lt; high &#123; pivot := Partition(a, low, high) Qsort(a, low, pivot-1) Qsort(a, pivot+1, high) &#125;&#125;func Partition(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low], a[high] = a[high], a[low] //将a[hign]放到pivoValue左边 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[low], a[high] = a[high], a[low] //将a[low]放到pivoValue右边 &#125; return low&#125;func Partition2(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low] = a[high] //将a[hign]放到较低的位置 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[high] = a[low] //将a[low]放到较高的位置 &#125; a[low] = pivotValue return low&#125;func main() &#123; a := []int&#123;0, 50, 10, 90, 30, 70, 40, 80, 60, 20&#125; QuickSort(a) fmt.Println(a)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go内存模型]]></title>
    <url>%2F2018%2F11%2F14%2F2018-11-14%2F</url>
    <content type="text"><![CDATA[1. 什么是 Go内存模型？ 2. Happens Before 3. Synchronization 3.1 Initialization 3.2 Goroutine creation 3.3 Goroutine destruction 3.4 Channel communication 3.5 Locks 3.6 Once 4. Incorrect synchronization 本文主要翻译自官方文档 The Go Memory Model 1. 什么是 Go内存模型？# 我们知道不同的 goroutine 可以对同一个变量进行读写操作。Go内存模型指定了在什么样的条件下可以保证一个 goroutine 写入到变量的值可以被另外一个 goroutine 正确的读取。 2. Happens Before# 在单个 goroutine 中，读、写操作按照程序设计的顺序进行。需要注意的是，在不改变 goroutine 程序行为的前提下，这些读、写顺序在编译的过程中可能会被重排。因此导致对相同变量的读、写操作在不同的 goroutine 看来执行顺序可能不同。例如，如果在某个 goroutine 中执行 a = 1; b = 2;，另一个 goroutine 可能观察到变量 b 比 a 先被赋值。 Happens Before 是针对Go语言编程中内存操作的一种局部排序。 如果 $e_{1}$ happens before $e_{2}$，那么也可以说 $e_{2}$ happens after $e_{1}$。进一步，如果 $e_{1}$ 既不 happens before $e_{2}$，也不 happens after $e_{2}$，那么我们称 $e_{1}$ 和 $e_{2}$ happen concurrently (并发)。 在单个 goroutine 中，Happens Before顺序就是程序设计的顺序 $v$：某个变量 $w$: 对$v$的写 $w'$: 对$v$的写，不同于$w$ $r$: 对$v$的读 $w$可以被$r$获取的条件： $r$ 不 happen before $w$. (包括 happen after 和 happen concurrently) 不存在另一个 $w'$ happens after $w$ but before $r$. $w$保证能被$r$获取的条件(该条件不允许$w'$与$w$或者$r$并发，因此比上面的条件更强): $w$ happens before $r$. 任何其它的 $w'$ 要么 happens before $w$，要么 happens after $r$. 当有多个 goroutine 可以访问$v$时，必须利用同步事件(synchronization events)来建立 happens before 以保证 $r$能够获取想要的$w$。 在初始化过程中，赋给$v$以其类型的零值的操作可以看作是内存模型中的一种$w$ 3. Synchronization# 3.1 Initialization# 程序的初始化在一个 goroutine 中进行，并且在该 goroutine 中还可以创建其它的 goroutine 如果包 $p$导入了包$q$，那么包$q$在被导入之前就完成了初始化，函数main.main在所有的init函数完成后开始执行，见astaxie的main函数和init函数一文 3.2 Goroutine creation# 启动一个新的 goroutine 的 Go声明发生在该 goroutine开始执行之前 12345678910111213141516package mainvar a stringfunc f() &#123; print(a)&#125;func hello() &#123; a = "hello, world" go f()&#125;func main() &#123; hello()&#125; 调用hello()将会在未来某个时间点( 可能在hello()返回之后 )打印hello, world 3.3 Goroutine destruction# 无法保证 goroutine 在其创建程序中的某个位置退出 123456var a stringfunc hello() &#123; go func() &#123; a = "hello" &#125;() print(a)&#125; 对 a 的写(赋值)没有进行任何同步操作，无法被其它 goroutine 获取，在激进的编译器中甚至可能会删除整个 go 声明。 3.4 Channel communication# 通道通信(channel communication)是同步两个 goroutine 的主要方法。 send 发生在完成相应的 receive 之前 程序： 12345678910111213141516var c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" c &lt;- 0 // send&#125;func main() &#123; go f() &lt;-c // receive print(a)&#125;&gt; Output:command-line-argumentshello, world 会保证打印 hello, world，因为： 对 a 的写 happens before 通道 c 的 send 通道 c 的 send happens before 通道 c 的 receive 通道 c 的 receive happens before print(a)，因此 , 对 a 的写 happens before print(a), 即保证 main() 获取了 goroutine 对 a的写 channel 的关闭发生在完成 receive(此时得到的是通道类型的零值)之前 123456789101112131415161718package mainvar c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" close(c) // 关闭&#125;func main() &#123; go f() print(a, "\n", &lt;-c) // receive&#125;&gt;Output:command-line-argumentshello, world0 无缓存通道的 receive 发生在完成 send 之前 调换 c &lt;- 0 // send 和 &lt;-c // receive的位置，得到程序 123456789101112131415var c = make(chan int)var a stringfunc f() &#123; a = "hello, world" &lt;-c //receive&#125;func main() &#123; go f() c &lt;- 0 // send print(a)&#125;&gt; Output:command-line-argumentshello, world 仍然保证打印 hello, world 但如果channel具有缓存，例如当c = make(chan int, 1)，那么程序无法保证打印 hello, world 当通道的容量为$c$时，第 $k$ 次 receive 发生在完成第 $k+c$ 次 send 之前 下面的程序给 work 的每个条目(函数类型)启动一个 goroutine，由于通道limit的容量为3，因此最多允许3个 goroutine 调用调用了函数w() 1234567891011var limit = make(chan int, 3)func main() &#123; for _, w := range work &#123; go func(w func()) &#123; limit &lt;- 1 w() &lt;-limit &#125;(w) &#125;&#125; 3.5 Locks# sync 包实现了两种 lock 数据类型, sync.Mutex和 sync.RWMutex. 对任意的 sync.Mutex 或者 sync.RWMutex变量 l且$n&lt;m$，第$n$次调用 l.Unlock() 发生在 第 $m$次调用 l.Lock()返回之前 程序 1234567891011121314151617181920212223package mainimport ( "sync")var l sync.Mutexvar a stringfunc f() &#123; a = "hello, world" l.Unlock() //第一次 l.Unlock()&#125;func main() &#123; l.Lock() go f() l.Lock() //第二次 l.Lock() print(a)&#125;&gt; Output:command-line-argumentshello, world 保证打印hello, world，因为， 第一次 l.Unlock() happens before 第二次 l.Lock() 返回 第二次 l.Lock() 返回 happens before print(a) 对于任意的l.RLock，存在$k$满足： 第 $k$ 次调用 l.Unlock happens before l.RLock； 与l.RLock对应的l.RUnlock happens before 第 $k+1$次调用 l.Lock 3.6 Once# 对某个函数f()，可以有多个线程通过once.Do(f)来对其调用，但仅有线程能够调用执行函数f()，其它的调用会被阻塞知道f()返回。 程序 123456789101112131415161718192021222324252627282930313233package mainimport ( "sync" "time")var a stringvar once sync.Oncefunc setup() &#123; a = "hello, world"&#125;func SETUP() &#123; a = "HELLO, WORLD"&#125;func doprint() &#123; once.Do(setup) //注意不要括号 once.Do(SETUP) print(a, "\n")&#125;func main() &#123; go doprint() go doprint() time.Sleep(time.Second)&#125;&gt; Output:command-line-argumentshello, worldhello, world 会打印两次 hello, world，但是仅在第一次调用 doprint 时执行了 setup 4. Incorrect synchronization# 程序 12345678910111213141516171819202122232425package mainvar a, b intfunc f() &#123; a = 1 b = 2&#125;func g() &#123; print(b, "\n") print(a)&#125;func main() &#123; go f() g()&#125;&gt; Output: //大多数输出结果00&gt; Output: //少数输出结果01 也可能先打印2，然后打印0 程序 1234567891011121314151617181920212223242526272829303132package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world \n" done = true&#125;func doprint() &#123; if !done &#123; setup() &#125; print(a)&#125;func twoprint() &#123; go doprint() go doprint()&#125;func main() &#123; twoprint()&#125;//有3种输出的可能&gt; Output:hello, world hello, world &gt; Output:hello, world &gt; Output: 下面的程序，由于不能保证main()先获取对done的写，因此print()可能打印空字符串。甚至main()完全没有获取对done的写，此时main()进入死循环 12345678910111213141516171819202122232425package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; print(a)&#125;&gt; Output:hello, world&gt; Elapsed: 3.703s //等待了较长的时间&gt; Result: Success&gt; Output:hello, world&gt; Elapsed: 0.704s &gt; Result: Success 类似的程序如下 1234567891011121314151617181920package maintype T struct &#123; msg string&#125;var g *Tfunc setup() &#123; t := new(T) t.msg = "hello, world" g = t&#125;func main() &#123; go setup() for g == nil &#123; &#125; print(g.msg)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建IPFS 私有网络]]></title>
    <url>%2F2018%2F11%2F05%2F2018-11-5%2F</url>
    <content type="text"><![CDATA[在servers上安装 Go 环境 生成 ifps 节点 创建共享密钥 添加启动节点 启动私有网络 本例为建立包含三个节点的IPFS私有网络，节点分别为： server a: root@45.32.28.71 server b: root@207.148.109.110 本地 mac 在servers上安装 Go 环境# 1234567891011cd ~ $wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz$tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz //解压到得到的 go 目录，放到 /usr/local 目录下$vim .bashrcexport GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN$source .bashrc$go version go version go1.11.2 linux/amd64 //安装成功 mac 上的安装类似。 生成 ifps 节点# 在三台机器上执行 12345678910111213141516171819202122232425262728$go get -u -d github.com/ipfs/go-ipfs $cd $GOPATH/src/github.com/ipfs/go-ipfs$make installCommand &apos;make&apos; not found, but can be installed with:sudo apt install makesudo apt install make-guile$apt update \\ 需要安装 make ， 先检查安装包...$apt upgrade \\ 更新安装包...$apt install make \\ 安装 make...$make install/usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exec: &quot;gcc&quot;: executable file not found in $PATHcmd/ipfs/Rules.mk:37: recipe for target &apos;cmd/ipfs-install&apos; failedmake: *** [cmd/ipfs-install] Error 2$apt install gcc...$gcc -v...gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)$make install...$ipfs init... 记下每个节点的ID，比如本例 server a 的ID: QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 server b 的ID: QmRyxoe9JpkDZuMK4G7PkXUy7nGv8VdM98d6Vr2wxFSa3V mac 的ID: QmWKKVUy9XqWEGhrikJW8ugHuFzKJJGP5DCGFyvzUJFjzL 创建共享密钥# 先在任意一台机器上创建密钥，然后拷贝到剩余节点。本例在mac上创建 12$go get -u github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen$ipfs-swarm-key-gen &gt; ~/.ipfs/swarm.key 手动拷贝 1$vim ~/.ipfs/swarm.key \\ 打开swarm.key, 拷贝内容 在servers上新建swarm.key 1$vim ~/.ipfs/swarm.key \\ 将拷贝的内容粘贴 使用 scp 命令 12$scp ~/.ipfs/swarm.key root@45.32.28.71:~/.ipfs/$scp ~/.ipfs/swarm.key root@207.148.109.110:~/.ipfs/ 添加启动节点# pfs init后的默认启动节点是连接ipfs公网的节点。建立私有网络需要在每一个节点上删掉默认启动节点 1$ipfs bootstrap rm --all 将网络中任意其他节点作为启动节点。例如将 server a 作为mac的启动节点 1$ipfs bootstrap add/ip4/45.32.28.71/tcp/4001/ipfs/QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 启动私有网络# 给三个节点添加了启动节点后，启动所有节点，便建立起了含有三个节点的IPFS私有网络。分别执行 1$ipfs daemon 可以使用 bootstrap list```查看节点所包含的启动节点，使用```ipfs swarm peers```查看节点连接了哪些其他节点。使用```ipfs add file```上传文件到节点，比如给mac节点上传pdf文件，并得到该文件的ID12```$ipfs add ~/files/GO语言编程.pdf 该文件的ID：QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi。现在与mac建立了连接的server就可以下载该文件了，在server上执行 1$ipfs get QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi \\在当前目录会多出一个新的文件便是get到的文件]]></content>
      <tags>
        <tag>IPFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A Study for the Reed-Solomon Code]]></title>
    <url>%2F2018%2F10%2F18%2F2018-10-18%2F</url>
    <content type="text"><![CDATA[Introduction Galois Field Galois Field Arithmetic Addition and Subtraction Multiplication and Division RS Code Coding Matrix Method Generator Polynomial Method RS Code in Distributed Storage Systems 5.1 Rotated Reed-Solomon code Local Reconstruction Code (LRC) References Introduction# Reed-Solomon (RS) code is an error-correcting code first proposed by Reed and Solomon in 1960, which is the most frequently applied digital error correction code around the word. The applications include data storage(hard drives, CD/DVD/Blue Ray), data transmission and common commercial activities(bar codes, QR codes) . RS code has the advantage of high capability of correcting random or burst errors since it encodes groups of bits instead of one bit at a time. Redundant datas are generated so that the original data can be reconstructed with part of the stored or received data loss. People often back up important files which can be regarded as kind of data loss protection with redundant data. However, backup is just a copy of the original datas while the redundant data generated in the RS code is a fusion of the all the original data parts, which is more efficient for storage and error correction. In this article, I have run through the procedure of the RS code and hope it is usefull for you to understand what is going on with this erasure code. Its application in the distributed strorage system are briefly introduced at the end. Part of implementations in pure Go are also provided whose source files can be found on the Githup website . Galois Field# The finite field is also called Galois field which has finite elements and the property that arithmetic operations on field elements always have a result in the field. In the sequel, we illustrate two kind of representations of the finite elements and its arithmetic operations. Proposition 1. For any prime $ p $ and any natual number$ r $ there exists a finite field with $ p^{r} $ elements and vice versa. With the proposition 1, the Galois Field is denoted as $ GF(p^{r}) $. In fact, the nature of RS encoding is mapping $ k $ elments of $ GF(2^{r}) $ into another $ n $ elements of $ GF(2^{r}) $ and $k+2\leq n\leq 2^{r} $. This Galois fields can be represented with the help of $ \mathbf{Z}{2}[x] $, the set of polynomials with coefficients in the field of two elements $ \mathbf{Z}{2} $, namely the polynomial representation as $$0,1,x,x+1,x{2},..,x{r-1}+x^{r-2}+...+1 \tag{1}$$ This representation can also be seen as a $r$-bit digit or binary vector. Proposition 2. $ GF(q) $ has cyclic the multiplicative group $ {\alpha, \alpha{2},...,\alpha{q-1}=1}$, where $ \alpha $ is the primitive element. Thus, $ GF(2^{r}) $ has the exponential representation as $$0, 1(=\alpha^{255}), \alpha, \alpha^{2},..., \alpha{2{r}-2} \tag{2}$$ which is a better choice for the '$ \times $' and '$ / $' operation. Even a binary matrix can be used to represente the elements. For example, we can establish a bijection between the vector representation and matrix representation over $ GF(2^{4}) $ as follows where the first column is the vector representation and the columns satisfy $column(i)=2\times column(i-1)$. This matrix representation transforms arithmetic over $ GF(2^{4}) $ into arithmetic over $ GF(2) $ which only has XOR, AND operations. Galois Field Arithmetic# In this section, we discuss arithmetic in $ GF(2^{8}) $, whose element corresponds a byte data. Addition and Subtraction# Addition and subtraction are operated under the polynomial representation (also a byte in $ GF(2^{8}) $) and both are equivalent to XOR operation 1234567func galAdd(a, b byte) byte &#123; return a ^ b&#125;func galSub(a, b byte) byte &#123; return a ^ b&#125; Multiplication and Division# The multiplication is operated with the exponential representation $(2)$, before that we should establish a bijection (injection and surjection) between the two representations. Suppose $$\alpha^{i} -&gt; 2^{i}$$ where $0\leq i \leq 2^{8}-2=254$. According to proposition 2, $\forall j\geq 255,\alpha{j}=\alpha{j-255}$. Proposition 3.$ GF(2^{8}) $ has the irreducible polynomial $ f(x)=x{8}+x{4}+x{3}+x{2}+1 $ which has no factors of smaller polynomials. The irreducible polynomial is necessary to establish the bijection since some $2^{i}$ term are no longer in $GF(2^{8})$. Let $ f(\alpha) =0$, we have $$\alpha{8}=\alpha{4}+\alpha{3}+\alpha{2}+1=2{4}+2{3}+2^{2}+1=00011101$$ or 0x1d . For convenience, we record the bijection with a table, namely called exponent table, whose indexs is the exponents of elements in exponential representation and value is elements in byte representation. 1var expTable = [255]byte&#123;0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, ..., 0x8e&#125; Use logTable[expTable[$i$]]=$i$, the logarithmic table is generated, 12345var logTable = []byte&#123; 0, 0, 1, 25, 2, 50, 26, 198, ... 116, 214, 244, 234, 168, 80, 88, 175,&#125; With these tables, the $\times$ and $/$ functions in $GF(2^8)$ are easily defined, 12345678910111213141516171819202122232425262728293031func galMultiply(a, b byte) byte &#123; if a == 0 || b == 0 &#123; return 0 &#125; logA := int(logTable[a]) logB := int(logTable[b]) sum := logA+logB if sum&gt;254 &#123; sum -= 255 &#125; return expTable[sum]&#125;func galDivide(a, b byte) byte &#123; if a == 0 &#123; return 0 &#125; if b == 0 &#123; panic("Argument 'divisor' is 0") &#125; logA := int(logTable[a]) logB := int(logTable[b]) logResult := logA - logB if logResult &lt; 0 &#123; logResult += 255 &#125; return expTable[logResult]&#125; Based on the result above, the power and inverse functions can be further obtained. In fact, the method to establish the bijection is not unique. The original paper of Reed and Solomon in 1960 provides another method with finite difference equation which has better computability. RS Code# Coding Matrix Method# 1. Orignal approach: For arbitrary $ k $ 8-bit symbols,$ m_{0}$, $m_{1}$, $...$, $m_{k-1} $, we have the message polynomial $$m(x)=m_{0}+m_{1}x+...+m_{k-1}x^{k-1},$$ with this $ m(x) $, $ 2^{8} $ codewords, i.e. $ m(0)$,$m(1)$,$...$, $m(\alpha^{r-2}) $ are obtained and the the encoded messages, which will be transmitted or stored, are $ n $ of the codewords (professionally called stripe). Using linear algebra, the stripe are denoted collectively as follows $$ \begin{bmatrix} m(\alpha_{1})\ m(\alpha_{2})\ ...\ m(\alpha_{n}) \end{bmatrix} = \begin{bmatrix} 1 &amp; \alpha_{1} &amp; ... &amp; \alpha_{1}^{k-1} \ 1 &amp; \alpha_{2} &amp; ...&amp;\alpha_{2}^{k-1} \ ... &amp; ... &amp; ...&amp;... \ 1 &amp; \alpha_{n} &amp; ...&amp;\alpha_{n}^{k-1} \end{bmatrix} \begin{bmatrix} m_{0}\ m_{1}\ ...\ m_{k-1} \end{bmatrix}\tag{3} $$ Note that we only discuss one byte a shard (the messages are splited into multiple shards for encoding) here, in practice one input shard contains thousands of bytes, in this case the output shard contains same size of byte as input shard and the vectors in $(3)$ becomes matrice. Coding procedure : 1.Split the whole message into same size data shards; 2. Build the Vandermonde matrix (coding matrix); 3. Multiplies the coding matrix by data shards to produce code shards. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (r reedSolomon) Split(data []byte) ([][]byte, error) &#123; if len(data) == 0 &#123; return nil, ErrShortData &#125; // Calculate number of bytes per data shard. perShard := (len(data) + r.DataShards - 1) / r.DataShards if cap(data) &gt; len(data) &#123; data = data[:cap(data)] &#125; // Only allocate memory if necessary if len(data) &lt; (r.Shards * perShard) &#123; // Pad data to r.Shards*perShard. padding := make([]byte, (r.Shards*perShard)-len(data)) data = append(data, padding...) &#125; // Split into equal-length shards. dst := make([][]byte, r.Shards) for i := range dst &#123; dst[i] = data[:perShard] data = data[perShard:] &#125; return dst, nil&#125;func vandermonde(rows, cols int) (matrix, error) &#123; result, err := newMatrix(rows, cols) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; for c := range row &#123; result[r][c] = galExp(byte(r), c) &#125; &#125; return result, nil&#125;// Multiplies a subset of rows from a coding matrix by a full set of// input shards to produce some output shards.// 'matrixRows' is The rows from the matrix to use.// 'inputs' An array of byte arrays, each of which is one input shard.// The number of inputs used is determined by the length of each matrix row.// outputs Byte arrays where the computed shards are stored.func (r reedSolomon) codeSomeShards(matrixRows, inputs, outputs [][]byte) &#123; for c := 0; c &lt; r.DataShards; c++ &#123; in := inputs[c] for iRow := 0; iRow &lt; outputCount; iRow++ &#123; if c == 0 &#123; galMulSlice(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; else &#123; galMulSliceXor(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; &#125; &#125;&#125; Since any $ k $ rows of Vandermonde matrix are linearly independent, with arbitrary $ k $ correct code shards, the original $ k $ data shards can be reconstructed by multiplying the corresponding inverse matrix. However, in practice, we usually do not know which one is correct or corrupted for the $ n $ received codewords. In this case, the plurality of votes method is necessary and $$ \left(\begin{array}{c} n-s\k \end{array} \right)&gt;\left(\begin{array}{c} s+k-1\k \end{array} \right) $$ or $$ s&lt;\frac{n-k+1}{2} $$ where $s$ is number of unkown errors, therefore $ n=k+2s $ always satisfies the in-equation. Another approach is to use the Berlekamp-Welsh Algorithm which avoids the heavy computation of votes: Berlekamp-Welsh decoder: 1. Send $m(0),m(1),...,m(n)$, receive $m'(0),m'(1),...,m'(n)$, and most $s$ of them such that $m(i)\neq m'(i)$； 2. $E(x)=x{s}+b_{s-1}x{s-1}+...+b_{0}$, $Q(x)=a_{k+s-1}x{k+s-1}+a_{k+s-2}x{k+s-2}+...+a_{0}$ 3. Solve the coefficients of co$E(x)$,$Q(x)$ with $ Q(i)=m'(i)E(i)$ 4. Derive $m(x)=Q(x)/E(x)$. And $\forall m(i)\neq m'(i)$,$E(i)=0$. The implicite principle: $Q'(x)/E'(x)$ and $Q(x)/E(x)$ agree on at least $k+s$ points. $E'(x)$ and $E(x)$ both have at most $s$ zero points. Elimilate $E'(x)$ and $E(x)$,$Q'(x)/E'(x)$ and $Q(x)/E(x)$ are degree at least $k-1$ and agree on at least $k$ points, thus $Q'(x)/E'(x)=Q(x)/E(x)=m(x)$. 2. Systematic coding matrix: In the original approach, all the code shards have been encoded. While in the systematic encoding, the original data shards become part of the code shards and only the parity shards should be encoded. In other words, the stripe contains the original datas and parity codewords together no longer codewords only. The coding matrix is composed of the top square identity matrix and the parity matrix. There are three methods of building the coding matrix in this systematic way are provided: Elementary transform on the Vandermonde matrix as the procedure 1. 123456789101112131415161718func buildMatrix(dataShards, totalShards int) (matrix, error) &#123; vm, err := vandermonde(totalShards, dataShards) if err != nil &#123; return nil, err &#125; top, err := vm.SubMatrix(0, 0, dataShards, dataShards) if err != nil &#123; return nil, err &#125; topInv, err := top.Invert() if err != nil &#123; return nil, err &#125; return vm.Multiply(topInv)&#125; Parity matrix is Vandermonde matrix. 1234567891011121314151617181920func buildMatrixPAR1(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Vandermonde // matrix starting at 1 instead of 0. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = galExp(byte(c+1), r-dataShards) &#125; &#125; &#125; return result, nil&#125; Parity matrix is Cauchy matrix. Cauchy matrices are easier to invert than general matrices [8]. 12345678910111213141516171819func buildMatrixCauchy(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Cauchy matrix. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = invTable[(byte(r ^ c))] &#125; &#125; &#125; return result, nil&#125; Generator Polynomial Method# Define the generator polynomial: $$ g(x)=(x-\alpha)(x-\alpha{2})\dots(x-\alpha{2s}) $$ and the codeword polynomial can be directly computed as $$c(x)=m(x)g(x)$$ For the systematic form, which is more often used in practice, we define $$ b(x)=x^{2s}m(x) \quad mod\quad g(x) $$ then the codeword polynomial becomes $$ c(x)=x^{2s}m(x)-b(x) $$ where $-b(x)$ is the parity codeword polynomial. All the polynomial operation above is processed over $GF(2^8)$. It is also observed that the correction of received message can be checked by testing its divisibility by g(x), and there is no need to decode for the systematic encoding if the answer is affirmative. Otherwise, we denote $r(x)=c(x)+e(x)$ and suppose there are $ v(\leq s) $ errors Syndrome based decoder: 1.Calculate the $2s$ Syndromes: $S_{j}=r(\alpha{j})=e(\alpha{j})$ 2. Solve $$ \begin{bmatrix} S_{1} &amp; S_{2}&amp; ... &amp; S_{v} \ S_{2} &amp; S_{3} &amp; ...&amp;S_{v+1} \ ... &amp; ... &amp; ...&amp;... \ S_{v} &amp; S_{v+1} &amp; ...&amp;S_{2v-1} \end{bmatrix} \begin{bmatrix} \Lambda_{v}\ \Lambda_{v-1}\ ...\ \Lambda_{1} \end{bmatrix}=\begin{bmatrix} -S_{v} \ -S_{v+1}\ ...\ -S_{2v}\tag{4} \end{bmatrix} $$ and use Chien search solve $\Lambda(x)=\Lambda_{v}x^{v} +\Lambda_{v-1}x^{v-1}+...+1=0$ to derive the $v$ roots, denoted as,$x_{1},..,x_{v}$. 3. Use Forney algorithm to solve $$ \begin{bmatrix} x_{1}^{-1} &amp; x_{2}^{-1}&amp; ... &amp; x_{v}^{-1} \ x_{1}^{-2} &amp; x_{2}^{-2} &amp; ...&amp;x_{v}^{-2} \ ... &amp; ... &amp; ...&amp;... \ x_{1}^{-2s} &amp; x_{2}^{-2s} &amp; ...&amp;x_{v}^{-2s} \end{bmatrix} \begin{bmatrix} e_{i_{1}}\ e_{i_{2}}\ ...\ e_{i_{v}} \end{bmatrix}=\begin{bmatrix} S_{1} \ S_{2}\ ...\ S_{2s}\tag{5} \end{bmatrix} $$ 4. The index $i_{j}$ of $e_{i_{j}}$ are determined by looking up the logarithmic table as earlier mentioned 5. Compute $e(x)=\sum_{j=1}{v}e_{i_{j}}x{i_{j}}$ and $c(x) = r(x)-e(x)$. It is worth mentioning that all the syndromes are zeros if $r(x)=c(x)$, this can be used to check if the received message is corrupted or if the message was completely constructed. RS encoding is relatively straightforward for the generator approach, but decoding needs complicated algebraic computation, especially for the step 2. Because the real value of $v$ is unknown and the normal way has to use the trial value untill the matrix in $(4)$ is nonsingular. Other algebraic methods for the evaluation of this error location polynomial $\Lambda(x)$ include Berlekamp–Massey algorithm and Extended Euclidean algorithm. This syndrome based decoder can be implemented with different hardware unit such as matrix vector multiplication unit, remainder unit, and performs hard-decision decoding up to $s$ errors. Hard-decision decoding decides the bit according to the a threshold, where each bit is definitely one or zero. While soft-decision decoding requires additional reliability information to improve the decision, which has better coding gain for the white Guassian channel [2]. RS Code in Distributed Storage Systems# The RS code are stored in different disks in the distributed storage systems, and the performance arasure code in distributed storage systems involves disk I/O and repair bandwidth overhead. 5.1 Rotated Reed-Solomon code# In the conventional RS code, all the parity blocds are encoded with data blocks in the same strip, while in the rotated reed-solomon code, parity blocks may be generated with different stripes as in the following figure, when the disk 5 in the figure fails, this method reduceS 3 operations of reading the data blocks than the conventional RS code [5]. Local Reconstruction Code (LRC)# LRC introduces local parity codes which requires slightly more storage space than conventional RS code, but significantly reduce the number of participating data discs for encoding, thus it is beneficial to the reduction of bandwidth and disc I/O overhead. The figure of pyramid code is shown as follows [6] However, repair of the global redundancy still needs to access all data discs, another LRC approach in [7] further introduces parity code ($ S_{3} $ in the figure) for the global parity codes ($P_{1}$,$P_{2}$,$P_{3}$,$P_{4}$) to avoid this undesirable situation. By choosing the coefficients of $c_{1}^{'}$, $c_{2}^{'}$, $c_{3}^{'}$, $c_{4}^{'}$ and $c_{5}^{'}$, $c_{6}^{'}$ properly, the parity code of $ S_{3} $ can be calculated by the existing parity codes $ S_{1} $ and $ S_{2} $. Thus parity code $ S_{3} $ does not have to occupy additional storage. Observation: Copy is kind of LRC. References# [1] I. Reed and G. Solomon, BPolynomial codes over certain finite fields,[ J. Soc. Ind. Appl. Math., vol. 8, no. 2, pp. 300–304, Jun. 1960. [2] Wicker and Bhargava, Reed-Solomon Codes and Their Applications, 1994. [3] James S. Plank and Lihao Xu, Optimizing Cauchy Reed-Solomon Codes for Fault-Tolerant Network Storage Applications. [4] Reed–Solomon codes for coders. [5] Khan O, Burns R C, Plank J S, et al. Rethinking erasure codes for cloud file systems: minimizing I/O for recovery and degraded reads. [6] Huang Cheng, Chen Minghua, Li Jin. Pyramid codes: flexible schemes to trade space for access efficiency in reliable data storage systems. [7] Sathiamoorthy M, Asteris M, Papailiopoulos D, et al. Xoring elephants: novel erasure codes for big data. [8] J. Blomer, M. Kalfane, R. Karp, M. Karpinski, M. Luby, and D. Zuckerman, An XOR-Based Erasure-Resilient Coding Scheme.]]></content>
      <tags>
        <tag>RS Code</tag>
        <tag>Golang</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang编程基础]]></title>
    <url>%2F2018%2F08%2F20%2F2018-8-20%2F</url>
    <content type="text"><![CDATA[在Ubuntu安装: 数据类型: 基本类型： 聚集类型 (aggregate types)： 数组 结构 引用类型 指针 切片（slice） 字典（map） 函数 通道（channel） 接口类型（interface）： 控制流 （for if switch defer goto）： 创建工程目录： Tips: 其他： 参考资料： 在Ubuntu安装:# 123456789&gt;cd ~ &gt;wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz&gt;tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz // 解压到得到的 go 目录，放到 /usr/local 目录下&gt;vim .bashrc // 写入以下内容export GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN&gt;source .bashrc 数据类型:# 基本类型：# 数值 整型：int； int8； int16； int32(rune，Unicode)； int64； uint； uint8(byte)； uint16； uint32； uint64； uintptr int, uint, uintptr 在 32 位系统上是 32 位，在 64位 系统上是 64位 浮点型：float32； float64 复数型：complex64； complex128 字符串：使用双引号 &quot;a&quot; 布尔: true； false 常量：三种基本类型 12345const( kb = 1024 e = 2.71828182845904523536028747135266249775724709369995957496696763 F = false) 在 if语句中，若检验条件为i &gt;= 0，则i 的类型不宜为 uint 型（uint 数据始终 &gt;= 0）。尽管内置函数 len() 返回值是非负整数，但它际返回 int 型， 1234medals := []string&#123;"gold", "silver", "bronze"&#125;for i := len(medals)-1; i &gt;= 0; i--&#123; fmt.Println(medals[i]) // "bronze", "silver", "gold"&#125; 基本类型与操作符构成表达式 取余 % 只用于整型；余数与被除数符号相同，5%3=2； -5%3=-2 5.0/4=1.25；5/4.0=1.25；5/4=1 &amp;&amp; 若左边的表达式结果为 false，不检验右边的表达式；&amp; 始终检验两边的表达式 与或^ ; 一元前缀^ 聚集类型 (aggregate types)：# 数组# 12345var a [3]intr := [...]int&#123;99: 1&#125; // 索引为99的元素，r[99]， 等于 1，其他默认 0p := new([10]int) // 将生成的数组的指针赋给 p, 为 *[10]int 类型p[0]=1 // 给 p 指向的数组的索引为0的元素赋值 1 数组的长度也是数组类型的一部分，因此 [3]int 和 [4]int 是不同类型的数组，不能进行比较或赋值。 结构# （1）结构的字段（field） 1234567891011121314151617181920212223type person struct&#123; // 定义 person 类型 gender string age int&#125;func main()&#123; student := person&#123;&#125; student.age = 16 student.gender = "male" // or student := person&#123; gender : "male", age : 16, //逗号不能省 &#125; // or student := person&#123;"male", 16&#125; teacher := &amp;person&#123; //取指针 gender : "female", age : 30, &#125; teacher.age = 36 //指针 teacher 仍然可以进行点操作&#125; 指针也可以进行点操作。 匿名结构，字段匿名 1234567891011121314student := struct&#123; // 匿名结构 gender : string age : int&#125;&#123; gender : "male", age : "17",&#125;type person struct&#123; string int&#125;// 按照顺序初始化student := person&#123;"male", 10&#125; 结构嵌套， 12345678910111213141516171819202122232425262728type person struct&#123; gender string age int parents struct&#123; // 嵌套一个匿名结构 dad, mom : string &#125;&#125;type address struct&#123; state, city string&#125;type person2 struct&#123; gender string age int address // 嵌套你一个结构address&#125;func main()&#123; student := person&#123;gender : "female", age : 10&#125; student.parents.dad = "Tom" student.parents.mom = "Lily" student2 := person2&#123;gender:"female", age:10, address : address&#123;county:"LA" state:"California"&#125; &#125; student2.address.state = "Massachusetts" // or student2.state = "Massachusetts" &#125; （2）结构的方法（method） 函数与方法 123456789101112131415161718192021222324package mainimport ( "fmt" "math")type Point struct&#123; X, Y float64 &#125;func Distance(p, q Point) float64 &#123; //函数 return math.Hypot(q.X-p.X, q.Y-p.Y)&#125;func (p Point) Distance(q Point) float64 &#123; // 方法，在函数名前增加一个形参（receiver） 类似于Java的this 和python的 self， return math.Hypot(q.X-p.X, q.Y-p.Y) // 接收者的名称通常取它的类型名称的第一个字母&#125;func main() &#123; p := Point&#123;1, 2&#125; q := Point&#123;4, 6&#125; fmt.Println(Distance(p, q)) // 打印 5， 调用函数 fmt.Println(p.Distance(q)) // 调用方法&#125; 当需要使用方法对值（value of type T，相对于方法来讲就是实参，argument） 的字段进行修改时，使用接收者为指针的方法或者叫指针方法 1234func (p *Point) ScaleBy(factor float64) &#123; // 接收者参数p的类型是指针类型 p.X *= factor // p在这里是指针，等价于 (*p).X p.Y *= factor&#125; 同一个 struct 的方法和字段占据相同的命名空间（name space），因此两者的名称不能重复； 指针方法看作高权限方法。 对方法的调用, 值（实参） 和 接收者（形参）类型要相同 12345678Point&#123;1, 2&#125;.Distance(q) // Point Pointpptr.ScaleBy(2) // *Point *Pointpptr.Distance(q) // 隐含 (*pptr)p.ScaleBy(2) // 隐含 (&amp;p) Point&#123;1, 2&#125;.ScaleBy(2) //错误！！！(&amp;Point&#123;1, 2&#125;).ScaleBy(2) 不仅仅是 struct 123456789101112131415161718package mainimport ( "fmt")type INT intfunc main() &#123; var a INT a = 1 a.Print() // 打印 2&#125;func (a *INT) Print() &#123; *a = 2 fmt.Println(*a)&#125; 方法是与命名类型(named type)相关联的函数。 引用类型# 指针# 1234var p *inti := 20p = &amp;i*p = 10 // i 的值为 10 切片（slice）# 123456789101112131415var s []int // 声明切片 sa := [5]int&#123;1, 2, 3, 4, 5&#125;s = a[:2] // [1, 2]， len(s)等于2，cap(s)等于5s = a[0:1] // [1]，len(s)等于1，cap(s)等于5s = a[3:] // [4, 5]，len(s)等于2，cap(s)等于2s := make([]int, 2, 4) //make([]type, len, cap) ，切片长度为2，底层数组的长度为4s = append(s, 1) // s 的地址不变s = append(s, 2, 3) // 生成新的数组，地址改变，容量翻倍，也就是cap(s)等于4*2=8s1 := []int&#123;1, 2, 3&#125;s2 := []int&#123;4, 5&#125;copy(s1, s2) //把 s2 复制到 s1，s1 为 [4, 5, 3]s1 = []int&#123;1, 2, 3&#125;copy(s2, s1) // s2 为 [1, 2] 切片的本质是对底层数组的引用；切片的容量（cap）是切片的始索引到底层数组的末索引的长度。 字典（map）# 123456var m map[int]string // key int 型；value string 型m = make(map[int]string)m2 := make(map[int]string)m[0] = "OK"delete(m, 0) // 删除 m 中键为0的键值对 嵌套， 123m := make(map[int]map[int]string) // value map型m[1] = make(map[int]string)m[1][2] = "YES" 函数# func main(int, []string) int means， function main takes an int and a slice of strings and returns an int 函数作为类型， 1var f func(func(int,int) int, int) func(int, int) int 不定长变参，闭包 12345678910111213141516171819202122232425262728package mainimport ( "fmt")func main()&#123; var_args(1) var_args(1, 2, 3) f := closure(10) fmt.Println(f(1)) fmt.Println(f(2)) &#125;func var_args(args ...int)&#123; fmt.Println(args)&#125;func closure(x int) func(int) int&#123; // 返回匿名函数 return func(y int) int&#123; return x + y &#125;&#125;输出：[1][1 2 3]1112 通道（channel）# channel 是 goroutine 沟通的桥梁，通过 make 创建，close 关闭 12345678910111213141516package mainimport ( "fmt")func main() &#123; c := make(chan bool) go func() &#123; fmt.Println("I from goroutine !") c &lt;- true &#125;() &lt;-c&#125; channel 作为函数形参 123456789101112131415161718package mainimport ( "fmt")func main() &#123; c := make(chan bool) go Hello(c) &lt;-c&#125;func Hello(c chan bool) &#123; fmt.Println("Hello, I from goroutine!") c &lt;- true &#125; 多个 goroutine，多个channel 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt" "runtime")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) // 开启多核 c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; // 启动多个 goroutin go Decomposition(c, i, 100000007) &#125; for i := 0; i &lt; 5; i++ &#123; // 多个 channel 阻塞 &lt;-c &#125;&#125;func Decomposition(c chan bool, index int, n int) &#123; // 质数分解 for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", index, n) c &lt;- true&#125;输出： 0: 1000000072: 1000000071: 1000000074: 1000000073: 100000007从输出结果的顺序可以看出 goroutine 并非先启动先执行 使用同步包来代替 channel 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( "fmt" "runtime" "sync")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) wg := sync.WaitGroup&#123;&#125; wg.Add(5) // 添加 5 个 任务（goroutine） for i := 0; i &lt; 5; i++ &#123; go Decomposition(&amp;wg, i, 100000007) &#125; wg.Wait() // 等到任务数减到 0 &#125;func Decomposition(wg *sync.WaitGroup, m int, n int) &#123; for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", m, n) wg.Done() // 任务数减 1&#125;输出：0: 1000000072: 1000000074: 1000000071: 1000000073: 100000007 selec{}语句， 如果有多个case 读取数据，select会随机选择一个case执行，其他不执行； 如果没有case读取数据，就执行default； 如果没有case读取数据，且没有default，select将阻塞，直到某个case可以执行。 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func main() &#123; c1, c2, block := make(chan int), make(chan string), make(chan bool) go func() &#123; for &#123; select &#123; // 按随机顺序处理多个 case case message, open := &lt;-c1: if !open &#123; // 如果通道 c1 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c1:", message) case message, open := &lt;-c2: if !open &#123; // 如果通道 c2 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c2:", message) &#125; &#125; &#125;() c1 &lt;- 10 c2 &lt;- "hello" c1 &lt;- 20 c2 &lt;- "world" close(c1) // 关闭通道 c1 &lt;-block&#125;输出：A message from main by c1: 10A message from main by c2: helloA message from main by c1: 20A message from main by c2: world 12345678910111213141516171819package mainimport ( "fmt" "time")func main() &#123; select &#123; case &lt;-time.After(2000000 * time.Microsecond): fmt.Println("2 seconds") case &lt;-time.After(1999999 * time.Microsecond): fmt.Println("1.999999 seconds") &#125;&#125;输出：1.999999 seconds 接口类型（interface）：# （1）接口代表某些方法的集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( "fmt")type game interface &#123; Strike_of_Kings() int Battle_Grounds() int&#125;type contact interface &#123; Wechat() QQ()&#125;type smartphone interface&#123; // 接口嵌套， game contact&#125;type iphone struct &#123; version string price float32 user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func (iph *iphone) QQ() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;// iphone 不满足 contact 接口func (iph iphone) Battle_Grounds() int &#123; fmt.Println("There are 4 teammates at most in the Battle Grounds.") return 4&#125;func (iph iphone) Strike_of_Kings() int &#123; fmt.Println("There are 5 teammates at most in the Strike of Kings.") return 5&#125;// iphone 满足 game 接口func (iph *iphone) New_Version(version string) &#123; iph.version = version&#125;func all_round_game(game) &#123; // 接口作为形参 fmt.Println("Both Strike of_Kings and Battle Grounds have installed.")&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; my_phone.Wechat() fmt.Println(my_phone.Battle_Grounds()) all_round_game(my_phone) // my_phone 符合 game 接口，可作为该函数的实参 var _ game = iphone // 确保 iphone 实现了接口game &#125; （2）任何类型都满足空接口；空接口interface{}作为形参可以接受任何类型的实参 12345678910111213141516171819202122232425package mainimport ( "fmt")func main() &#123; m := make(map[int]interface&#123;&#125;) m[1] = "a" m[2] = 2 m[3] = false print_map(m)&#125;func print_map(m map[int]interface&#123;&#125;) &#123; for k, v := range m &#123; fmt.Println(k, ":", v) &#125;&#125;输出：1 : a2 : 23 : false []string 和 []interface{} 是不同的类型； 接口是一种抽象类型，可理解为是将所有具体类型按照方法集进行再分类； 指针方法集包含非指针方法集。 （3）接口值（interface value）包含 类型 （接口的动态类型）和 类型值 （接口的动态值） 两个部分，仅当两者均为nil 时，接口才为nil （4）反射 （reflection） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt" "reflect")type iphone struct &#123; version string price int user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; Info(my_phone)&#125;func Info(itf interface&#123;&#125;) &#123; t := reflect.TypeOf(itf) fmt.Println(t) for i := 0; i &lt; t.NumField(); i++ &#123; fmt.Println(t.Field(i)) &#125; fmt.Println("___________________") v := reflect.ValueOf(itf) fmt.Println(v) for i := 0; i &lt; v.NumField(); i++ &#123; fmt.Println(v.Field(i)) &#125;&#125;输出：main.iphone&#123;version main string 0 [0] false&#125;&#123;price main int 16 [1] false&#125;&#123;user main string 24 [2] false&#125;___________________&#123;X 8316 Xiaohe&#125;X8316Xiaohe 控制流 （for if switch defer goto）：# （1）for： 1234567891011for (inti statement)；condition；(post statement) &#123;&#125;for i := 0; i &lt; 10; i++ &#123;&#125; for ; i &lt; 10; &#123; // 去掉分号&#125; for i &lt; 10&#123; // while 语句&#125;for&#123; // 无限循环&#125; （2）if： 123456 if (init statement)；condition &#123;&#125; if (init statement)；condition &#123;&#125;else &#123;&#125; （3）switch： 12345678910111213switch (init statement)；some value &#123; case 0： case f()： ... default：&#125;switch &#123; case 布尔表达式1： case 布尔表达式2： ... default：&#125; 一旦符合条件自动终止，若希望继续检验下面的case，使用 fallthrough 语句。 （4）defer： defer 后必须跟函数引用 defer 语句被检验后，延迟函数获得变量的拷贝 123456func a() &#123; i := 0 defer fmt.Println(i) i++ return&#125; // defer 语句打印0 defer 语句被检验后，延迟匿名函数获得变量的地址 12345678910111213func b() (i int) &#123; defer func() &#123; i++ &#125;() return 1 // 将1 赋给 i&#125; // 返回 2。利用 defer 语句修改外围函数的命名返回值func c() &#123; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Print(i) &#125;() &#125; return&#125; // 打印 333 defer 语句被检验后，延迟函数的引用被推入堆栈，当外围函数返回后，按照后进先出的顺序被调用（即使外围函数发生错误，如 panic，延迟函数仍然会被调用） 12345func d() &#123; for i := 0; i &lt; 4; i++ &#123; defer fmt.Print(i) &#125;&#125; // 打印 3210 更多细节如，panic， recover（只能用在延迟函数中） 参考 defer blog。 （5）goto： 123456789101112131415161718192021222324LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; break LABEL // 跳出与LABEL同级的循环，即跳出无限循环 &#125; &#125; &#125;LABEL: for i := 0; i &lt; 10; i++ &#123; for &#123; continue LABEL &#125; &#125;LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; goto LABEL // 将再次进入无限循环 &#125; &#125; &#125; 通常标签放到 goto 的后面。 创建工程目录：# Go工程中共有三个部分： src：存放go源码文件 pkg：存放编译后的包文件 bin：存放编译后的可执行文件 **注意：**src目录需要自己创建，pkg和bin编译时会自动创建。 步骤： 新建工程目录，my_project，并在该目录下创建 src目录； 把my_project 添加到 GOPATH，GOPATH=/home/user/...;my_project（可以同时添加多个路径目录，Linux下用冒号:隔开，window下分号;隔开）; 在 src 下创建my_pkg 和 my_cmd; 包文件放入到 my_pkg 中，比如 test.go 1234567package my_pkgimport "fmt" func Test()&#123; fmt.Println("Hello,world!") fmt.Println("You used a function defined in my_package!")&#125; 在命令行src目录，执行 go install my_pkg 将创建 pkg 目录并声成 my_pkg.a 文件。 my_cmd 中放入 package main，比如 hello_world.go 12345678package mainimport( "my_pkg")func main()&#123; my_pkg.Test()&#125; 在命令行src目录，执行 go install my_cmd 将创建 bin 目录并生成可执行文件成 hello_world.exe 文件。 目录结构： src/ $\quad$ my_pkg/ $\qquad$ test.go $\quad$ my_cmd/ $\qquad$ hello_world.go Tips:# import 包A的时候，会自动调用包A的init()函数（i字母小写）。如果该包A又import了别的包B，会优先调用包B的init()函数，最后才调用main包的init()函数。 一个包的init()函数可以定义多个，每个都会被调用，调用的顺序按文件名排序。同一个文件也可以定义多个init函数。 其他：# fmt.printf verbs： %x %b：16进制，2进制显示；%t：显示 bool 结果；%T：显示值的类型；%v：显示值；%p：显示地址；\n：换行 Sublime text 3 上一个编辑处: alt+- 下一个编辑处: alt+shift+- GoSublime： GoSublime快捷键列表：ctrl+.+. (连击 .) 查看声明：ctrl+.+h 代码跳转：ctrl+shift+左键 package control：ctrl+shift+p Goland：退回上一次光标位置：ctrl+win+alt+左键 参考资料：# [1] 无闻;Go编程基础系列视频. [2] Alan A.A. Donovan; Brain W. Kernighan; The Go Programming Language; 2015.]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地项目上传到 Github 仓库、Git开发命令]]></title>
    <url>%2F2018%2F07%2F04%2F2018-7-4%2F</url>
    <content type="text"><![CDATA[生成本地版本库 （.git 文件夹） 创建 SSH key 创建 GitHub 仓库 上传到 GitHub 仓库 本地修改跟新到 GitHub 仓库 生成本地版本库 （.git 文件夹）# 123git initgit add .git commit -m "..." 操作如下， 创建 SSH key# 查看 c盘 用户目录是否包含 .ssh 目录。如果包含，打开 id_rsa.pub 文件并复制里面的内容（密钥） 如果不包含 .ssh 目录（上述操作会报错），通过如下命令创建 1ssh-keygen -t rsa -C "your email address" 其中 C 为大写。然后按照前面的方式复制密钥。 将密钥添加到 GitHub 创建 GitHub 仓库# ![](https://upload-images.jianshu.io/upload_images/1863961-d05408b0cfc2e198.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) ![](https://upload-images.jianshu.io/upload_images/1863961-f7edb952c890e069.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) 上传到 GitHub 仓库# 12git remote add origin git@github.com:jiangtaohe/test.gitgit push -u origin master 本地修改跟新到 GitHub 仓库# 若本地已经关联到仓库，git remote add origin 命令行去掉。 1234git remote add origin git@github.com:jiangtaohe/test.gitgit add .git commit -m "..."git push 1git add file file的修改添加到暂存区 1git commit file -m "备注信息" 创建新的版本库，并将file在暂存区中的修改添加到新的版本库中 1git stash 将工作区和暂存区的修改装箱后回到版本库初始状态(相当于撤销所有修改) 1git stash pop 将 git stash装箱的修改倒出 1git checkout -- file 撤销file工作区的修改 12git checkout --ours (--theirs) filegit add file file发生merge冲突时，完全采取本方(他方)的修改 1git fetch origin dev:local_dev 获取远程分支dev的代码，并在本地创建本地分支local_dev 1git pull origin dev 拉取远程分支dev与当前分支和并(merge) 1git reset --hard commit_id(前4位数) 切换到某个版本库 1git branch branch_name 新建分支 1git branch -d branch_name 删除分支 1git merge branch_name 合并分支 123git statusgit loggit reflog 1git remote -v 打印远程仓库名称和地址 1git remote set-url --add origin git@gitlab.com:jiangtaohe/test.git 增加一个远程仓库 1git rm --cached a.txt git不再跟踪a.txt, 但文件仍保留 1git rm -f a.txt git不再跟踪a.txt, 同时文件被删除]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅历]]></title>
    <url>%2F2018%2F07%2F01%2F2018-7-1%2F</url>
    <content type="text"><![CDATA[有时人的成长在不知不觉中发生，且不论是生理上的还是心智上的。比如人的身高的变化，对于旁人看来是很大的改变，但对于当事人可能是相当无感的（除非你刻意的去测量，并画出折线图来，很少人会这么做吧）。与前者相比，心智的 变化更加隐蔽，你甚至都不好记录数据作出图表来，但并非一无所知，有些是可以从生活中窥见端倪。 少年时期的我非常讨厌吃苦瓜。你可能已经脑补出我第一次吃苦瓜时候的表情了。 “是人吃的吗？”，当然没有说出口，但我当时就那么想的。让我惊奇的是母亲竟吃得津津有味 (＃°Д°) 好像我吃了一口假的苦瓜。转念一想，既然这玩意儿都叫苦瓜了，那是必苦无疑了。那时的我品不来苦瓜的味道，自然理解不了母亲的有滋有味了。后来偶尔遇到苦瓜也会吃上一小片，“浅尝辄止”，毕竟还是那个味儿啊，干嘛亏待自己。直到上了大学后才有了改变。 话说我在大学吃了几年食堂，喜欢吃的都吃得腻了。某天心血来潮，要不来盘炒苦瓜吧。我突然发现这玩意儿不那么苦了，甚至感到别有一番风味。原以为跟苦瓜品种有关，所以后来回外婆家时，我特意让外婆做了道炒苦瓜，吃起来也是不那么苦。我意识到“物是人已非”，苦瓜还是年少时的苦瓜，而我却不一样了。这种变化当然有生理上的，但更多的是心智上的，而后者是自己的阅历在不断增长的结果。有些事情阅历够了自然就会了。 类似的还有对戏曲的理解。以前的我根本就看不了戏曲的，无感啊。随着年龄的增长，我对戏曲的态度也发生改变，虽然谈不上热爱，但多少也能品到其中的一些韵味。尤其是京剧，不愧为国粹，尽管没看过一个完整的剧目，也叫不出多少剧目的名字来，当我被表演者的一颦一簇、一唱一打所牵动的时候，我知道那就是好的戏曲，了不起的艺术！]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独憩]]></title>
    <url>%2F2018%2F06%2F19%2F2018-6-19%2F</url>
    <content type="text"><![CDATA[有时候我真地喜欢安静，独自一人，不被打扰，做一些没有意义的事情。 当下简单地唯水，笔，布而已。]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运动与冥想]]></title>
    <url>%2F2018%2F06%2F14%2F2018-6-14%2F</url>
    <content type="text"><![CDATA[近来又把跑步纳入日常。跑着跑着，跑出了一点心得，今以记之，算是对自己坚持锻炼的勉励。 一开始，我是跟着小伙伴一起跑来着，然后有几次自己跑。回想运动时候的状态，我发现自己跑运动地更充分，锻炼的效果也更好。据说跑步半个小时是一种很好的锻炼方式，前提是要保质保量。保质就要求全程保持在跑的状态，你可以跑快点或者慢点，但不要是 walking 。保量就是最少跑半个小时，当然你也可以按照路程（多少圈跑道）来计。值得注意的是，这个保质保量因人而异，你需要给自己设立合理的目标且不能够轻易就可达成。 专注于跑步有利于目标的达成。这也解释了为什么独自跑步的效果更好（与小伙伴相互鼓励当然也挺好），因为不用刻意去协调别人，你可以更快找到自己的节奏。当你持续地专注于自己的身体和感觉时，你可以体会到控制与活力，而维持标准动作可以加深这种体会。因此，不妨把跑步看作一次冥想训练，专注于自我，体会积极的力量也接受脑涨腿乏感觉，但不要让疲劳占据上风，否则你将动作变形，愈感举步维艰。 避免外部干扰因素有助于专注，比如握着手机，携带狗狗等尽量避免。 最后需要强调的是注意安全。当身体出现不适的时候，千万不要勉强。前两些天就有公众号报道某男子跑步过程中摔倒了两次仍要坚持，最终导致猝亡的杯具。还有上文提到独自运动有助于专注，但还是避免去人少的地方活动，尤其是女同学。学校的操场是绝佳的场所，因为有其他的同学还可以减少孤独感，对自己的坚持是很有帮助的。]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多宝塔碑精选]]></title>
    <url>%2F2018%2F06%2F10%2F2018-6-10%2F</url>
    <content type="text"><![CDATA[《多宝塔碑》精选三十七字。来源于搜狐“书法思考”，今藏以时习之。 横、竖：(三、王、十、半、中)# 撇、捺：(大、手、又、年、入)# 点：(心、涵、浮、并、尚、小、於、其、感)# 钩、挑：(宗、求、观、表、见、咸、食、以)# 折：(自、名、了、山、牙、矣、母、外、女)#]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 笔记]]></title>
    <url>%2F2018%2F05%2F28%2F2018-5-28%2F</url>
    <content type="text"><![CDATA[创建 flask instance（也就是一个应用）两种方式：1. (module) 在URL\my_app.py中加入 12from flask import Flaskapp = Flask(__name__) 2.(package) 在URL\app_folder\__init__.py中加入 12from flask import Flaskapp = Flask(&apos;app_folder&apos;) 阅读 Miguel Grinberg's book: Flask Web Developent SECOND EDITION 中的一个小应用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import os from datetime import datetime # python 标准库，datetime.utcnow()from flask import Flask, render_template, session, redirect, url_for, flash from flask_bootstrap import Bootstrap # flask 扩展from flask_moment import Moment # flask 扩展from flask_wtf import FlaskFormfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequiredfrom flask_sqlalchemy import SQLAlchemyfrom flask_migrate import Migratebasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__) # 创建应用app.config['SECRET_KEY'] = 'hard to guess string'app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(basedir, 'data.sqlite')app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = Falsebootstrap = Bootstrap(app) # templates 文件夹中 base.html 扩展了 bootstrap/base.htmlmoment = Moment(app) # 设置日期、时间的格式。moment.js 由 base.html导入db = SQLAlchemy(app) # 创建数据库migrate = Migrate(app, db)class Role(db.Model): __tablename__ = 'roles' # 表格名称 id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship('User', backref='role', lazy='dynamic') # 与 User 类关联。backref 给 User 类创建 role 属性，在生成 User 对象时通过 role 与一个 Role 对象关联。 def __repr__(self): # 直接输出对象或者通过 print 打印对象时，信息都按__repr__方法中定义的格式进行显示。 类似的 __str__ 只有在 print 打印时才生效。便于调试。 return '&lt;Role %r&gt;' % self.nameclass User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey('roles.id')) def __repr__(self): return '&lt;User %r&gt;' % self.usernameclass NameForm(FlaskForm): name = StringField('What is your name?', validators=[DataRequired()]) # DataRequired()要求提交时表单不为空 submit = SubmitField('Submit') # 表单的提交按钮。 在 render html 时，添加 type='Submit' 属性@app.shell_context_processordef make_shell_context(): # 运行 flask shell 时自动从 app(hello.py) 导入 db, User, Role return dict(db=db, User=User, Role=Role)@app.errorhandler(404) def page_not_found(e): # 404，500 为 html 错误类型 return render_template('404.html'), 404 # 返回元组@app.errorhandler(500)def internal_server_error(e): return render_template('500.html'), 500'''@app.route('/')def index(): return render_template('index.html', current_time=datetime.utcnow())'''@app.route('/user/&lt;name&gt;')def user(name): return render_template('user.html', name=name) # name=name， 前者代表 user.html 中的 name 变量，后者代表由用户在网址栏中输入的值，即&lt;name&gt;@app.route('/', methods=['GET', 'POST']) def index(): # Post/Redirect/Get pattern，inde()被调用两次 form = NameForm() # 生成表单实例 if form.validate_on_submit(): # 表单被提交且通过所有的 validators （这里只有 DataRequired()一个）时返回 True old_name = session.get('name') if old_name is not None and old_name != form.name.data: flash('Looks like you have changed your name!') # 当两次提交的内容不同时显示提示框。flash() 里的参数被 模板 base.html 中的 get_flashed_messages() 函数提取。 session['name'] = form.name.data # 保存表单提交的 data return redirect(url_for('index')) # url_for('index') 返回 root URL。redirect() 发出对 root URL 的 GET请求，作为对 POST 请求的回应。 return render_template('index.html', form=form, name=session.get('name')) # 对 redirect() 的 GET请求的回应。# 加入数据库@app.route('/', methods=['GET', 'POST'])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() # 查询表单提交的用户名 if user is None: # 如果不在数据库中就把它加入 user = User(username=form.name.data) db.session.add(user) db.session.commit() session['known'] = False else: session['known'] = True session['name'] = form.name.data return redirect(url_for('index')) return render_template('index.html', form=form, name=session.get('name'), known=session.get('known', False))]]></content>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to Create a Personal Blog]]></title>
    <url>%2F2018%2F05%2F22%2F2018-5-22%2F</url>
    <content type="text"><![CDATA[The Structure of The Blog Apply For a Github Account and Create a Repository Create hexo source file download and install create file select and add your theme 2.4 deploy the source file to the github repository When you see this blog post, you have already had some kind of motivation to create a personal blog, maybe it is to possess something, record your ideas or just to be cool. From my observation, most people who have a personal blog are the computer professionals. But this does not mean you have to create your blog with much computer knowledge. The rest of this post will show you the process can be easy and fun. The Structure of The Blog# From the structure, you almost know what to do next. You don't have to build a browser, since your PC has already had one. You just need to do the left two things, applying for a github account as the remote platform to store your blog files, creating the local source file which is the root of your blog. Apply For a Github Account and Create a Repository# Click Github to apply. Create hexo source file# Most of the source file is generated by Hexo which is a popular blog framework and is based on Node.js. We also need Git to deploy the source file to your newly created repository. download and install# Node.js Git Hexo is installed with the Git tool. After installing the Git, click your the right mouse button on the desktop and select the &quot;Git Bash Here&quot; option (means open the bash window in the current directory). Type the following commond to enter your home directory. 1cd ~ Input the following commond to install Hexo. 1npm install hexo-cli -g create file# Create hexo source file . You can make your own file name to replace &quot;hexo_source&quot;. 1hexo init hexo_source select and add your theme# Select a theme from hexo themes library . You can also use hexo-new-vno if you like the theme of my blog 😉. Then use the commond to add the theme file to your hexo source file you have already created. 12cd hexo_sourcegit clone https://github.com/monniya/hexo-theme-new-vno themes/new-vno You will see the new-vno file at ...\hexo_source\themes\new-vno if not wrong. In fact, hexo has a built-in theme landscape. Open ...\hexo_source\ _config.yml (you can use editors like atom, sublime etc.) and revise some arguments. 1234567891011121314151617181920title: 小禾の新世界subtitle: STAY HUNGRY, STAY FOOLISH!description: (～￣▽￣)～ 嗨 (✿●'◡'●)keywords:author: #your name as authorlanguage: zh-Hans timezone: email: #your email addressurl: https://your_user_name.github.ioroot: /your_user_name.github.io/plugins: hexo-generate-feed # you need input "npm install hexo-generate-feed" in the git bash window to install this plugin.theme: new-vnodeploy: type: git repo: https://github.com/your_user_name/your_user_name.github.io.git branch: master More details of configuration click here. And revise arguments in ...\hexo_source\themes\new-vno\ _config.yml to configure the theme. 12345678910111213menu: 归档: /archivesrss: /atom.xmldescription: RSSsocial: weibo: #your weibo address github: #your github address stack_overflow: facebook: twitter: google_plus: To write a blog, you just write a markdown file in .../hexo_source/source/ _posts folder. 1234567---title: How to Create a Personal Blogdate: 2018-05-22 21:37:37tags: hexo---My first blog post ...## The Structure of The Blog 2.4 deploy the source file to the github repository# Install the deploy tool. 1npm install hexo-deployer-git --save Start to deploy. 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d After the deploy you can visit your blog by typing &quot;your_user_name.github.io&quot; in the browser. You have already built the blog. Congratulations!]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
