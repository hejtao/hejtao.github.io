<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx Notes]]></title>
    <url>%2F2020%2F03%2F22%2F2020-3-22%2F</url>
    <content type="text"><![CDATA[启动、停止和重启 启动、停止和重启# 12345678910111213141516nginxsystemctl start nginx.servicesystemctl start nginxps aux | grep nginxngxin -s quitnginx -s stopkillall nginxsystemctl stop nginx.servicesystemctl stop nginxnginx -s reloadsystemctl restart nginx.servicesystemctl restart nginxnetstat -tlnp]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flutter Notes]]></title>
    <url>%2F2019%2F12%2F28%2F2019-12-28%2F</url>
    <content type="text"><![CDATA[Fascinating Flutter Pages Dynamical Disco Notes Fascinating Flutter Pages# Dynamical Disco# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import 'package:flutter/material.dart';import 'dart:math';class DiscData &#123; static final _rng = Random(); double size; Color color; Alignment alignment; DiscData() &#123; color = Color.fromARGB( _rng.nextInt(200), _rng.nextInt(255), _rng.nextInt(255), _rng.nextInt(255), ); size = _rng.nextDouble() * 40 + 10; alignment = Alignment( _rng.nextDouble() * 2 - 1, _rng.nextDouble() * 2 - 1, ); &#125;&#125;void main()&#123; runApp( MaterialApp( debugShowCheckedModeBanner: false, home: Scaffold( body: Container( color: Color(0xFF15202D), child: SizedBox.expand( child: VariousDiscs(50), ), ), ), ), );&#125;class VariousDiscs extends StatefulWidget &#123; final numberOfDiscs; VariousDiscs(this.numberOfDiscs); @override _VariousDiscsState createState() =&gt; _VariousDiscsState();&#125;class _VariousDiscsState extends State&lt;VariousDiscs&gt; &#123; final _discs = &lt;DiscData&gt;[]; @override void initState() &#123; super.initState(); _makeDiscs(); &#125; void _makeDiscs() &#123; _discs.clear(); for (int i = 0; i &lt; widget.numberOfDiscs; i++) &#123; _discs.add(DiscData()); &#125; &#125; @override Widget build(BuildContext context) &#123; return GestureDetector( onTap: () =&gt; setState(() &#123; _makeDiscs(); &#125;), child: Stack( children: [ Center( child: Text( 'DISCO FACE', style: TextStyle(color: Colors.white, fontSize: 50), ), ), for (final disc in _discs) Positioned.fill( child: AnimatedAlign( duration: Duration(milliseconds: 500), curve: Curves.easeInOut, alignment: disc.alignment, child: AnimatedContainer( duration: Duration(milliseconds: 500), decoration: BoxDecoration( color: disc.color, shape: BoxShape.circle, ), height: disc.size, width: disc.size, ), ), ), ], ), ); &#125;&#125; Notes# 组建调试 12345@override Widget build(BuildContext context) &#123; debugPaintSizeEnabled = true; return Container(); &#125; ListView 支持 app body 的滚动, Column + SingleChildScrollView]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Notes]]></title>
    <url>%2F2019%2F12%2F01%2F2019-12-1%2F</url>
    <content type="text"><![CDATA[linux 文件移动、复制 文件权限 Linux查找命令 其它 vim linux# 文件移动、复制# mv a b：重命名 mv /home/music/往后余生.mp3 /home/loved_music/ ： 把往后余生剪切（移动）到 loved_music下 cp -a /home/jiangtao/* /home/huaxi ： 复制jiangtao下的所有文件到huaxi下 cp -a /home/jiangtao /home/huaxi ：文件夹拷贝，得到 /home/huaxi/jiangtao rm -rf /home/jiangtao/* ： 删除jiangtao下的所有内容。-r不管有多少级目录，一并删除；-f 强行删除，不作任何提示 rm -rf /home/jiangtao ：删除jiangtao目录 cat textfile：显示内容 cat -n textfile1 &gt; textfile2：把 textfile1 的文档内容加上行号后输入 textfile2 这个文档里 cat -b textfile1 textfile2 &gt;&gt; textfile3：把 textfile1 和 textfile2 的文档内容加上行号（空白行不加）之后将内容附加到textfile3 文档里 文件权限# chown (change ownership)将指定文件的拥有者改为指定的用户或组 123&gt;sudo chown -R $(whoami) /usr/local/Cellar&gt;sudo chown root:hejtao file.txt&gt;sudo chown hejtao:hejao file.txt -R: 处理指定目录以及其子目录下的所有文件 chmod abc file 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限 r=4(可读)，w=2(可写)，x=1(可读写) 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5。 chmod 765 file.txt 等价于 chmod u=rwx,g=rw,o=rx file.txt Linux查找命令# find . -type f -mmin -10 搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录 find . -name 'my*' -ls 搜索当前目录中，所有文件名以my开头的文件，并显示它们的详细信息 find . -type f -iname &quot;*.php&quot; find . -size -1M 小于1M的文件 find . -type d -not -iname &quot;*php&quot; 找不以php结尾的目录 find . -maxdepth 1 -type f -iname &quot;*.conf&quot; 当前和下一级目录 find . -type f -iname &quot;*.php&quot; -exec grep &quot;function&quot; {} + locate -i hello.txt 查找文件位置，-i 选项忽略大小写 locate ~/m 搜索用户主目录下，所有以m开头的文件 其它# echo 显示字符串，转义字符，变量；内容定向至文件 12345&gt;echo hello, world! &gt; hello 先清空在写入&gt;cat hellohello, world!&gt;echo hello, world! &gt;&gt; hello 换行后写入 grep ipfs . -r -n 在当前目录的多级文件进行（-r）递归搜索，并（-n）显示行号 grep -i -n &quot;function&quot; ./* ps -ax | grep ipfs : 显示系统中当前运行的包含 ipfs 的进程 一行输入多个命令,使用; 、&amp; 、| 1234&gt;echo i am hejtao\n ; echo hello hejtaoi am hejtaohello hejtao ifconfig: 查看和配置网络设备 mkdir rmdir touch new.txt新建文件 man查询命令的信息 停止命令 Ctrl + c 强制停止命令 Ctrl + z 清空窗口 clear 自动联想TAB 关闭sudo halt 重启 sudo reboot. ssh root@207.148.109.110 mosh root@207.148.109.110 scp ./Go语言编程_许式伟.pdf root@207.148.109.110:~/my_files 本地上传到vps 清屏 clear 屏幕翻页 ctrl l ls -l (long) -r(reverse) -s(size) ls &gt; outfile.txt 结果写入outfile.txt ls | tee outfile2.txt 显示结果，并将结果写入outfile2.txt apt-cache 断开ssh：ctrl d vim# 保存退出：shift zz 不保存退出：shift zq 删除本行： dd 复制本行：yy 行标下粘贴：p 行标上粘贴：P u 撤销上一步的操作,输入u两次，你的文本恢复原样 Ctrl+r 恢复上一步被撤销的操作 ggVG 全选 , 选中内容以后就可以d 删除选中内容 , y 复制选中内容到0号寄存器 gg 让光标移到首行，在vim才有效，vi中无效 V 是进入Visual(可视）模式 G 光标移到最后一行]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学通识50讲]]></title>
    <url>%2F2019%2F11%2F25%2F2019-11-25%2F</url>
    <content type="text"><![CDATA[发刊词：数学该怎么学？ 模块一 ｜ 数学的线索 01 ｜ 导论：数学通识课的体系和学习攻略 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理 03 ｜ 数学的预见性：如何用推理走出认知盲区 04 ｜ 数学思维：数学家如何从逻辑出发想问题 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学 07 ｜ 数学应用：华罗庚化繁为简的神来之笔 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要 09 ｜ 数列和级数（二）：传销骗局的数学原理 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密 模块二 ｜ 数学的概念 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大 12 ｜ 三次方程：数学史上的发明权之争 13 ｜ 虚数：虚构这个工具有什么用 14 ｜ 无穷：我们为什么难以理解无限的世界？ 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？ 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？ 17 ｜ 无穷小（三）：用动态和极限的眼光看世界 18 ｜ 19 ｜ 模块五 ｜ 微积分 30 ｜ 微积分（上）：如何从宏观变化了解微观趋势 发刊词：数学该怎么学？# 在上个世纪80年代，国内流行过一句口号：“学好数理化，走遍天下都不怕。”因为当时的教学体系还不完善，数理化这些基础学科比重大，而且容易培养出建设型人才，所以受到重视。当然，随着综合教育体系的完善，这个口号也就不再流行了。 ... &emsp;&emsp;但是，在今天来看，无论你的专业和工作是什么，你都会发现，数理化这些底层学科是不是牢固，真的决定了一个人的知识结构能搭多高，在专业上能走多远，尤其是数学。数学作为一切科学的基础，它化繁为简，直击本质的思考方式，让很多人获益。那些数学成绩好的人，做起事来总是一通百通，很容易脱颖而出。 但是事实上，很多学习数学的人会感觉自卑，并产生厌恶。这是为什么呢？当然不是数学本身的问题，也不是我们人的问题，而是因为我们和数学之间缺失了一个桥梁。数学是一种抽象的知识体系，而我们人要靠经验感知才能认识世界，这中间需要一个桥梁，这个桥梁一旦构建起来，每一个人都能受益于数学。 那么是否每一个人都有可能学好数学呢？公平地讲，数学往深了学确实很费脑力，对大多数人来讲有点难度，但是把平时用到的、能够提升我们思维的数学学好，是每个人都能做到的。接下来我就用一个例子谈谈怎么学数学。 2017年，一位原央视的主持人请我和中国科技馆前馆长王渝生先生，做一个有关数学的节目。在节目开始前，主持人对我说，她高考时数学不及格，是个学渣。我说，你能有今天这样的成就，显然不是学渣。数学没学好，不是你的问题，是教学的方法和考量学生的方法不对。 然后我就告诉她美国顶级的高中和大学是怎样教数学的。在美国最好的高中，把数学课由中国的一门课变为8～10门内容不同的课程，每门课还要开A、B、C三个难度不同的班。比如我们中国（从初中到高中）的几何，被分为平面几何A、B、C，解析几何A、B、C，等等各种难度的课程和班级。 入门的那几门数学课足够浅显，难度较低的班会讲得更浅，内容更精简。比如平面几何的A，讲清楚几何学的原理和用途，以及推理的思维方式就好，就不让学生再做那些比较难的证明题了。像点、线、面、三角形、四边形和多边形等概念，以及平行、垂直等关系，其实对任何人都不难，都能取得好成绩。 当然，由于你选择了简单的数学，也就没有浪费时间去攻克对自己来说很难的数学内容，就可以学更多自己喜欢的文学或历史，然后申请那些更适合自己的大学。 更重要的是，虽然你所学的数学课不多，也不深，但好歹掌握了基本概念，掌握了相应的思维方式，如果将来真想再继续学，还是有可能的。否则你学了一大堆理解不了，考试通不过的内容，不仅浪费时间，而且本来能学会的简单内容也全丢掉了。 不信我问你，还记得住计算圆球体积的公式，或者方程组的解法吗？那些都不是什么很难的内容，但是因为大家做不出数学题，考不出满意的分数，就从心里彻底放弃了这门课，以至于那些本应该记住的简单内容也干脆全忘光了。可以说，结果就是早早地就把通往数学的桥梁毁掉了，从此以后，再也没有体会过数学思维的乐趣，放弃了智识生活的可能。 那么在我的数学课中，我会教什么？大家又应该怎么学？学完以后应该怎么用呢？ 在教学方面，我会模仿美国的数学教学方式，为你做好三件事，也是我这门数学课的三个教学特色： 首先，我会为你重建这座通往数学的桥梁，帮你把那些熟悉的知识点各安其位，放进知识体系里。 我的讲法是把一门数学课从完整的体系变成一个个的知识点，讲透之后，再还原回体系。让你能够熟练地把握知识点和课程体系的关系，这门课的体系也就搭建好了。 以最难的几何学为例，再难的几何题，其实最终都可以拆成那五个最基本的公理。这五个公理，又可以推导出几何学的任何结论。就如同几种乐高积木可以搭出任何形状一样，我会在几何那个模块介绍给大家。 至于这个体系能构建得多大，则要看学生能够接受的程度，学生接受的程度高，就搭一些复杂的，接受程度低，就搭一些简单的。但是能够拆解和搭建哪怕是比较小的体系，通识教育的目的就达到了。 **其次，在介绍这些关键数学知识点的同时，我会讲清楚它们在数学上的位置，以及和各种知识体系的相关性。**这样不仅能够把各种知识打通，而且能够让你在自己的行业中超越绝大部分从业者。 我的《数学之美》出版后，很多人读后感慨，原来数学对信息处理帮助这么大。但其实那本书中介绍的全部内容，不过是一些知识点。而仅仅是理解了那些知识点的计算机从业者，就已经获得更强的竞争力了。 再比如，为什么大家熟知的勾股定理，在国际上通行的叫法是毕达哥拉斯定理？因为勾股定理只是经验，而毕达哥拉斯定理却完成了数学证明，但教科书出于发明权的考量并没有说明，结果就是把数学这门课的逻辑基础搞丢了。以至于很多人大学毕业工作多年依然搞不清物理上用实验证实的定律和数学上用逻辑证明的定理有什么差别。如果基础就打歪了，以后进入工作，很可能出大错。 **最后一点，也是最重要的，是通过学习数学，实现思维方式的跃进。**为了做到这一点，并不需要讲述太难的数学知识，而是需要讲透。 事实上，我们无论是讲透毕达哥拉斯定理，还是更难懂一些的欧拉公式，都可以在讲述的过程中将数学家超出凡人的思维方式讲清楚。毕竟对于大部分人来讲，一辈子用不到欧拉公式，如果他们不容易理解，用简单的例子把道理讲清楚就变得格外重要了。 至此，我为你搭建的桥梁就算建造好了，当然，还是需要你亲自从这头走到那头去，我们接下来谈谈你怎么做，才能跟着我学好数学： 一个学好数学最重要的办法是，不断训练自己的思维方式。 很多人喜欢读侦探小说和悬念小说，喜欢解决各种谜题，这其实是人类的一种天性，也是对头脑的一种训练。学数学能够提高我们这方面的能力，让自己成为一个“深入的思考者”（Deep Thinker）。 世界上有两种所谓的聪明人，一种是反应很快的人，被称为Quick Thinker，另一类则是Deep Thinker，也被称为Hard Thinker，无论是哪一种，其实都是可以后天训练的。训练快速反应最好的办法就是多听多看。但是训练Deep Thinker，就需要练习一环扣一环解套的本事了。 用数学做这种训练的好处是，它经过上千年的发展，已经有一整套训练材料了。所以学数学，就像打游戏晋级一样，一点点往前探索，一个个击破难题。 最后，请你查看课表（即目录），当然我还是想再从不同的维度上帮你提炼一下。 首先，我们会学到虚数、极限、微分、积分等等这样的具体知识点，掌握它们之间的关联，以及它们在人类认知方面的地位。这样我们就能理解人类是如何扩展自己的认知的。如果我们把自己成长的过程和人类成长的过程做一个对标，就能通过它们扩展我们自己的认知。 再往上一个维度，你还能了解数学在人类知识体系中的地位，比如数学和艺术的关系，和法律，和经济学的关系，等等。很多时候，数学不能直接解决我们的实际问题，但是它能够给我们提供一个思路。 在更高的维度上，我会通过介绍数学的发展史，帮你理解数学思维，也就是人类的认识是如何从直观到抽象，从静态到动态，从宏观到微观和宇观，从随意到确定，再到随机，等等。 好，如果你想重新认识一下数学，和我一起感受一次数学之美，那么欢迎你加入我的《数学通识50讲》。当然，除了数学通识，我还将开设一系列的通识课程，把每个人都需要掌握的人类知识精华，整理成课程，帮每个现代人装备自己的头脑，找到最适合这个世界的思维方式。 好，我们马上开始数学之旅！ 模块一 ｜ 数学的线索# 01 ｜ 导论：数学通识课的体系和学习攻略# 这一讲算是数学通识课的学习地图，我会带你俯瞰一下这门课的全貌，便于你系统地把握课程内容。 ... &emsp;&emsp;如果把人类的知识体系用学科来划分的话，数学可能是其最大的一个，因此要想在50讲左右的时间里介绍它的全貌是不可能的。 所幸的是，作为通识教育，你不需要学那么多，而且数学的各个分支，无论难易，从体系到研究方法，再到应用方法是共通的。 成年人接受数学通识教育，其实只要做到一点就够了，就是从理解初等数学到理解高等数学——（也就是）把自己对所有和数学相关的概念和方法的理解程度，从静态的、具体的，上升到动态的、规律性的。要达到这个目的，不需要讲很多内容，但需要一些线索。 下面我就简单介绍一下课程的内容和我选择它们来串联课程的理由。 第一模块讲的是数学究竟是怎么从一个猜想，得出推论，然后又产生实际应用的。 根据《时间简史》和《大设计》的共同作者蒙洛迪诺的讲法，人类早期的所有知识体系都是：“前科学”。这是好听的说法，难听的说法叫做“巫术式”的。 在所有早期文明中，唯一的例外是古希腊。但即使是在古希腊，我们所知的那些大学问家们比如泰勒斯、赫拉克利特、亚里士多德，他们的思维依然是前科学的，不是科学的，因为他们对客观世界的解释，加入了太多主观的想象。而在古希腊，真正具有划时代意义的人则是毕达哥拉斯。 毕达哥拉斯是将数学从经验上升到系统性学科的第一人。他确立了数学的起点，也就是必须遵循严格的逻辑证明才能得到结论的研究方法，这就让数学从早期那些需要靠测量和观测的学科，比如天文学、地理学和物理学中，脱身出来，成为所有基础学科之上，带有方法论性质的特殊学科。 因此，我们会先从毕达哥拉斯学起，他也是整个第一模块的主线。那么我会怎么讲这个模块呢？ 首先，我会讲毕达哥拉斯最出名的毕达哥拉斯定理，也就是我们所说的勾股定理。 我们还知道，毕达哥拉斯最被后人所诟病的地方是否认无理数的存在，并假装视而不见，还把提出这个问题的学生害死了。 对此，今天很多人说他无知，顽固，拒绝接受真理等等。但是要知道，在当时人们所知的有限的数学领域中，毕达哥拉斯是这个体系的教主，他需要这个建立在逻辑之上的体系的一致性和完备性，而逻辑上的一致性也是数学最基础的原则。 因此，他发现无理数的出现会破坏他所理解的数学体系的完备性，动摇数学大厦时，他就采取了教主们才会采用的激进行为。 毕达哥拉斯真正的错误在于，他不懂得要维系数学这个体系，需要定义“无理数”这样的新概念。无理数造成的数学危机解决之后，数学反而发展了，并没有像毕达哥拉斯想的那样崩溃。 毕达哥拉斯另一个了不起的成就，就是算出了黄金分割的比例。从黄金分割出发，毕达哥拉斯发现了数学和美学的关系，并且开始用数学指导音乐。 概括来讲，我们在第一模块“数学的线索”里面，以毕达哥拉斯为线索，一方面将很多数学知识点串联起来，向大家展示数学是什么样的体系，另一方面，我们把毕达哥拉斯作为例子，说明数学发展和体系构建常常经历的步骤。也就是，从特例到引理再到定理、推论，最后到应用的全过程。 但是数学的发展又非单一线索，从一个点出发可能产生了很多并列的推论，因此我们不得不在课程中把并行的内容按顺序来讲。比如在第一模块中，我们在讲完黄金分割的应用后，又会回来讲和它有关的等比数列。 当你知道数学定理是如何从猜想到推论再到应用的过程，我们就进入课程的第二个模块“数的概念”，通过讲述人类对数字这个概念的认识历程，我会给你一个思维工具——“从具体到抽象”，从而解释为什么你从小学数字，但其实对数字的认识并没有提高，以及学数学多年都不能为己所用的原因。 照理讲，我们的认知水平应该随着所学内容难度的提升而提升，但是通常不是如此。很多人学到大学关于数字的概念时，对数字的理解方式，还停留在小学阶段。 比如，对于无穷大和无穷小这样的概念，很多人依然以为它们只是巨大的数字和极小的数字。事实上它们和我们日常遇到的具体数字不同，代表着变化的趋势和变化的快慢。因此从小学到了大学，大家对数字的理解就应该从静态到动态，但遗憾的是，很多人并没有这样的认识。 当一个人用小学的思维方式，学习大学的数学内容，一定会觉得难以理解，于是对数学敬而远之。这并不能怪学习的人，而是怪很多数学课在设计时，没有把听众当作未来的主人，而只是把他们当作未来的工匠，教给他们一些具体知识让他们干活，而非更高级的思维认知。 因此，在第二模块中，我们会突出数学作为“抽象思维”工具的作用，比如人们从具体算术到抽象代数，用到解方程、虚数等等，为什么要学习它们？因为它们的角色是人类造出来的抽象工具，在现实生活中并不存在，但是有了它们，现实的问题就好解决了。数学通识教育，一个重要目的就是让大家习惯于使用这样的抽象工具。 **第三、第四模块的内容集中在我们熟知的几何和代数。**在几何的模块中，我们会以它为例子介绍什么是公理化的知识体系，它是如何建立的。 在代数的模块中，我们会重点介绍函数和向量。函数这个概念的发明，把我们人类的认知从个体上升为整体，从单点联系，上升为规律性的网状联系。 比如同一道题目，从小学到大学，理解是不同的，这是一个从单纯理解数字大小，到理解它方向性的过程。 在小学，如果我们看到一道题，说张三以50公斤的力拉箱子，李四以30公斤的力拉，拉箱子的力是多少？答案很简单，就是80公斤。但是到了初中，我们有了负数的概念，你就要问他们拉箱子的力是相同的还是相反的，如果是相反的，只有20公斤。 再往上学，我们就要问他们拉箱子的力夹角是多少度，在90度时和120度时，受力可是不同的，这就进入到了大学思维。 向量和线性代数，就是把数字从单纯的数值，变成了有方向的数值。所以，我认为这两大知识点，最能代表代数模块的内涵，可以帮助大家提升认知。 **第五模块是微积分，这已经是高等数学的内容了。**但是，我们其实在第二模块里已经不知不觉地把微积分中最难的内容提前讲了，因此在这个模块，大家反而会觉得简单。 对于微积分，它和初等数学的工具有什么不同呢？人们开始对把数学从关注静态的关系，变成了对动态规律，特别是瞬间规律的把握上。理解这一点，并且主动应用到工作中，是我们学习微积分的目的。那些很难的概念，解题技巧，其实毫不重要。 好，前面你学习了数学公理、数字、几何、代数和微积分，提纲挈领地回顾了数学发展的历史，这些分支有个特点，就是能给出问题唯一的答案。 但是到了近代，很多现实问题很难有完全确定的答案。于是，**为了研究不确定世界的规律性，概率和统计发展起来了。**数学的这个分支在今天我们充满不确定性的世界里非常重要，也是所谓的大数据思维的科学基础。 纵观数学发展的历程，以及我们应该具有的数学思维历程，我们可以看到这样的趋势，从个案到整体规律，从个别定理到完整的知识体系，从具体到抽象，从完全的确定性，到把握不确定性。 无论是在整个的课程中，还是每一个模块之内，我们都能看到这样人类认知升级的过程。当然，我觉得这也应该是我们自己的认知升级过程。 在课程的最后，我们会介绍数学和其它学科的关系。这样能够在完整的知识体系中，更好地理解数学。接下来，我们就先从毕达哥拉斯讲起，从数学的起点开始我们的数学之旅。 02 ｜ 勾股定理：为什么在西方叫毕达哥拉斯定理# 我们的第一个模块，会为大家介绍数学的线索，也就是它从猜想到定理再到应用的整个过程。我会以毕达哥拉斯定理为例来展开。 ... &emsp;&emsp;勾股定理大家都不陌生，它讲的是直角三角形两条直角边的平方之和等于斜边的平方。 但是，这个定理在国外都被称为毕达哥拉斯定理。毕达哥拉斯（Pythagoras，约公元前580年—约公元前500年）是古希腊著名的数学家和知识的集大成者。 相关阅读：《科技史纲60讲》15｜为什么其他文明没有诞生古希腊的科学？ 接下来有两个疑点，你的中学老师可能在刻意回避或者说没有讲清楚，而它们又实在太重要了。 第一个疑点：这个定理是否在毕达哥拉斯之前就被发现了？ 我们过去的教科书里讲，据汉朝的数学书《周髀算经》的记载，早在公元前1000年的时候，周公和商高这两个人就谈到了“勾三股四弦五”。他们的年代比毕达哥拉斯早，因此教科书中讲是中国人商高最早提出这个定理的，于是称之为勾股定理或者商高定理。 我们先不说《周髀算经》里所记载是否靠谱，就算靠谱，它也只是记载了一组勾股数（即直角三角形直角边和斜边都是整数的情况），并不能说明发现了其中的规律。因为比周公和商高早1500年，古埃及人在建造大金字塔时就已经按照勾股数在设计墓室的尺寸了。 如果再往前推，美索不达米亚人早在公元前18世纪左右就知道很多组的勾股数（包括勾三股四弦五），而且留下了实物证据。比如耶鲁大学的博物馆里就保存了一块记满勾股数的泥板。 接下来就产生了第二个疑点，古埃及和美索不达米亚为什么不去争夺这个定理的发现权呢？ 简单地讲，所有这些古代文明不过是举出了一些特例而已，甚至没有提出假说。我们在后面的课程中会看到，很多时候特例中反映出的规律和后来真正的定理可能是不同的。所以，这种特例就没有意义。 如果像美索不达米亚人那样举了很多特例，而且没有发现例外，是否可以认为他们最先发现这个定理呢？答案是否定的，因为光举例子还是不够的，还需要做出一个明确的规律性的描述，这种描述我们可以把它称为命题。 一个命题在没有证明之前，只能算是猜想，比如著名的哥德巴赫猜想。而总结出一个猜想和证明定理依然是两回事，当然这是比举几个例子进了一大步了。 再接下来，猜想如何证实呢？在这一点上数学和自然科学完全不同。那么我们就要说到数学和自然科学的三个本质差别，也是这一讲最重要的三个知识点，它们能够帮助我们理解数学特殊的方法和思维方式，或者说了解数学的推理世界与我们真实的测量世界的区别。 1.测量和逻辑推理的区别 我们知道几何学源于古埃及，当地人出于农业生产的考虑，对天文和土地进行度量，发明了几何学。但是，度量出来的几何其实和真正的数学还有很大的差距。 比如说，古代文明的人们确实观察到勾股数的现象，他们画一个直角三角形，勾三尺长、股四尺长时，弦长恰好就是五尺长，于是就有了勾三股四弦五的说法。 但是这里面存在一个大问题，我们说长度是三尺，其实并非数学上准确的长度，用尺子量出来的3，可能是3.01，也可能是2.99。这样一来勾三股四弦五就是一个比较模糊的说法了。 为了让你更好地理解这一点，我们不妨看这样一个例子。 图中左上方有一个8x8的方格，它的面积是64，这没有疑问吧？我按照图中所示的粗线将它剪成四部分，两黄两灰，再重新组合，就得到了一个13x5的长方形，它的面积是65。请问面积是64的正方形怎么重新组合一下面积就多出1，变成65了呢？ 当然我们知道64不等于65，这里面一定有问题。那么问题在哪儿呢？其实，问题就出在再拼接时，它们并不是严丝合缝的，只不过缝隙较小，大部分人看不出来罢了。 在数学上，观察的经验可以给我们启发，但是它不能成为我们得到数学结论的依据，数学上的结论只能从定义和公理出发，使用逻辑严格证明得到，不能通过经验总结出来。 讲回到勾股定理，一个工匠注意到勾三股四弦五这个现象，和提出一个具有普遍意义的定理是两回事。 我们通过观察还可以发现，如果勾3.5，股4.5，那么弦大约是5.7，这个“大约”的误差只有万分之一点六左右（弦长大约是5.700887），古代任何测量都发现不了。这时如果你说勾3.5股4.5弦5.7，从物理上来说基本正确，但是在数学上就错了。这是第一个差别，就是测量会出错，但推理不会。 那么，如果我们抛开误差的影响，是否可以认为早期文明的人们发现了勾股定理呢？也不能，只能说他们观察到一些现象，而非发现了定理。这涉及到数学和自然科学的第二个主要区别，证实和证明的区别了。 2.用事实证实和用逻辑证明的区别 在自然科学中，一个假说通过实验证实，就变成了定律。比如说与牛顿同时代英国的大科学家波义耳同法国科学家马略特一同发现：一个封闭容器中气体的压强和体积成反比。这很好理解，因为体积压得越小，内部的压强肯定越大。这两个人通过很多实验，都证实了这件事，于是这个定律就由他们两个人的名字命名了。 但是，如果有一个非常爱较真的人一定要抬杠，说你们证实了所有的情况（各种体积和压强的组合）吗，你们敢保证没有例外么？波义耳和马略特肯定会说，我们不敢保证没有例外，但是这个规律你平时使用肯定没有问题。 果然，后来人们真的发现当压强特别大时，这个定律就不管用了。但是没有关系，在大多数条件下，这个定理依然成立，今天人们在做产品时，依然可以用。 事实上，今天几乎所有的自然科学的定律和理论，不仅存在一个被推翻的可能性，而且有很多的例外。比如，证实引力波的实验，也只能保证99.9999%的可能性结论是对的。 但是，在数学上，用实验来验证一个假说（在数学上常常被称为猜想）是不被允许的，我们在后面介绍无穷大时，大家还会看到这甚至是做不到的。数学的结论只能从逻辑出发，通过归纳或者演绎得出来。它必须完全正确，没有例外，因为但凡有一个例外（也被称为反例），就要被完全否定掉。这里面最著名的例子就是哥德巴赫猜想。 今天人们利用计算机，在可以验证的范围内，都验证了这个猜想是对的，但是因为没有穷尽所有的可能，就不能说猜想被证明了。因此，我们依然不能在这个基础上，构建其它的数学定理。 所以，数学世界和测量世界第二个区别就是，数学理论必须要证明，保证没有例外。 3.科学结论相对性和数学结论绝对性的区别 为什么数学要那么严格，它的定理为什么不能有任何例外，更不能特殊情况特殊处理呢？因为数学上的每一个定理都是一块基石，后人需要在此基础上往前走，试图建立一块新的基石，然后数学的大厦就一点点建成了。在这个过程中不能有丝毫的缺陷，一旦有，整个数学大厦就轰然倒塌了。 还是以勾股定理为例，它的确立，其实教会了人们在平面计算距离的方法，在此基础之上，三角学才得以建立，笛卡尔的解析几何才得以确立，再往上才能建立起微积分等数学工具。此外我们这个模块后面会讲到的无理数的出现、黄金分割，都和它有关。 人类今天发明的各种科技，像无线通信、航天等等，依赖于这些定理。如果出现了一个违反毕达哥拉斯定理的反例，不仅是这个定理失效了，而且整个数学就完蛋了，我们的科技也就时灵时不灵了。因此，数学上的每一个定理，必须也只能通过逻辑推演来证明，用多少实例来验证都没有用。 理解了数学定理确立的过程，以及它随后产生的巨大影响，我们就清楚定理和定理证明在数学中的重要性了。正是因为这个原因，西方才将这个定理命名为毕达哥拉斯定理，以彰显他的贡献。是他明确提出这个定理，并且严格地证明了它，从此毕达哥拉斯定理才成为了数学上普遍的规律。 有了一个个的定理，数学就得以建立起来，而且这个建立在逻辑推理基础上的大厦很坚固。在数学上，当一个新的定理被证明后，就会产生很多自然的推论，每一个推论可能都是一个重大的发现，甚至能带来人类认识的升级。毕达哥拉斯定理的一个直接推论，就是无理数的存在。这个内容我们下一讲再讲。 要点总结： 数学和自然科学不同，它不相信测量，不是建立在实证基础之上，而是建立在逻辑基础之上的。数学也不接受大部分情况正确，但是包含例外的定理。这样整个数学大厦的基础才得以稳固。 数学定理确立的过程大致是这样的，一开始可能只是大家注意到几个特例，然后发现很多例证提出猜想，猜想经过证明就成为了定理，定理会有推论，在此基础上，会有新的定理和应用。 思考题： 在物理学中，从不同的角度理解光，会得到粒子说和波动说两种解释，数学从两个角度证明一个定理，会不会得到不同的结论？ 03 ｜ 数学的预见性：如何用推理走出认知盲区# 上一讲，我们通过毕达哥拉斯定理解释了数学的起点，它必须是从逻辑推理和证明得来的，而非测量和实验出来的。我们这一讲就看看以毕达哥拉斯定理为起点出发，人们又发现了什么。 ... &emsp;&emsp;在古希腊毕达哥拉斯（Pythagoras，约公元前580年—约公元前500年）所处的时代，人们认识到的数学上的数字都是有理数，它们都有我们平时所说的分数，具有A/B这样的形式，比如2/3，其中A和B都是整数，当然，整数本身可以被看成分母等于1的分数，比如5=5/1。 毕达哥拉斯有一个很怪的想法，他坚信世界的本源是数字，而数字必须是完美的。整数很完美，而且分数的分子分母也都是整数，不会是零碎的，因此也很完美，整数和分数所构成的有理数让毕达哥拉斯一直坚信自己的想法。 但是，一旦毕达哥拉斯定理被他证明以后，麻烦就来了。 我们上一讲讲过，数学的定理具有永真的特点，它一旦被证明，你就找不到反例。当人们在用毕达哥拉斯定理时，就发现了问题。假设某一个直角三角形的两条直角边长都是1，那么斜边该是多少呢？ 你可以根据毕达哥拉斯定理算一下，既然两条直角边都是1，它们各自的平方也是1，加起来是2，因此斜边的平方是2，这个斜边就是一个自己乘以自己等于2的数字，从大小来看，它应该在1和2之间。接下来请问，这个自己乘以自己等于2的数字是否是“完美”的有理数？ 根据毕达哥拉斯对所有的数字都是有理数的认识，它必须是啊！好，我们就假定存在一个数字是R，它能够写成R=A/B的形式，其中A、B都是互素的整数（互素指的是两个数写成分数的形式，不可再约分），那么现在假设这个数字R的平方恰好等于2。注意一下，这里面有三个条件，请一定牢记： A、B都是整数。 A、B互素，也就是不能再约分了。 A/B的平方等于2。 这三个条件能否同时满足呢？答案是不能。为了说明这一点，大家不妨跟着我做一个简单的逻辑训练。 好，这次我们用的方法，在数学上被称为反证法，就是先假定你说的条件都满足，然后我来找出矛盾之处，这样就能推翻原来的假设。 具体到上面这个问题，我们从上面第三个条件出发，就得知分子A的平方除以分母B的平方等于2： $ A^{2} / B^{2} = 2 $ 我们把B的平方移到等式的右边2那边，就是： $ A^{2} = 2 \times B^{2} $ 接下来我来问你，A是奇数还是偶数？你会说它当然是偶数，因为等式的右边是2乘以B的平方，都乘以2了，那A的平方结果肯定是偶数，奇数的平方不可能是偶数，所以A必须是偶数啊。既然A是偶数，我可以把A写成2乘以一个数，比如C，也就是A=2C这种形式，其中C是一个整数。 那么A的平方等于什么呢，等于4倍的C的平方，我就用这个4倍的C的平方代替A的平方，放在原来等式的左边，右边还是2乘以B的平方： $ 4 \times C^{2} = 2 \times B^{2} $ 这个等式的两边都可以用2去同时除一下，于是就成了两倍的C的平方等于B的平方： $ 2 \times C^{2} = B^{2} $ 这时我问你，B是偶数还是奇数？你会说当然是偶数，因为两倍的C的平方是偶数啊。 这下子问题来了，怎么A和B都是偶数呢，这不就和上面的第二个条件，也就是“A、B互素，不能再约分”矛盾了吗？ 那么到底哪里发生了错误呢？我们先要检查一下我们的推导过程，我们发现没有错误。因此，要么是数学错了，要么是认知错了。勾股定理的证明是通过严格的逻辑推导出来的，也不会有错，于是只能是我们的认知错了。 也就是说，存在一种数字，我们过去没有认识到，它们无法写成有理数的形式，即A/B，它们是无限的不循环小数，在这样的数中有一个自己乘以自己时等于2。我们今天把这个数字称为√2。这一类的数字其实很多，它们被统称为无理数。 据说毕达哥拉斯的学生希帕索斯最初发现了上述矛盾，于是就去和他的老师讲了。而毕达哥拉斯是个把数学看成宗教的人，出现无限的不循环小数在毕达哥拉斯看来是数学的漏洞，但他又无法把这件事解释圆满，这就是数学史上的第一次危机。 毕达哥拉斯决定把这位学生扔到海里杀死，好把这件事隐瞒下来。 当然，像√2这样的“无理数”存在的事实，却不可能一扔了之，无理数是客观存在的，毕达哥拉斯是隐瞒不住的，这件事成为了这位确立了数学在人类知识体系中地位的大学问家的一个污点。 另一方面，无理数的危机也带来了数学思想一次大的飞跃，它告诉人们，人类在对数字的认识上还具有局限性，需要有新的思想和理论来解释，认识本身不能有禁区，那些事先为科学设定的条条框框，最终都不得不被抛弃掉。 从这个例子中，我们能学到什么呢？ 首先，在遇到数学和现实的矛盾时，我们需要仔细检查推理的过程是否有疏漏，这种情况占大多数。 在排除了推导的错误后，接下来，两种情况必居其一： 要么，我们的眼睛和我们的认知欺骗了我们，就如同我们以为所有的数都是有理数，但其实不是。这是常有的事情。 要么，最初的假设错了或者说不够好。这种事情在历史上偶尔发生过，但是很少，我们后面在介绍非欧几何时会仔细讲到这种情况。这种情况我们通常不需要考虑。 既然在推导没有错误时，通常是我们的观察或者认知欺骗了我们，那么我们就应该把危机看成是转机。人类在科技历史上，很多重大的发明发现恰恰来自于上述的矛盾。 在数学史上，除了无理数被发现之外，几个重大的事件，比如无穷小概念的提出，对无穷大的重新认识，以及公理化集合论的确立，都和那些矛盾有关。这些矛盾有时看似造成了数学危机，但是，人们化解了危机之后，就拓展了认知，建立起新的理论。它们或者让数学本身进步了，或者在科学上做出重大的预言。 几年前约翰·霍普金斯大学的天体物理学家亚当·里斯（Adam Riess）教授给我讲的一堂课，我至今记忆犹深，他让我坚信了对数学本身的信心。里斯等人通过计算，发现宇宙的质量是负数，这怎么可能？难道是数学错了，还是我们对宇宙的理解完全错了？ 里斯在做了仔细的检查后首先排除了推理有误的可能性，然后他们不得不承认数学的结论是对的，出错的是我们眼睛（包括观测的仪器）。于是，他们认定宇宙中一定存在我们看不见，更不了解的东西，那些就是所谓的暗能量，亚当·里斯等人后来因此获得了诺贝尔奖。 在自然科学上，很多重大的发现，最初都不是直接和间接观测到的，而是根据数学推导出来的，比如说黑洞、引力波便是如此。在历史上，血液循环论、现代原子论最初都是建立在数学推导上的假说，然后才逐渐被实验验证了。 世界上有很多我们不能依靠直觉和生活经验理解的事物，但是我们可以从数学出发，经过一步步推导得到正确的结论，我们甚至不需要亲力亲为地做一遍就知道我们的结论一定是正确的。这就如同你不需要会踢足球，才能评论足球一样，你只需要把握住一些准则就可以了，而数学就是这样的准则。 要点总结： 从数学的定理出发，可以推导出很多针对现实世界的推论，从而改变我们对现实世界的看法，这就是数学的预见性。比如，毕达哥拉斯定理的一个直接结果指出了无理数的存在，它把人类对于数字的认识范围从有理数扩展到了无理数。 当然，可能有读者朋友会想，那些预见性可能和我们相去甚远，其实不然，后面我们会举一些和大家相关的例子，比如如何识破庞氏骗局，为什么不能做空股票，等等。 康德讲：“世界上只有两样东西是值得我们深深景仰的，一个是我们头上的灿烂星空，另一个是我们内心的崇高道德法则。”他所说的星空，其实包括数学这样的知识体系。对于很多云山雾罩的事情，我们只需要在逻辑上推演一遍，就能把问题的真相搞清楚了。 思考题： 我们都知道，整体要大于部分，因此10厘米长的线段上的点应该比5厘米长的多，但是如果我能用严格的逻辑证明它们上面的点一样多，你相信么？ 欢迎给我留言，并把文章分享出去，让更多的人感受到数学之美。我们下一讲再见。 04 ｜ 数学思维：数学家如何从逻辑出发想问题# 这一讲就来举一个发生在我们身边的例子，说明如何利用数学原理思考问题，并且久而久之在遇事时本能地用一个数学的头脑辅助判断。 ... &emsp;&emsp;当然，数学思维高深精妙，但是万法归一，最重要的那个原则就是，从逻辑出发想问题，这样就可以发现很多日常中被忽略的问题，从而找出真正答案。 我们先从最近的一次金融危机讲起。在金融危机之后，英国女王问全世界的经济学家们，你们这么多人怎么没有一个预测到金融危机？这让学者们都很没面子。 经济学家们当时确实是过于乐观了，所以很多暂时不会出问题的隐患被隐瞒了下来，因此大家会觉得没问题。不过当时有一些其实并不懂经济学的人，利用特殊的方法，嗅出了问题。 比如巴菲特从直觉出发，觉得那些金融衍生品刻意包装，一定是为了掩盖很多真相，坚决不参与那场赌博。像这样的投资人并不少，其中最著名的是一个叫贝尔（Michael Burry）的医生，他数学很好，而且雇了一些数学家替他做事，靠坚守数学上的一些基本道理，成为那场豪赌中获利最丰厚的赢家。 贝尔他们的逻辑其实很简单，就是我们常常说“复利”增长从数学上讲是无法长期为继的。比如说，财富每年增长7%，这个速度在很多人看来并不算快，但是如果两千多年前的陶朱公以及他的后人能维持这个财富增长速度，哪怕当年他只留下一个铜板，今天他的传人所拥有的铜钱的数量要超过宇宙中的原子的数量，这在现实中当然不可能。 做投资的人都清楚，在一开始投资基数较小的时候，能够维持指数增长，一旦基数变大，就做不到了，还不切实际地想维持，就是拆东墙补西墙的庞氏骗局了。 很多人觉得自己足够聪明不会上庞氏骗局的当。但是变相的庞氏骗局要识破就没那么容易了。2008年金融危机中的罪魁祸首CDS，就是奸商们包装的一个不容易看懂的庞氏骗局，接下来我们就来说说它。 我们知道2008年金融危机的原因是美国房屋的次级贷款出了大问题，那它和CDS有什么关系呢？别着急，我们从次级贷款说起，然后你就明白什么是CDS了。 让我们先回到克林顿当总统的时代。那时，克林顿政府为了让本来付不起首付的穷人也能买房子，允许银行提供购房首付的贷款。比如100万的房子，通常需要贷款80万，首付20万，但是假如有一个人叫林肯，他没钱支付首付，当时除了允许他把房子先抵押了，从A银行获得正常的80万贷款，还允许他以较高的利息从B银行获得首付20万的贷款。 如果房价一直上涨，这没有问题，因为即使林肯付不起月供了，A银行也可以通过变卖房子收回自己的80万贷款，剩余的钱，还够B银行也能拿回自己的20万。B银行提供的就是次级贷款，由于它的风险显然比A银行大，因此利率也高，这样如果有个别几个人的贷款拿不回，它也能从其他购房者偿还的利息中填补漏洞。 当然，B银行还有一个更稳妥的做法，就是从高利息（比如每年10%）中拿出一部分（比如1%），向C保险公司购买贷款者违约的保险。 保险公司C根据历史数据发现房屋贷款收不回来的情况很少，只占房贷的2%左右，而它从B银行可以连续挣15年的钱（不考虑复利的因素），15年下来，担保10亿的房产就能收入1.5亿，成本只有2000万，这利润率高达650%的事情保险公司自然就答应了。 接下来，投资银行D看到C公司做了这样一笔好买卖，非常眼红，就和C商量将这10亿美元的保险生意卖给自己，并愿意留给C公司20%的好处，即3000万美元。C公司想，1.5亿虽然多，但是要承担15年的保险义务，不如一次性得到3000万实在，就答应了。 D公司是投资银行，更精明，将C公司为B银行作担保的业务，包装成证券，叫做CDS（信用违约交换），加价3000万美元卖给了另一家投资银行E。E公司可能将各种类似的CDS又打了一个包，以新的证券形式在市场上市了。 就这样，在经过无数次包装后，CDS的内部结构大部分人已经看不懂了，但是人们总觉得自己可以从下家身上赚到钱。于是一同把CDS炒到了50万亿美元这么大的规模，这甚至超过当时美国房市本身的总值。 这个骗局的本质是什么呢？就是大家炒来炒去，都是在赌一件事，就是今后15~30年，房价会一直快速上涨。 然而，房价不可能永远快速上涨，特别是在经济本身没有上涨的前提下。一旦有大量房主还不上钱，或者不愿意还钱，这些CDS就变得一钱不值。更糟糕的是，给购房者提供次级贷款的银行，后面的保险公司以及很多购买了CDS的投资银行也都完蛋了，整个金融体制就垮了。 这件事可以通过数学算出来，其实不只是刚才提到的贝尔，当时有不少人在CDS的骗局破灭之前，发现了问题，后来挣到了大笔的钱。只不过贝尔挣钱的比例太高，他的故事后来被拍成了电影《大空头》，他从此成为了名人。 接下来我们就说说什么叫做具有数学的思维。它不是指算小账算得清楚，而是说善于基于数学知识，使用逻辑发现问题，或者预见到不得不做的事情。我们在生活中，有时不得不面对非常复杂的问题，里面有很多噪音难以一一滤出，这时就需要掌握一种工具让我们能够不受噪音影响作出正确的判断。而数学常常是我们可以信赖的工具。 下面我和你分享一个我的经历。有一次在一个由政府组织的关于“一带一路”的座谈会上，几位领导问我，“吴教授，咱们关起门来讲，中国输出了那么多资本，最后钱能回来么？” 我说，挣得回来，挣不回来，我不知道，因为这里面牵扯太多的因素。但是资本输出和帮助其它国家富裕这两件事都必须做，我可以从数学证明这两件事的必要性。他们很好奇这件事和数学有什么关系，于是我继续讲： 中国在过去的四十年里，实现了每年8%的指数增长，除了中国人勤劳勇敢。另外有两个数学上的原因，一是因为最初的基数小，能够持续高速增长。二是过去国内市场空白一片，供不应求，国际上其它国家人均财富，比中国高很多，相比中国过去的生产能力，购买力近乎无限。 但是40年后的今天，中国人均GDP已经达到了世界的平均水平，总的经济体量已经世界第二，占全世界的18%。那么中国还能不能维持过去的增长速度呢？从数学上讲，根本做不到。 我们就假定中国经济能够按照每年6%的速度增长，这个速度虽然比过去慢了一点，但是比全世界3%的平均水平快很多。再过40年，中国GDP大约能增长10倍。而全世界经济增长的速度只有3%左右，再扣除中国的贡献，中国以外的国家和地区的增速只有2.34%左右，这样增长40年，只能增长1.5倍左右，那时中国GDP大约占到全世界50%。 这时候矛盾就出现了，中国以外有全世界4/5以上的人口，总的财富仅仅和中国一样多。那时，全世界都没有足够的财富买得起中国不断制造的产品和不断提供的服务。这时只有两个办法，一个是提高世界其它地区的购买力和经济增长，另一个是让中国经济增长降到世界的平均水平。 后者显然不是我们想要的，于是借钱给其它国家购买中国的产品和服务，当然中国可以换得一些战略资源，同时让世界其它国家也维持足够高的经济增长，以便它们能维持购买力，并且还得起钱，就是中国不得不做的事情了。而这就是“一带一路”要实现的目标。至于投资和贷款能否拿得回来，那要看操作的水平了。 在历史上，19世纪的英国，二战后的美国，以及80年代的日本，都是资本输出国，因为你不输出资本，大家就买不起你的东西，而你也就无法维持体面的经济增长。中国10年前不提“一带一路”的事情，一是因为还没有必要性，二是因为自己的钱不多；近几年才提出，是因为今天中国正好从处在人均GDP低于世界平均水平到变成高于平均水平的转折点上。因此在商业和资本两个层面全球化就变得迫在眉睫了。 我们在生活中，常常说“算笔账”这三个字。其背后其实就是说基于一些事实，用数学这个工具来考量，发现问题。为什么数学思维可以很容易地发现问题呢？因为我们常常用到在数学证明中的工具：矛盾律。 就是说一个事物不能既有A属性，又没有A属性。比如我们上一讲在证明√2是无理数时说到，如果它是有理数P/Q，那么P和Q这两个整数，既不能同时是素数，又必须同时是偶数，这就违背了矛盾律。同样，中国既不可能拥有全世界所有的财富，还让世界其它地区买得起中国的商品，这也违背了矛盾律。 要点总结： 通过数学的思维方式，发现生活中的问题，看清我们必须采取的行动，这就是学习数学的意义所在。这既可以被看成是认知的升级，也可以被认为是掌握了数学原理之后的灵活应用。 当然，数学有很多它做不到的事情，下一讲我们进一步讲讲数学思维的边界。 05 ｜ 数学边界：从毕达哥拉斯定理到费马大定理# 我们前面讲了数学的预见性，以及数学思维的用处，但是这讲我想和你谈谈数学的局限性，大家可能会有一个疑问，就是这种局限性是来自于我们自己的数学知识不够，还是来源于数学本身的局限性呢？ ... &emsp;&emsp;应该讲这两方面的原因都有，第一部分因素在大家听完这门课后会补上很多，不用担心；第二部分则是我们这一讲要讲的内容。我们有必要了解数学本身的局限性，才能更好地使用它的原理和思维方式。今天我们还是从毕达哥拉斯定理的推广说起。 在几何上有很多整数组满足毕达哥拉斯定理，它们就是勾股数，比如（3，4，5），（5，12，13）等。从代数上解释勾股数，就是方程 $ a{2}+b{2}=c^{2} $ 的整数解。 当然，人类总是很好奇，人们就在想，如果上面方程中的平方变成立方，甚至任意N次方，它还有整数解吗？比如，是否有三个整数a，b，c，使得，$ a{3}+b{3}=c^3 $ ？ 这个问题困扰了人类几千年。后来有一个叫费马的数学爱好者就提出一个假说，说除了平方的情况，其他更高次方的方程都找不到整数解，它被称为费马大定理（或者费马最后定理）。 虽然它被称为定理，但数学家们只是把它看成是猜想，或者假说，因为没有证明。我们前面讲到，猜想，哪怕用很多数据验证过了，只要没有证明，就无法成为数学大厦中的一块砖，就无法在它的基础上搭建新的东西。 因此，在费马之后的几百年里，很多数学家都试图证明它，但是都不得要领。费马自己说他已经证明了这个定理，只是那张纸不够大写不下，但后人认为是费马搞错了。 于是费马大定理就成了一道跨越了三个多世纪的超级难题。直到1994年，才由著名的英国旅美数学家怀尔斯证明出来，而这个过程也是一波三折。 1986年，怀尔斯在做了十多年的准备后，觉得证明费马大定理的时间成熟了，终于决定将全部精力投入到该定理的证明上了。为了确保别人不受他的启发率先证明了这个著名的定理，他决定在证明出这个定理以前不发表任何关键性的论文。 但是，如果一个人苦思冥想，推导的逻辑错了自己也看不出来，为了避免这种情况的发生，怀尔斯利用在普林斯顿大学教课的机会，不断地将自己部分的想法作为课程的内容讲出来，让博士生们来挑错。 1993年6月底，怀尔斯觉得自己准备好了，便回到他的故乡英国剑桥，在剑桥大学著名的牛顿研究所举行三场报告会。为了产生爆炸性的新闻效果，怀尔斯甚至没有预告报告会的真实目的。因此，前两场报告其实人不多，但是这两场报告之后，大家都明白接下来他要证明费马大定理了。 于是在举行最后一场报告时，牛顿研究所里挤满了人，据估计可能只有1/4的人能听懂讲座，其余的人来这里是为了见证一个历史性的时刻。 很多听众带来了照相机，而研究所所长也事先准备好了一瓶香槟酒。当怀尔斯写完费马大定理的证明时，很平静地说道：“我想我就在这里结束”，会场上爆发出一阵持久的鼓掌声。这场报告会被誉为了20世纪该研究所最重要的报告会。 不过故事到此并没有结束，数学家们在检查怀尔斯长达170页证明的逻辑之后，发现了一个小漏洞。怀尔斯开始认为这个小漏洞很快能补上，但是后来才发现这个小漏洞会颠覆整个证明的过程。 怀尔斯又独立地工作了半年，但毫无进展，在他准备放弃之前，向普林斯顿大学的另一个数学家讲述了自己的困境。对方告诉他，他需要一位信得过的，可以讨论问题的助手帮忙。 经过一段时间的考虑和物色，怀尔斯请了剑桥大学年轻的数学家泰勒来一同工作，最后在泰勒的帮助下怀尔斯补上了那个小漏洞。由于有了上一次带有乌龙性质的经历，怀尔斯这次有点怀疑自己是在做梦。于是他到外面转了20分钟，发现自己没有在做梦，这才喜出望外。 由于怀尔斯在证明这个定理时已经超过了40岁，无法获得菲尔兹奖，因此国际数学大会破例给他颁发了一个特别贡献奖，这也是迄今为止唯一一个特别贡献奖。关于费马大定理证明过程的更多细节，大家可以听罗辑思维的第85期节目。 那么证明这个古老的数学难题有什么意义呢？这个定理证明过程本身导致了很多数学研究成果的出现，特别是对于椭圆方程的研究。今天区块链技术用到的椭圆加密方法，就是以它为基础的。 在怀尔斯之前，有一批数学家，特别是日本的谷山丰，对这一系列理论做出了重大的贡献，怀尔斯的成功是在他们的工作基础之上的。今天的比特币可以讲完全是谷山丰理论的一次有意义的应用。而在怀尔斯之后，泰勒等人还在不断发展这方面的理论。 对于三个世纪数学家们证明费马大定理的过程，我和大家分享我的三点体会： 今天的数学（指纯粹数学，不是应用数学）真的很难，想在这方面取得突破性贡献不容易，怀尔斯从10岁开始就立志解决这个问题，他努力了30年。他最后的证明长达200页。但是，有了理论，使用它做有意义的事情，还是容易得多。比特币就是一个很好的例子。 数学是世界上最严密的知识体系，任何的推导不能有丝毫的纰漏。怀尔斯差点因为一个小的疏忽毁掉了整个工作，希望通过这一点，大家对数学的严密性有所体会。 数学走到今天这一步，是在一个个定理的基础上一点点搭建起来的，而今天的成就，又为明天的发展奠定了基础，这样数学就获得了可叠加的进步。 毕达哥拉斯定理是，a的平方+b的平方=c的平方的情形。费马大定理是，a的N次方+b的N次方=c的N次方的情形。因此，前者是起点，后者是一个普遍情况的延伸。接下来，如果我们沿着毕达哥拉斯定理和费马大定理继续往前拓展，会是什么情况呢？ 比如任意一个多项式方程 $ 2x^{2} + 3 y^{3} = z^{4} $ ，或者 $ x^{2} + 3 y^{3} - w^{5} = z^{4} $ ，请问它们有没有整数解？这个问题就是著名的希尔伯特第十问题（简称第十问题）。 对于任意一个多项式方程，我们能否在有限步内，判定它是否有解？ 对于一些特例，我们知道有整数解，比如 $ x^{2} + y^{2} = z^{2} $ 就有；对于另一些特例，我们知道没有整数解，比如费马大定理所描述的情况。 但是，对于更多的，一般性的不确定方程，我们不仅不知道怎么解，甚至无法判断一个方程有没有整数解。因此，1900年在巴黎举行的国际数学大会上，希尔伯特在提出23个著名的数学问题时，把它列为了第十个。 第十问题其实隐含了一个更为深刻的认识论问题，就是对于大部分数学问题，我们能否找到答案？到目前为止，我们所能解决的数学问题其实只是所有数学问题中很小的一部分。 当然，很多人会说尚未找到答案不等于没有答案。第十问题实际上在直接挑战数学的边界，也就是说，通过数学的方法，我们可能根本无法判断一些问题的答案存在与否。如果连答案是否存在都不知道，就更不用说通过数学的方法解决它们了。 这样就为数学划定了一个明确的边界。从1900年之后，特别是在二战之后，欧美不少数学家致力于解决这个问题，因为这也涉及到计算机所能处理问题的边界。 第十问题的解决颇具戏剧性。在上个世纪60年代，被认为最可能解决这个难题的是美国著名的女数学家朱莉娅·罗宾逊，她从博士一毕业就致力于研究这个问题，也取得了很多突破性的进展。 虽然罗宾逊因为这方面的贡献成为了美国科学院第一位女院士，美国数学学会第一位女会长，她离解决这个问题最终还是差几步。1970年，俄罗斯天才的数学家尤里·马季亚谢维奇在大学毕业后一年就解决了这个问题，证明了这类问题是无解的，从此在世界上一举成名。 纯数学这个学科除了需要一些运气之外，比拼的是人的智力，智力到哪个程度，成就就到哪个水平，这倒不是宿命论，而是说明人要根据自己的特长选择做事。 第十问题的解决其实扑灭了人类的一丝希望，但是也让人类老老实实地在边界内做事情。人类过去常常希望找到一个工程问题的解析解，即答案是以一个公式的形式存在，这样套入任何数字，就得到了具体的答案。 但是，很多问题最后证明找不到严格推导出来的解析解，当然这也不妨碍大家在工程上可以使用近似的数值解，解决实际问题。认清这一点，做事的方法也就改变了。 搞流体力学和控制理论的人都知道，那里面有很多复杂的非线性方程要解决。在上个世纪，美苏两国走了两条不同的道路。前苏联因为数学水平较高，而计算机技术很落后，因此他们习惯于下硬功夫做很难的数学题，找到非线性问题的解析解。 而在美国方面，数学水平高的人没有前苏联多，但是计算机技术先进，因此他们习惯于把很麻烦的非线性问题变成很多计算量大，但是却很简单的线性问题（或者其它数值计算问题），找到工程上能接受的近似解。 那么谁取得的效果好呢？从结果来看，美国似乎更好些。关于什么是线性方程，我们后面会讲到，这里大家记住线性方程简单，非线性方程非常复杂即可。 要点总结： 我们介绍了费马大定理的来龙去脉，它往前和毕达哥拉斯定理的关系，往后和希尔伯特第十问题的关系。我也和大家分享了我对这个定理被证明过程的体会。 我们通过希尔伯特第十问题介绍了数学的边界，这是一个硬的边界，大家不要试图逾越。但是数学的边界有些时候不是我们解决问题的边界，因为世界上除了数学的方法，还有其他方法。 到目前为止，我们以毕达哥拉斯定理的产生和发展为线索，介绍了数学猜想到数学公理的推导过程，接下来的两讲，我们还是以毕达哥拉斯这个人为线索，谈谈数学的应用，以及在其它知识体系中的位置。 我们下一讲再见。 06 ｜ 黄金分割：毕达哥拉斯如何连接数学和美学# 今天大家对毕达哥拉斯的了解，除了勾股定理，还有就是黄金分割。而他用数学指导艺术和音乐，也确立了数学在其它知识体系和人类文明成就中的中心地位。这一讲，我们就从黄金分割出发，进一步理解数学的用途。这个用途不仅仅是在思维方面，也能实实在在指导我们的工作。 ... &emsp;&emsp;我们先来看一张照片，感受一下黄金分割。 这是雅典卫城的帕特农神庙，它无论是在艺术史上，还是建筑史上地位都很高，如果你度量一下它正面的宽与高，正好符合我们所说的黄金分割。 黄金分割大家并不陌生，你可能还会说出它的比例大约是1:0.618，也就是1.618。其实不仅帕特农神庙本身和里面很多雕塑的关键比例符合黄金分割，著名的雕塑《断臂的维纳斯》，它的身高和腿长的比例，腿和上身的比例也都符合黄金分割。符合这个黄金比例的雕塑或建筑就看上去很顺眼，很美观。 那么黄金分割是如何确定的呢，这个比例为什么看起来顺眼呢？简单地讲，它的美感来自几何图形的相似性。 比如我画了一个符合黄金分割的长方形，它的长度是X，宽度是Y。如果我们用剪刀从中剪掉一个边长为Y的正方形（也就是图中灰色的部分），剩下来的长方形，长宽之比依然会符合黄金分割。 当然，我们还可以继续剪掉一个正方形（图中绿色的部分），剩下的长方形（图中透明的部分）的长宽依然会符合黄金分割的比例。也就是说，如果我们这样不断地切下去，剩余部分都是成同一比例的。 黄金分割的这个比例很容易算出来。根据黄金分割上述的相似性质，我们可以很容易算出来X/Y的比例是1.618左右，更精确地讲，是√5加上1之后的和除以2，这是一个无理数，通常用希腊字母Ф来表示。 黄金分割为什么漂亮？除了在几何上层层相似，这个相似性之外，它也反映了自然界的物理学特征。如果我们把刚才图中的长方形不断做切割，然后将每个被切掉的正方形的边用圆弧替代，就得到了这样一个螺旋线。由于这个螺旋线每转动同样的角度，得到的圆弧是等比例的，因此它也被称为等角螺线。如果你对比这个螺旋线和下面的蜗牛壳，是否觉得很相似？ 不仅蜗牛壳如此，龙卷风的性质乃至像银河系这样星系的形状都是如此。需要指出的是，这不是巧合，而是因为任何东西如果从中心出发，同比例放大，必然得到这样的形状。 或许正是因为黄金分割反映了宇宙自身的一个常数，我们对它才特别有亲切感，所以哪个建筑或者画作如果有意无意满足了这个条件，它就显得特别美。除了帕特农神庙，埃菲尔铁塔等建筑的主要尺寸的比例，也正好符合黄金分割，甚至符合等角螺旋线。 类似的，《蒙娜丽莎》的主要结构部分也可以对应一条等角螺旋线。需要说明的是，无论是帕特农神庙的设计者，还是达·芬奇或者埃菲尔，他们都知道黄金分割，并且刻意使用了这个比例。 最先提出黄金分割的人是谁呢？古埃及人似乎早在4500年前就知道了这个比例的存在，因为大金字塔从任何一个面看上去，其正切面的斜边长和金字塔高度之比正好是黄金分割的比例。 当然，没有证据表明他们算出了精确的比例公式，因为他们不知道有无理数存在。 今天一般认为，算出黄金分割公式的还是毕达哥拉斯。虽然相传毕达哥拉斯是在一次听到一个铁匠打铁和谐而动听的声音后，研究出了黄金分割，但是我觉得这种说法缺乏依据。 大家更认可的说法是，毕达哥拉斯学派的人在做正五边形和五角星的图形时，发现了黄金分割的比例。在正五角星中，每一个等腰三角形的斜边和底边的比例都是黄金分割1.618。 我们刚才说毕达哥拉斯还可能是从铁匠的打铁声中获得了黄金分割的启发，但是无从考证，不过毕达哥拉斯学派利用数学指导音乐是真实的事情。毕达哥拉斯认为，要产生让人愉快的音乐，就不能随机在连续的音调中选择音阶，而需要根据数学上的比例设计： 首先，人们发现两根琴弦，如果它们的长度比是2:1，它们所奏出来的音节就相差一个8度，如果我们用简谱来记录，也就是1-2-3-4-5-6-7-i，高音1的音高是中音1的两倍。在这一个8度中最高音和最低音的频率之比也就是为2:1。 接下来，将这8度又一分为二，按照4:3和3:2的比例，分出一个4度音和一个5度音，它们分别对应1-2-3-4和4-5-6-7-i。注意，由于4/3 x 3/2 = 2:1，因此一个4度音和一个5度音会还原成一个8度音。 最后，每个4度音分成两个整声调，即分出2和3，5度音分为三个整声调，即分出5，6，7。这样就是按照比例设计的了。 如果不按照比例分配音节是什么结果呢？我们听到的声音就如同噪音，而不是有规律的乐音。今天对耳蜗的解刨学研究发现，耳蜗的形状其实也是螺旋线的，和黄金分割的螺旋线非常吻合。这可能是按照黄金分割设定音律后，声音悦耳的原因。 毕达哥拉斯和他的学派对音乐和美学的影响一直影响到柏拉图和亚里士多德，以及后来诸多文艺复兴的学者。 数学不仅和音乐密切相关，也对建筑和绘画艺术产生了重大的影响。我们看从文艺复兴时期开始，到19世纪浪漫主义时期的西方油画，都会惊叹于它们的逼真。这个逼真的效果从哪里来？它源于艺术家们使用单点透视的方法，成功地将三维形象绘制到一个二维平面上。当然，这个绘画技术不是一天发明的。 其实，早在古希腊时期，人们就发现了远处景物显得小，近处的显得大这样的特点，并且将这种特点反映到绘画中了，他们把这种方法叫做短缩法。但是，古希腊人并不知道物体在离开我们远去时，该遵循什么数学法则进行缩小。 到了文艺复兴时期，佛罗伦萨的画家乌切洛沉溺于使用几何学技术将绘画变得逼真，在他为美第奇家族绘制的《圣罗马诺之战》中，我们可以看到明显采用透视法炫技的痕迹。 大家可以仔细看看地上倒下的战士和旁边的长矛，都指向远方的消失点。他用透视法为绘画构建了立体的舞台。不过，如果你仔细看，会觉得这幅画中有不少别扭的地方，因为这幅画好像不止一个透视的方向。 那么是谁真正解决了透视法中的数学问题，并且将这种技巧给予了广大艺术家的呢？他是文艺复兴时期大名鼎鼎的建筑师和工程师布鲁内莱斯基，今天佛罗伦萨的圣母百花大教堂就是他的杰作。关于这座在建筑史上划时代建筑的建造过程，我们在《科技史纲60讲》中已经介绍了，这里就不再赘述了。 布鲁内莱斯基所发明的单点透视法，完全符合我们视觉应有的几何学原理，具体讲就是相似三角形的原理，因此按照这样的方法画出来的画就非常逼真。下面我们就从视觉中的几何学原理出发，简单介绍一下单点透视法。 假定我们前方100米和500米处各有一棵大树，它们都是50米高。我们知道近处的树在我们的眼睛里显得高，远处的显得小。那么看起来，它们的比例到底该是几比几呢？简单地讲，就是应该和距离成反比，即100米处50米高的树，放到500米处，应该显得只有10米高。如果放到无穷远处，则应该是0米高，也就是地平线上的一个点。对于其他的距离，我们看到的高度也是同样和距离成反比。这样，如果我们把各个距离之处50米高的大树连城一条线，就是我们得到的透视的视觉效果了。 下图是我在电视剧《权力的游戏》的外景地（北爱尔兰）拍的照片。从照片可以看出，所有相同大小的景物，按照远近的比例缩小，在远处汇聚到一点。 理解了我们视觉的数学原理，就可以利用它创造出不同的艺术效果。比如在现实世界里，我们看到的是单点透视，因为人的眼睛不可能同时往两边看，但是我们可以在艺术创作中采用两点和多点透视。 下图是两点透视的效果图，景物消失在一左一右两点上。我们通常目光只能集中在一个方向，看不了这么广的视角，但是你如果用鱼眼镜头拍照，就能拍出这样的效果。 我们在今后的课程中，还会讲到，艺术需要数学，也需要光学。印象派绘画的一大特点，就是很好地利用了当时人类在物理上对于色彩和亮度认识的进步。 要点总结： 最后总结一下今天的内容，其实我们是在回答数学的用途。 数学和艺术，以及其他的知识体系有着千丝万缕的联系，我们以黄金分割和透视法为例子介绍了这种关系。了解一些基本的数学知识和方法对我们做其他事情有很多好处。当然，有些人会讲，我们学不会那些数学上的道理啊，没关系，有些方法你只要记住就好。 我们下一讲就从黄金分割出发，介绍优选法，大家只要掌握它的一些基本原则，就能直接使用了。 07 ｜ 数学应用：华罗庚化繁为简的神来之笔# 我们前面讲过，由于数学是一个纯粹依靠脑力进行研究的学科，而它的严密性又非任何自然科学可比，因此很多数学家们有一种高高在上的自我认知，你如果让他们来解决一些实际问题，他们可能会看不上眼。 我在一次聚会中遇到一位数学家和一位数学基础非常好的理论物理学家。后者可能是想往数学上靠近一点，对数学家讲，我们也是搞数学的，数学家马上说，你们搞的那些东西怎么能算是数学？ 这类情况并不是个案，我见过很多持这种态度的数学家，他们甚至不觉得统计学是数学的一个分支。数学家好像每天研究的东西都深不可测，几乎成为了一种神乎其神的群体。 但是，很多真正高水平的数学家，他们不仅能够研究复杂的理论问题，还能够为复杂的实际问题找到简单的，可重复使用的解决方法，比如我国老一辈著名的数学家华罗庚先生。华先生是20世纪唯一一位能够称得上是世界级的中国数学家，他在数论等方面有很多贡献。 不过，绝大部分中国人都不知道华先生的贡献在哪里，只记住了他所推广的优选法。大家之所以记得住优选法，还是因为很多工业生产受益于此。 在现实的世界里，有一大类的问题可以归结为数学上的最优化问题。小到大家平时发面蒸个馒头，一公斤面先要发酵多长时间，然后放多少克碱，或者做一盘菜放多少盐，多少糖；中到我们在投资时，为了同时兼顾风险和收益，股票配比占总资产的多少比较合适；大到设计一个火箭，燃料和氧气的配比多高最合适。这些问题从本质上讲都是最优化问题。 当然，在很多时候决定好坏的因素不止一个，而衡量标准也不止一个。所以很多看起来简单的优化问题，往往在设计时就得非常复杂。 在生活和工作中，在解决每一个复杂的优化问题时，都可以建立一个特定的数学模型，然后用一大堆工具和计算机刻意接近它。但是，对于大多数各行各业的从业者，并不具有足够多的数学知识，也搞不懂那么复杂的数学模型，他们仅仅是希望你给我几个简单的原则来遵守，几个简单的步骤来执行就好。 于是1958年，华罗庚先生就率领了一大批数学家走出大学和科学院大门，到工农业生产单位去寻求实际问题进行研究，提出解决方案。 华先生最先想到的是线性规划。所谓线性规划，就是用很多线性方程在多维空间里划定一个区域，在区域里找最佳值。 下图中每一条直线就是一个限制条件，它们一同划定了一个蓝色的框框，线性规划就是一个简单的在蓝色框框中寻找最佳值的方法。当然，在实际应用中，经常是在高维空间，而非图中的二维空间里求解，但道理都是一样的。 线性规划的本质是将实际应用中那些复杂的非线性求解问题，变成很多个线性方程的问题。要直接解决前者那些复杂问题，需要数学家们做很多推导，显然在实际生产中办不到。而后者，说白了就是死算，当时虽然没有计算机，但是用计算尺还是能完成计算的。 应该讲，华罗庚先生等人的工作，当时还是取得了一批应用成果的，但是不大，因为在工厂机关企业里，就是解线性方程这样简单的数学题，一般人也做不对。 大部分数学家遇到这种情况，恐怕就直接埋怨一线工作的人数学水平低了。但是华先生却没有怪大家水平低，而是觉得自己依然没有把数学变得更简单，于是他进一步总结经验，制定出一套易于被人接受、应用面广的数学方法。他把这些方法称之为优选法。 这种方法非常简单，对当时中国既缺乏数学人才，又缺乏计算机的企事业单位提高效率起到了巨大的作用。 优选法有两个含义，首先它能够找到实际问题的最佳解。其次，它强调寻找最优解的方法本身最简单，或者说最优，具体来说，就是用最少的试验次数来找出最优解在哪里。 假如我们蒸馒头，想试验一下一公斤面放多少碱合适。按照优选法来说，首先我们要找到这个问题的答案，当然你可以每次增加10%一次次地试验，但是这样可能试验的次数特别多。因此，优选法还希望只进行两三次试验，就找到合适的分量。 优选法的原理就是基于我们前面介绍的黄金分割，因此华先生又称之为“0.618法”。为方便说明，我们就假定影响结果的变量（华先生称之为因子）只有一个，比如做馒头时放碱的量。 我们假定1公斤面粉，放碱的重量范围为0～10克之间，精准度到0.1克。当然碱放得太多太少都不行。我们还假定用不同碱量做出来的馒头的口味是可以量化度量的： 根据优选法，第一次试验取在黄金分割点，也就是0～10克之间6.18克的位置。如果我们发现这样做出来的馒头碱多了，那么怎么办呢？根据华先生的优选法，第二次做试验选择从0到6.18克之间的黄金分割点。 我们在前面讲了，黄金分割有一个特别好的性质，就是(1-0.618)/0.618=0.618，这样一来，0到6.18克的黄金分割点正好是10-6.18 = 3.82克的位置，这就使得这前后两次找到的黄金分割点，6.18和3.82中间出现了中间点，恰好是5.0克，也就是说5.0成了两次黄金分割点的对称点： 当然，你如果和没有多少数学基础的人来讲对称中轴之类的话，他未必听得懂。华先生用了一个非常生动形象的方法来解释这一特征，他称之为折纸法，即把第一个黄金分割点，点在一张纸上，然后把纸从中间对折一下，第二个黄金分割点的位置也显就出来了。 优选法的效率可以从理论上严格证明。比如说做5次试验，就可以将范围缩小到原来的9%，6次可以将范围缩小到6%以下。 华罗庚先生的优选法，给这一大类问题找到了一个结果比较令人满意的，步骤非常容易遵循的方法。 上个世纪70年代，华先生出版了小册子《优选法平话》，后来又扩充了一些案例编写了《优选法平话及其补充》。这两本书用了极为通俗的语言和生活中的案例对优选法的原理和操作进行了描述，当时初中毕业的普通工人都能学会使用，于是优选法在中国得到了极大的普及。 当然，在实际应用中，很多问题有多个变量，而不只是一个。优选法对这种问题设计了一种二维的折纸法，具体做法大致是这样： 先确定第一个维度的黄金分割点； 再确定第二个维度的黄金分割点，这样就把二维空间划分为四个部分； 接下来确定第一个维度的第二个黄金分割点； 再确定第二个维度的第二个黄金分割点。 重复第三、第四个步骤，直到找到最佳点。 在数学上很容易证明，在一个平面区间里存在唯一的最佳点，这种方法很容易找到。对于有更多变量的问题，也可以沿着上述思路扩展，但是这时大家会发现，它其实就是线性规划的一个特例。 **华罗庚先生的贡献在于找到了一种一线职工都很容易掌握和运用的数学方法解决实际问题，并且用非常通俗的语言把复杂的方法简单化。**这才体现出大师的水平。反观我们一些专家学者，喜欢故意把理论包装得高、大、上，然后哗众取宠。他们和真正的大师高下立判。 学了知识，关键要使用好。黄金分割的妙处可以讲是上天赐予的，因此了解了它之后，在很多地方我会有意无意地使用这个比例。比如我拍照片时，喜欢将照片中的主角放在照片的黄金分割点处。 下图是我在爱尔兰拍的海边风车，它在照片的黄金分割点。此外，天空的比例、海水的比例，也基本上符合黄金分割的原则。如果把风车放在画面的中央，看起来就显得呆板了，此外无论画面中天太多，或者水太多，都有失平衡。 在投资的配比上，我喜欢将60%～65%左右的资产放在回报高，风险也相对高点的股市上，这基本上符合黄金分割的比例。在剩余的大约38%的资产中，大约25%左右放在相对稳妥的债券上，这也大约是38%的黄金分割点。最后的百分之十几，则是各种复杂的组合投资。 在很多需要作决定的事情上，我自觉或者不自觉地把作决定的时间放在黄金分割点或者反方向的黄金分割点上。 比如需要更多一点时间作比较、作决定的事情，不妨往后放放，但是不要到最后一刻，比如出门度假寻找酒店和机票，你需要时间了解情况，并且货比三家，但是真到了最后一刻，要么酒店订不上了，要么机票太贵。 另一种情况是，我们在作出决定后，需要较长的时间来实现我们的想法，我一般就把作决定的时间点放在0.382的地方，也就是反方向的黄金分割点上。比如要创业，就不要把大部分时间放在想做什么事情上，而需要花更多的时间来做。 当然，每到具体的问题，一定存在比简单利用黄金分割更好的解决办法。但后者的好处是，在你对细节无法了解，甚至一辈子学不会的情况下，总要有一定的做事准则，得到不会太坏的结果，这其实就是数学在很多场合的作用。 很多人抱怨数学不够灵活，其实任何无条件的硬性规定和原则都有这个特点，但是在绝大部分情况下，有准则总比没有好。这是我对数学，特别是对黄金分割的一些感悟，也算是对今天内容的总结。 接下来三讲，我们还是从黄金分割出发，重新理解数列和级数。我们下一讲见！ 08 ｜ 数列和级数（一）：当下很重要，但趋势更重要# 你好，欢迎来到我的《数学通识50讲》。这一讲的主题是：数列和级数：要知道当下很重要，但趋势更重要。 有人问我，是否通过学习数学提高了见识水平？公平地讲，很难找到某一个数学知识点，学了之后让见识马上提升，这种直接产生效果的知识我是没有遇到。但是通过学习一些数学知识和方法，帮助我形成了系统的做事方法，并且改进了看待世界的角度，这却不是虚言。 今天和大家分享两点体会，第一点是我们如何举一反三，通过对单个事件，或者说对个案的研究，寻找出对一系列问题的通解，第二点是从很多孤立事件出发，看到并理解趋势和规律。 为了说明这两点，在接下来的几讲里我们用数列这个专题作为例子，练习把握从个体到群体的规律。当然，讲数列还有一个目的，就是承上启下，它会用到前面讲的黄金分割的知识，并且为后面讲极限、无穷大和无穷小奠定基础。 我们先来看一个具体的数列，给你这样一串数字： 1，1，2，3，5，8，13，…… 如果我来问大家下一个数字应该是什么，比较善于琢磨规律的人会指出，由于每一个数字（除了前两个）都是前面两个数字之和，因此下一个应该是21，即8+13。这个答案完全正确，这样一连串有规律的数字放到一起，就形成了我们要说的数列。 上面这个数列，就是数学中鼎鼎大名的斐波那契数列。在这个数列中，我们是有规律可循的，根据数列中开头几个元素的具体数值，知道整个数列每一个位置元素的数值，就是提升自己从孤立事件里发现规律的能力。 数列其实在今天中国的小学已经讲到，比如常见的两种数列分别是这样的： 1，2，3，4，5，6，7，……以及1，2，4，8，16，32，…… 前一种数列由于相邻两个数字（我们称之为元素）的差距都是1，因此被称为等差数列，后一种由于相邻两个数字的比值都是相同的（都是2），因此被称为等比数列。 在学校里，老师会讲从1加到100怎么计算，也会讲到等比数列（也被称为几何数列）会增长很快。但是为什么要把这些数字放到一起研究，其实老师们是语焉不详的。当然即使老师讲，以小学生的理解能力也未必能体会。因此今天我们就从这里入手，讲讲数列和数字的关系。 数列是一种工具。**它看似是一串数字，但这里重要的是彼此的关联，以及数字的规律，而不是数字本身。**那些规律和我们现实生活中一些事情的发展过程相关，于是这个工具就能够运用到我们真实的世界里了。 比如我们后面要讲到的媒体转播的发散和收敛问题，以及利息问题，就和几何数列有关。以斐波那契数列为例，它其实反映出一个物种自然繁衍，或者一个组织自然发展过程中成员的变化规律。斐波那契数列最初是这样描述的： 有一对兔子，它们生下了一对小兔子，前面的我们叫做第一代，后面的我们叫做第二代。然后这两代兔子各生出一对兔子，这样就有了第三代。这时第一代兔子老了，就生不了小兔子了，但是第二、第三代还能生，于是它们生出了第四代。然后它们不断繁衍下去。那么请问第N代的兔子有多少对？这个数列，就是1，1，2，3，5，8，13，21，…… 如果我们稍微留心一下这个数列的增长速度，虽然它赶不上1，2，4，8，16这样的翻番增长，但其实也很快，也呈现出一种指数增长的趋势。在现实生活中，兔子的繁殖曾经就是这么迅猛。 1859 年，一个名叫托马斯·奥斯汀的英国人移民来到澳大利亚，他喜欢打猎，但发现澳大利亚没有兔子可打，便让侄子从英国带来了24只兔子。 这24只兔子到了澳大利亚后被放到野外，由于没有天敌，它们便快速繁殖起来。兔子一年能繁殖几代，年初刚生下来的兔子，年底就会成为“曾祖”。几十年后，兔子数量飙升至40亿只，这在澳大利亚造成了巨大的生态灾难。 有人可能会问，为什么不吃兔子？澳大利亚人也确实从1929年开始吃兔子肉了，但是吃的速度没有繁殖的快。澳大利亚政府甚至动用军队捕杀，也收效甚微。 最后，在1951年，澳大利亚引进了一种能杀死兔子的病毒，终于消灭了99％以上的兔子，可是少数大难不死的兔子产生了抗病毒性，于是“人兔大战”一直延续至今。从这个故事我想说的是，真遇上指数增长的事情，是非常可怕的。 接下来，我们就定量地分析一下斐波那契数列增长有多快。我们不妨用Fn代表数列中第n个数，那么Fn+1就表示其中的第n+1个数。我们再用Rn，代表Fn+1和Fn的比值，也就是后一个数和前一个数的比值，你可以把它们看成是数列增长的相对速率。 下面的表给出了斐波那契数列中前12个元素的数值，以及增长的速率。 大家可以看出Rn这个比值，很快趋近于1.618了，这恰好是黄金分割的比例。这个结论说明，数学的各个知识点，可能存在某种天然的联系，这似乎是数学这套系统本身浑然天成的结果，因此很多人讲这其实就是数学之美的体现。 我们课程从毕达哥拉斯，讲到黄金分割，然后通过黄金分割，由此把一些数学知识关联起来。这其实就是一个学习数学的技巧了，绝大部分时候不在于题做得有多难，而在于你闭上眼睛，能够用一两条关键的线索把各个知识点串联起来。 通过上面这个比例，我们需要说明两件事情。首先，虽然这个数列最终的走向是收敛于黄金分割的比例，但是在一开始的几个数，并不符合这个规律。这在数学上不是偶然现象，很多时候，仅仅通过少数几个数字得到的所谓的“规律”，其实和采用大量数据后得到的规律完全是两回事，这一点要特别注意。 其次，上述这个比率，几乎是一个企业扩张时能够接受的最高的员工数量增长速率，如果超过这个速率，企业的文化就很难维持了。企业在招入新员工时，通常要由一个老员工带一个新员工，缺了这个环节，企业的人一多就各自为战了。 而当老员工带过两三个新员工后，他们都会追求更高的职业发展道路，不会花太多时间继续带新人了，因此带新员工的人基本也就是职级中等偏下的人，这很像兔子繁殖，只有那些已经性成熟而且还年轻的在生育。 我们在谈到等比数列时，通常会想到指数爆炸，变得越来越大。但是还有另一类等比数列，它们的数字每一个都比前一个小，最终就会趋近于零。 炒股的人有这样的经验，如果每次损失10%，用不了几次就损失一半了，这就是等比数列中每一个数字都在不断按比例衰减的结果。具体讲，大约6次，就会损失一半，大约13次就会损失3/4。 再举一个例子，今天用于测定年代的碳-14测定法，利用的就是这个原理。碳-14是自然界里一种天然的元素，是宇宙射线照射大气的产物，因此它会不断产生，但是它有放射性，因此过一段时间会衰变掉一部分，于是它在自然界保持着一个动态平衡。 生物体在活着的时候，会吸入大气中的碳-14元素（通过二氧化碳），因此它体内的比例就和自然界的比例相同。但是生物体一死，就不会再吸入碳-14了，因此体内碳-14的比例就会逐渐降低。 根据生物遗骸体内碳-14的比例，结合碳-14衰变的速率（也称为半衰期），就能算出古代生物体距今的时间。所以，对于等比数列，我们一般理解的是快速上涨，但是它也可能代表不断地衰减。 数列，其实讲的就是一个趋势。很多时候，我们不仅关心当前这个数有多大，或者我们有多少钱，多少资源，还关心明天它能变得多大，变得多快，这就是数列的意义。至于等差数列，其实是缓慢上涨的，即使每一个都比前面的大，到后来的增长也很不明显。 也就是说，同样是增长的趋势，我们还需要关心积累的速度。比如说，一个刚工作的年轻人，一年挣10万元，能存20%的收入，他每年的工资增长10%。当地的房价是300万元，首付要20%也就是60万，那么他工作多少年能够付得起首付呢？ 这就要计算数列中每一个元素之和了，这个算出来的和，被称为级数。具体到这个问题，我们知道这位年轻人第一年能存2万元，第二年能存2.2万，然后是2.42万、2.66万、2.93万……假如他要存N年才能凑够首付，这个N最后算出来就是15年。 计算公式：S（N）= 2（1 + 1.1 + 1.1^2 + 1.1^3 + …… + 1.1[1]) 建议你亲自算一算这道题，这样你就更能体会为什么必须进步，而且要比同龄人更快地进步了。 思考题： 如果房价保守估计，每年上涨3%，那年轻人又需要存多少年呢？ 要点总结： 我们通过数列（和级数），扭转一下大家对数学的认识：数学大部分时候研究的不是一个个孤立的数，而是要揭示一些规律和趋势。 我们通过斐波那契数列介绍了几何数列可能会带来的指数爆炸问题；同时我们还介绍了另一种几何数列——不断递减的数列。通过斐波那契数列，将它和我们前面介绍的黄金分割关联起来。让大家体会到数学知识点的关联性。 在数列这个领域，我们不仅关心趋势，还关心积累的效果，这是我们接下来两讲要讲的内容。 我们下一讲再见。 09 ｜ 数列和级数（二）：传销骗局的数学原理# 今天，我们来讲讲数列的求和，也就是所谓的级数。在讲这个问题之前，我们来看一个传销的例子。 传销通俗来说，就是拉人头发展下线，你拉别人进来，别人再拉新人进来，每次进人，你都有提成。这么一来，只要你的下线不断把新人拉进来，你什么都不用干，就能躺着拿钱了。大多数搞传销的老鼠会都是这么忽悠你的，我们今天从数学上看看这个看似没问题的“发财经”是否可行。 我们先假定某个传销公司的提成方式只覆盖两层： 每一个人入会需要缴纳1万元（或者买1万元的东西）； 发展一个直接下线，可以从后者的身上提成20%； 直接下线每发展一个下线，可以从下线的下线身上再提成20%的20%。 接下来的问题是，张三入会了，他在什么情况下可能挣到钱？我们先分析两种情况： **情况1：**张三找到5个朋友也加入这个老鼠会，而他的每一个下线也发展了5个下线。这样，他付出1万元，而从每个直接的下线身上得到10000x20%=2000元，五个下线一共给他带来1万元。类似的，下线的下线也可以给他带来一共1万元，两者相加是2万元，张三赚1万元。 **情况2：**张三找到3个朋友也加入这个老鼠会，而他的每一个下线也发展了3个下线，这样他的收入一共只有9600元，反而亏了400元。 从这两个例子可以看出，要想在老鼠会中挣钱，并不是一件容易的事情。一个人可能会因为一时冲动，或者贪财而被卷进去，但是他要在朋友中找到5个和他同样糊涂或者贪财的人，并不容易。而且，由于朋友之间的朋友圈有很大的交集，通常的情况就是张三想发展的人，和他的朋友想发展的人都是一群人。 接下来我们再看另一种情况，假设这个老鼠会对会员“特别好”，每一个会员可以自己拿下面所有层会员的提成，当然每往下一层，提成的比例要逐级指数递减。这样的话，如果层数不断加深，直到无穷，是否处在比较高层的人就有无限的钱可以拿了呢？也未必，这要看每一层的人能发展多少会员了。 在上面第一种情况下，即张三成功地发展了五个下线，而每个下线也发展了5个，张三还真能拿无限多的钱，因为每一层都给他贡献了10000元，如果层数不断涨下去，他就能拿无限的钱。 但是，在情况2时，也就是张三和他所有的下线（既包括直接的，也包括间接的）每人都发展了三个人。虽然张三挣的钱可以超过他付出的10000元，但却是有限的。具体来讲，他从下一层下线获得6000元，下面第二层获得3600元，第三层获得2160元，这样逐渐减少，最后无限加下去，总和并不是无穷大，而是一个有限的数，只有1.5万元。 此外，让我们再看另一个可能性。 **情况3：**张三和他所有的下线每人都发展了两个人，这样张三从各层下线挣到的钱的总数是： 4000 + 1600 + 640 + …… = 6666.67元 虽然看上去他从无穷多的人身上挣到了钱，可是，这挣钱的效率衰减很快。他挣的钱还没有付出的本钱多。很多人误以为只要从无限多的人身上挣钱，就能挣很多钱，这其实是不了解级数这个概念而产生的误解。 接下来我们就从理论上分析一下几何级数，也就是几何数列求和的问题，把这个问题搞清楚，上面那个老鼠会挣钱效率的问题就迎刃而解了。 我们还是从老鼠会分配钱的方法入手。我们假设每一个人发展了K个下线，从每个直接下线分钱的百分比为p，从第二级下线分钱的比例为p2，那么第三级的比例为p3，因为要分3次，以此类推，逐级下降。 如果每一个人交的会费为A，那么一个人能拿到的钱就是： A*K*p + A*(K*p)^2 + A*(K*p)^3 + A*(K*p)^4 + …… 这是一个等比级数，或者叫做几何级数。 这么加下去等于多少呢？很显然，如果K*p&gt;=1，它就是无穷大，这也就是为什么当分成比例为20%时，每个人只要发展五个下线，从理论上讲，能挣无限多的钱。这时，上述的级数被称为发散的。 但是，Kp&lt;1时，上面这个式子虽然加了无穷多项，但到后面都是零点几这样的小数的次方，只能是越乘越小，所以总和是一个有限的数（AKp/（1-Kp））。当然，Kp越接近于1，这个数越大，Kp越小，这个数越小。这时，上述级数被称为是收敛的。 其实可以把每一项的“K*p”用r来表示。什么时候发散什么时候收敛，这个r是关键，它其实是后一个元素和前一个的比值，比如斐波那契数列，它的后一项比前一项，就是黄金分割1.618，至于翻番的指数数列，它就是2，因为我们知道翻番就是翻两倍。当r&gt;=1时，这个级数就发散，加起来无穷大。当r&lt;1时，它就收敛，加起来是一个有限的数。 了解了级数的发散性和收敛性，对我们生活、工作和科研会有很多帮助，可以帮我们看清很多类似的迷局。下面我们就来看两个例子： 例一，社交网络上的信息传播问题。 在社交网络上，有时一篇文章会被不断地转发，然后大家就看到相关的事件被发酵了。这很好理解，我们常说，一传十，十传百，其实就是说当r=10的时候，一个人发出信息后，经过几何级数的增长，数量剧增的情况。 但事实上，一条信息总是传着传着就死了。大部分公众号文章的阅读量都不过万。那么问题出在哪里呢？我们就用等比级数分析一下。 我们假定订阅公众号的人中阅读了某篇文章的第一批读者数量是A0。大家读了之后觉得有价值，然后转发了的百分比为p，每一次转发，平均能有K个受众，而这些受众中打开阅读的比例为q，那么第二批读者就有A0pKq个，我们把pKq用r代替，这就是前面的等比级数了，第三批有A0r^2个读者，以此类推。如果r &gt; 1，那么这篇文章就霸屏了。 但是如果r&lt;1，无论怎么传播，无论一开始花多少钱让A0变得很大，读的人数都有限。比如，第一批读者是5000人（不算少了），接下来r=1/2，最终所有的读者加起来，不到1万。如果r=0.9，那么读者数量就可以达到5万。 我在2019年接受了大约50次采访，只有两篇报道不是标题党（甲子光年的一篇和澎湃新闻的一篇），这还是对媒体进行了严格筛选，并在我强烈要求不可以标题党的情况下发生的。 从这里可以看出，标题党的问题只会比我遇到的更严重。但是从结果来看，标题党并没有帮助提升阅读量，因为真实的阅读量摆在那里。这里面根本的原因就是，一旦读者发现一篇文章是标题党，他就有上当的感觉，都未必会读完，更不要说转发了，这个时候转发传播的因子r就可能远远小于1，第二批读者要比第一批少很多，第三批更少，然后就渐渐趋于零了。 不仅媒体如此，任何一个产品，要想成为爆款，都需要提高转发率p这个比例，也就是大家使用后满意，然后愿意主动宣传的比例。 第二个例子是关于核裂变的链式反应的。 我们知道，核裂变就是一个快速运动的中子撞击原子之上后，又会裂变为一些原子和中子，随即释放很多能量。如果每一个中子又撞上一个铀原子，那么就会释放更多的能量。这样一级级撞下去就形成了所谓的链式反应，所有的铀原子都被撞开，并释放出大量的能量，这就是原子弹的原理。 但是，运动的中子随机撞上铀原子的原子核概率是很低的，大约是百万分之一，这就是天然铀矿不会变成原子弹的原因。我们假定第一批参加核裂变的原子数量是A0，那么第二批只有A0*r个。我们知道只有r&gt;1，链式反应才能继续，而且越来越剧烈。 那么怎样才能提高r这个值呢？很简单，首先铀纯度要高，这样中子就有更多的机会撞到铀原子上。其次，铀块的体积要足够大，这样当中子错过了第一个铀原子时，它还有机会撞到其它铀原子上。 能够让链式反应维持的最小铀块体积被称为临界体积，它其实就是保证r&gt;1的体积。原子弹的临界体积是多少起初大家并不清楚，而这又显然无法通过试验测量出来，因为搞不好就会产生核爆炸。所幸的是，奥本海默通过数学计算准确算出了这个临界体积，这才让曼哈顿计划得以成功。从这里我们又可以看到数学的预见性。 要点总结： 首先，我们讨论了级数什么时候会是无穷大，什么时候是有限的。这里面扮演关键角色的是相邻两个元素的比例r，如果r&gt;=1，即后一个比前一个大，级数就是无穷大，就是发散的。反之，如果r&lt;1，它就是收敛的，多少项加到一起，它也是一个有限的数字。 其次，我们在生活中，有些时候希望r&gt;1，比如我们要传播消息，但是有些时候我们希望r&lt;1，比如我们不希望谣言扩散，时间会让r逐步下降，这时要做的事情是千万不要挑起新的事端，火上浇油。 通过介绍级数，我希望大家能够对趋势有量化的体会。下一讲我们介绍一个和大家投资、贷款相关的金融问题，有关利息的问题。我们下一讲再见。 10 ｜ 数列和级数（三）：藏在利息和月供里的秘密# 今天我们讲述两方面的内容，一来是应用前两讲讲的有关几何级数的知识，分析贷款利率方面的一些注意事项，特别是要防止陷入某些坑中。有些人不知不觉多付了几倍的利息却毫无知觉。二来讲讲利率和债券投资方面的关系。 不过我要先做一个提示，这讲提到的数字和计算稍微有些多，不过都是些加减乘除，不会很难，而且我也会帮大家算好。希望你坚持听完，这样能帮你省下不少冤枉钱。 我们先来说说贷款的问题。 假定你买房要向银行贷款120万，年化利率是6%，那么月利率是0.486%，接近0.5%，为了方便起见，我们就算是0.5%。假如你一年还清，每个月还一次，一共十二次还款，也就是12期。在12期的贷款中，每个月所还的钱该是多少呢？ 有人可能会想，利率6%，一年还清，利息就是120万x6% = 7.2万。每个月既要还本金，也要还利息，本息平摊到12个月，每个月10万本金，6千利息，一共10.6万。 这个算法对不对呢？今天很多P2P贷款公司，就是这么和大家算账的，一些不良中介，也是这么算钱的。但是，这其实多交了很多的利息。那么我们每个月应该付多少钱呢？这取决于两种常见的还款方式我们采用哪一种。 第一种被称为等额本金偿付，这种方法顾名思义，就是每个月还的本金数相同。在这个例子中，总贷款120万，12个月还清，每个月要还10万本金。当然，你每个月还要还利息，但其实，利息是随着本金归还后，不断减少的。 我们先看看第一个月，你要还全部贷款的0.5%作为利息，也就是120万x0.5%=6000元的利息。因此第一个月你需要还10.6万元，这和P2P公司对你的要求一样。 但是到了第二个月，由于你所欠的本金只有110万了，这110万的利息是5500元，比第一个月120万时的利息少了500元，因此这个月你只需要还10.55万。以此类推，第3个月你只需要付100万本金的利息，最后到第12个月，这样你所需还的利息就逐渐减少了。 这是一个等差级数，十二个月加起来是123.9万。其中利息3.9万，而在前面P2P贷款错误的计算方法中，你支付了7.2万的利息，多付出了3万多的利息。 刚才说了第一种等额本金偿付，我们再说第二种支付方式：等额本息偿付，就是说把贷款的本金和利息都加起来，除以还款期数，这样每个月还的本金和利息都是相同的。在这种情况下，每个月还款中一部分被用于还了利息，剩下的才用于减少所欠的本金。那么每个月要付多少钱呢？ 等额本息偿付的本金和利息计算相对复杂。具体到这个例子每月要偿付本息103,279.72元，利息共支付39,356.59元。 相比第一种支付方式，这种方法多支付了300多元的利息，但是它的好处是前几个月的月供较低，这对需要钱的年轻人来讲更有吸引力。今天大部分银行向客户提供的是这种支付方案。 但是，通常没有人只贷款1年，一般期限都在15年以上。如果是15年，那就是180期贷款，贷款的年利率还是6%，那么每月的月供是10,126.28元，15年下来，要支付约622,730.75元，大约是本金120万的一半。 如果利率降到4%，那么15年算下来，大约能省23万元的利息（只要支付397,725.92元），这不是一笔小钱。由于支付的利息降低，同样收入的人可以买更贵的房子。在这个例子中，支付同样的月供大约可以买136万的房子。也就是说，利息降一点，10多年下来能省很多钱。 相反，如果利息涨到8%，维持月供不变，只能买大约105万的房子（120万的贷款就要支付864,208.50元的利息）。很多人在买房子时，会为省一万块钱来回来去讨价还价，但是他们在接受贷款利率时，常常在不知不觉中多付出0.5%甚至更高的利率，这其实是捡了芝麻丢了西瓜。 今天绝大多数正规的银行，在给顾客贷款时，都是采用上述方法计算和收取利息的，可以讲是明码收费，是公平的。但是，很多民间的P2P公司提供贷款时，都有很多的坑，我们不妨来看一看。 首先，它们贷款的利息就高，比如同样是贷款120万，12期还清。他们说每个月收1%的利息，很多人算不过账来，觉得年化利息就是12%，比银行6%的利息只多出一倍，还可以接受。其实（1+1%）^12 -1 = 12.68%，比银行的利息多出1.1倍。当然这还不是最大的坑。 其次，它们采用我们一开始说的算法计算利息，你的借期是一年，它们会让你支付120万x12.68%=15.2万的利息。而银行等额本金偿付的方式才3.9万元。 这还没完，很多P2P贷款公司要求你先支付利息，你借了120万，它只给你120万-15.2万 = 104.8万元，然后每个月它还按照你借了120万要求你归还本金，即每月10万元。当然，如果你想要拿到120万，就得向它更多地借款，需要在合同上写137.4万，当然还的利息也就多了，共计17.4万。 这样算下来，你比向银行借款多付了将近3倍多的利息。也就是说，如果以等额本金偿付的方式正规地贷款，这相当于借了年息27%左右的高利贷。很多人问学数学有什么用，搞清楚这里面的猫腻，就是最现实的用途。 当然，很多人会说，我还是算不清这里面的账，没关系，只要记住下面两个原则即可： 借钱不要去所谓的P2P一类的机构。 永远记住“卖的人比买的人精”，不要试图贪便宜。 除了借款，我们很多时候还会把钱借给别人，还想拿到更高的利息收益。比如说你存银行或者买债券，当然银行通常把债券包装成理财产品，让你搞不清它的本质。实际上，这类固定收益的投资和买国库券是没有差别的，国库券风险很小，一般被认为是无风险利率，用来对比其他理财产品，我们就以它为例来说明。 今天中国二手债券市场并不发达，大家很少交易二手国库券。但是在美国等发达国家，人们通常会有大约20%～30%的资产放在类似于国库券的债券上，而且二手债券交易频繁，很多中间商利用大家对微小利息变化带来的债券价值变化不敏感的弱点挣了很多钱。 各国国债付利息的方式有两种，一种是到期后连本带息归还，还有一种是半年（或者一年）付一次利息。很多人觉得前者是利滚利，更合算，这其实是误解。因为当你在每半年拿到利息后，可以再买新的国库券，依然能实现利滚利。因此，这两种方式在投资上基本上是等价的，我们就以连本带息一次归还的债券来说明。 假如你购买10000元十年期的国库券，（复利的）年息5%，10年后到期，你可以拿到6290元左右的利息，也就是说10年下来，你的投资获利62.9%，还是不错的。 通常发行债券的机构会把它包装成年利率6.29%的单利金融产品，这样显得投资回报更高一些，也好计算一些。中国的国库券说的利息，都是折算后的单利利息，每年实际的回报要比标称的利息少一些。 接下来我们看两种情况。第一种情况，如果你刚买了国库券，央行就加息0.5%，新的10年期国库券的（复利）利息变成了5.5%，你手上的国库券就瞬间贬值了。这是怎么回事呢？我们不妨假设你的邻居小明在加息后买了10000元的新国库券，他10年后大约能获得17080元，比你手上面值10000元的国库券多出了大约800元的利息。因此，我们可以得到第一个结论，加息意味着同样面值的债券实际价值的贬值 。 另一种情况，你手上的国库券会升值，那就是降息。比如央行的利率降低了0.5%，相应10年期国库券的利率也下调到4.5%，这时你手上那10000元的国库券，就相当于10489元新发行的国库券，等于瞬间升值了5%左右。因此我们可以得到第二个结论，降息意味着同样面值债券的升值 。大家如果对里面的细节搞不太清楚，记住这两个结论就好。 未来在中国，随着金融市场的完善，债券交易也会像股票交易一样普遍，大家都需要了解这方面的知识。而这里面核心的知识，就是复利增长的数学原理。 要点总结： 我们通过对比正规银行收取利息的方式，和那些打擦边球钻空子的P2P收取利息方式的不同，说明在贷款这方面有非常多的坑，你一不小心就要多支付很多倍的利息。 我们通过利率和国库券等固定收益债券价值的关系，说明了利率的调整是如何影响到我们手头上投资产品的价格的。 这两个例子实际上是我们这几天所讲述的数学知识的应用。大家既可以看到数学在生活中非常现实的用途，更应该看到它能够帮助我们更好地看待“趋势”这个概念。比如央行通过调整看似不多的利率，就会影响很多年债券价格的趋势。 模块二 ｜ 数学的概念# 11 ｜ 鸡兔同笼：方程这个数学工具为什么很强大# 你好，欢迎来到我的《数学通识50讲》。从这讲开始，我们进入第二模块的学习，看看人类对数的认知，是如何从具体到抽象的。 上学时，数学想要考高分，老师和家长总是会说，要多做题，题做得多了自然就会了。大部分人也确实通过题海战术取得了还可以的成绩，但是往往题目稍微改变就又不会了，而有些人，做题不多，成绩却很好，这其中的差别在哪里呢？ 我们先从一个大家最熟悉的鸡兔同笼问题讲起，这是现在小学生都要学习解决的数学题，它讲起来并不复杂，但是对于智力还在发育中的小学生，多少有点费劲。今天很多老师把做法教给学生们，大家长大后基本上也忘了，所以这样学数学基本上等于白学。 鸡兔同笼这个问题是这样说的： 在一个笼子里，有鸡和兔子，从上面数，数出来35个头，从下面数，数出来94只脚，请问鸡和兔子各有几只？ 这个问题最初出现在中国南北朝时期的《孙子算经》。《孙子算经》给了一个不算太好理解的解法，它是这么说的： 将所有动物的脚数除以2，也就是94/2 = 47。每只鸡有一对脚，兔子有两对脚。 假设所有的动物都是鸡的话，就应该有35对脚，但事实上有47对脚。 如果将一只鸡换成一只兔子的话，用47减去35，得到12，说明需要有12只鸡被换成兔子，这就是兔子的数目。 知道了兔子的数目，鸡的数目也就知道了。 不知道你听了这个解法是否明白了，我估计第一次听的人，听了之后至少要想几分钟，或者在纸上画一画，才能明白。上述方法是《孙子算经》里给的算法，它不缺乏巧妙性，但是太不直观。不直观的结果，就是无法让人举一反三，因为这个方法只针对这个特定的问题有效。比如我把问题改一下： 假如有若干辆三轮车和汽车（四轮），一共有20辆，有65个轮子，请问有多少辆汽车，多少辆三轮车？ 这个问题就无法用上面的方法解决。因为无论先把车辆的轮子数除以3，或者除以4，都不可以，因为65既不能被3整除，也不能被4整除。 这道题在古代就没法解了，中国古代有不少数学著作流传下来，里面解了不少问题，但是中国的这些数学论著相比欧洲的和阿拉伯的有一个大的缺陷，就是它们给出的都是一个个具体问题的解法，而不是一套系统的方法，因此再多解法也难穷尽所有的问题。 今天小学里教的方法在通用性方面要比古代的方法好了不少。通常学校里会这么教： 我们假定笼子里全是鸡，那么应该有35 x 2 =70条腿。 但是现在有了94条腿，多出24条，就应该是由四条腿的兔子造成的。 如果我们用一只兔子替换一只鸡，就会多出两条腿，那么替换24条腿需要多少只兔子呢？ 24 / 2 = 12，于是就有12只兔子，剩下的就是鸡。 这个方法可以直接解决上面的汽车和三轮车的问题，具体做法你可以想想，自己算一下： 我们假定都是三轮车，那么应该有20 x 3 = 60个轮子。 现在有了65个轮子，多出了5个，它们应该是汽车造成的。 如果用一辆汽车换一辆三轮车，就会多出1个轮子。 现在多出了5个轮子，因此应该有5辆汽车。 今天在学校里，如果遇上一个好老师能把鸡兔同笼问题讲透，孩子是能做出汽车和三轮车问题的。当然依然会有一些同学不会做，因为他们只是记住了鸡兔同笼算法，不会应用到其他问题上。 这些学生要考满分，只好多做题，把三轮车的题目做一遍，再把其他相似的题目也做了，于是就很辛苦。但是即使能够灵活运用鸡兔同笼的解法，大部分人也还是不能解决所有这类问题，比如我再出一个题还是做不出来： 红皮鸡蛋5元3个，白皮鸡蛋3元2个，小明花了19元，买了12个鸡蛋，问红皮的和白皮的各几个？ 这个问题其实是鸡兔同笼问题的变种，但是用上面改进的鸡兔同笼的解法也不管用。对于这个问题，有兴趣的同学可以在留言区讲讲你的解法，前提是不要用方程。 那么能不能针对所有这些问题，提供一个寻找答案的思路呢？美国人的教法很有趣，下面我就和你分享一下。 首先，在小学他们不教学生那些需要技巧的解法。对于鸡兔同笼问题，就是列表的笨办法。比如，在第一个例子中，他们先让学生们明白，兔子的数量不能超过94/4 = 24只，然后就列一张表，从24只开始往下试验，看看脚的数量有多少： 我当时看了他们的教科书，就想美国人真笨，果然数学学不好。 但是发现他们再做其它相似的问题时，就可以从上述过程中受到启发，比如前面的鸡蛋问题，美国人也是列表： 事实上，只要是有整数解的各种二元一次方程的问题，都可以用列表这种笨办法解决。也就是说，美国小学的做法实际上是教给了大家一个很笨的，但是很通用的工具。这样，能解决一个就能解决很多，虽然办法很笨，很花时间，但总不至于让孩子们无从下手。 至于那些解题技巧，他们很少在小学教，省得大家学不会，有挫败感。那些聪明的孩子，可以去上课外班。上述笨办法的另一个好处是，学生们在列表的过程中，更感受到数字变化的趋势，慢慢地就会知道大约从多少开始试验，而不是永远从零开始。 相比之下，中国学校里教的那些聪明办法，常常和具体问题有关，除非是悟性很好的学生，普通孩子并不容易举一反三，因此家长总是责怪孩子笨。 当然，在这一类问题中如果数字很大，列表就不太现实了。这时，老师会告诉大家，别着急，到了中学（或者小学高年级），学了解方程自然就会了。 很多人在离开学校之后，除非辅导孩子，可能一辈子不会再解方程了，以至于会质疑为什么要在中学学习它。因为他们并不知道，方程就是用来解你之前不会的难题的，它是一个非常强大的解题工具，它可以让我们脑子想不清的很多数学问题变得非常直观、简单。 还是以上面的鸡兔同笼问题为例。我们只要假设鸡有X只，兔子有Y只，然后列这样两个方程即可： X+Y=35 2X+4Y=94 对于汽车和三轮车的问题，相应的方程是： X+Y=20 3X+4Y=65 对于鸡蛋的问题，我们可以把问题稍微变一下，也是一样的解法，解法我放进文稿了，你可以先自己试着做一下，再看答案。 解：红皮鸡蛋3个一盒5元，白皮鸡蛋2个一盒3元，一共花了19元买了12个鸡蛋，问红皮和白皮的各几盒？我们假设它们为X和Y，就有下面的两个方程： 3X+2Y=12 5X+3Y=19 X和Y分别是2和3，于是我们就知道两盒红皮鸡蛋有6个，白皮三盒也是6个。 上述三组方程，对于高年级的学生来讲，做出来是分分钟的事情。如果你不教会他们方程这个工具，让他们苦思冥想，这几个问题还真有点绕脑筋。从这三个例子中，我们体会一下方程是什么，它是一种工具，这种工具有一整套合乎逻辑的解法，只要通过一个问题掌握这个解法，就能把成千上万的问题解决掉。这才是学习数学的正道，而不是做更多的题。 那么如何把形形色色的题目抽象成同一类题目呢？这就涉及做数学应用题的核心关键了，就是要把用自然语言描述的现实世界的问题变成用数学语言描述的问题，比如列出方程。人的作用其实相当于一种翻译器，做练习题就是练习翻译，只要现实世界的问题变成了数学的问题，就能用现成的工具解决它们。 学习数学也好，物理也好，其实关键不在于刷多少道题，而是在于理解它们中工具的作用，然后学会把生活中的问题用数学或者物理学的语言来表达，剩下的就交给工具了。 多年前我问张首晟教授，为什么老一辈（当时50岁以上）的理论物理学家很少能再发表具有轰动性效应的论文？他说他们的数学工具不够先进，因为他们读研究生的时候学的数学和新生代科学家相比多有不足。 对此我也深有体会。当我们掌握了中学的一些数学工具后，小学的各种数学难题就变得非常容易。当我们掌握了微积分这个工具后，很多中学的数学难题就不值一提了。我们常说，工欲善其事，必先利其器，这就是说明了工具的力量。 中国古代在数学上有很多贡献，但大多集中在解决一个个具体的难题，而不是创造工具。相比之下，无论是古希腊还是后来的伊斯兰文明，在这方面贡献都要大得多。 我们今天说的解方程，无论是有很多未知数的一次方程（比如我们前面给的三个方程组，它们的未知数的次数都只有一次），还是一元二次方程，比如X^2 + 2X = 3，在阿拉伯伟大的数学家花拉子密的著作《代数学》中都有详细的论述，只要读了他的这本书，一大堆数学问题就都会做了。 相比之下，读那些只涉及到具体问题的书，就算读书破万卷，遇到新的问题还是没法解决，因此，学会把具体问题抽象成模型，才能解决更多更难的新问题。 要点总结： 我们用鸡兔同笼问题，说明了数学的本质是工具。美国人为了强调数学的工具性，在小学教学生们笨办法，但是从工具的角度讲却是一个好工具，到了中学，就有解方程这个工具。 相比之下，我们学了很多针对具体问题的解题技巧，其实用处远没有想象的大。在学习数学时，我们最需要做的，就是将生活中的某些问题，由自然语言翻译成数学语言，然后用相应的工具来解决。 最后介绍一下下一讲的内容，数学发展到花拉子密的时候，已经有了解决一元二次方程的公式了。但是在接下来的几百年里，没有人能够找到诸如X^3 + X + 1 = 0这样的一元三次方程的解法。当然最终它的解法还是被发现了，至于是谁发现的，则是数学史上一桩著名的公案，而这个方法的发现，你还可以看到数字的概念是如何从实数扩展到虚数的。 欢迎你把这篇文章分享到自己的家长群，帮助家长朋友们和自己的孩子一起重新理解数学。我们下一讲再见。 12 ｜ 三次方程：数学史上的发明权之争# 我们上一讲说了方程是一个能办具体问题，等量转化成类型问题的好工具，我们在中学也学了一元二次方程的解法，但是当学到一元三次方程时通常就被卡住了，因为没有通用解法，只有那些特殊方程用巧妙的办法才能把解凑出来。 现在回想起来，大家可能有疑问，那一元三次方程的解法是否有现成的公式可以套用呢？确实有！但是为什么世界各国的中学都不讲呢？因为这个公式太复杂，而且大家今天有了计算机，只要理解这一类方程的意义，让计算机帮助解决就好了。 但是在过去没有计算机，大家对这一类问题束手无策，因此只能靠技巧来解个别具体的方程。直到15世纪，人类还不知道它的通解，当时在欧洲，谁能解几个三次方程，就算得上是数学家了。 欧洲早期最著名的大学是意大利的博洛尼亚大学，它也是全世界最早的大学。该大学里面有一个叫费罗的数学家，他有一个学生叫菲奥尔，这个学生既不聪颖，也不好学，看样子将来是找不到工作了。 费罗临死前就对他说，你将来怎么办啊，要不为师传给你一些秘诀，你将来就拿它去找最有名的数学家挑战，如果赢了他，也便能在数学界扬名立万站住脚了。不久费罗老师就去世了。 菲奥尔在老师死后，果然混得不太好，于是就拿出了老师的秘籍，去找一个叫做塔尔塔利亚的数学家挑战，“塔尔塔利亚”是意大利语“口吃”的意思，这个数学家的真名叫做尼科洛·丰塔纳，但是今天大家都很少提及他的真名，而用他的绰号。 当时欧洲数学家之间盛行挑战，就是各自给对方出一些自己会做的难题，如果自己做出了对方的题，同时把对方难倒了，就算赢了。1535年，菲奥尔听说塔尔塔利亚会解一些三次方程，当时大家还不知道三次方程的通解，解具体的三次方程都靠玩技巧，就给他出了一堆难题，像这样的一些： $ x^3+8x+2=0 $ $ 2x^3+7x+5=0 $ 看了这些题目你会发现，它们都大同小异，都是解三次方程，而这些方程中都没有二次项。我们不妨将这些三次方程称为第一类的三次方程。费罗老师给菲奥尔留下的“九阴真经”，其实就是这一类方程的解法，费罗在发现了这样方程的通解后，除了悄悄告诉了自己的女婿，以及这位不上进的学生，没让旁人知道。 在拿到菲奥尔给的这些难题后，塔尔塔利亚也毫不客气地给对方出了一堆难题，也是求解三次方程，但形式上略有不同，诸如下面这样： $ x^3+x^2-18=0 $ 它没有一次项，但是有二次平方项，我们不妨将它们称为第二类的三次方程。这一类三次方程的解法，塔尔塔利亚已经想出来了。双方约定30天为期，并且压上了一笔钱做赌注，于是比赛算是正式开始。 菲奥尔看了一眼对方的题，知道自己做不出来，也就根本没打算做。然后他每天晚上跑到塔尔塔利亚的窗外去侦察，看看对方进展怎么样。菲奥尔的如意算盘是，对方也做不出来自己的题，于是双方打平，这样菲奥尔就一战成名，比肩塔尔塔利亚了。 塔尔塔利亚并不知道这些，他就每天从早到晚在书房里做数学题。眼看30天的期限快到了，塔尔塔利亚还没有解出来，菲奥尔暗自高兴，这场比赛看似能打平。然而，皇天不负有心人，塔尔塔利亚最后经过努力解出了对方的难题，赢得了比赛，菲奥尔自然就退出了历史舞台。在这之后，塔尔塔利亚又花了6年时间，完全解决了一元三次方程的问题，这是后话了。 从1535年开始，就有很多人想从塔尔塔利亚那里学习三次方程的解法，但是塔尔塔利亚就是不说。后来有一位叫做卡尔达诺的数学家，不断恳求塔尔塔利亚，想知道第一类和第二类一元三次方程的解法，后者受求不过，让卡尔达诺发下毒誓保守秘密后，将第一类三次方程的解法告诉了他。 卡尔达诺有一个学生叫费拉里，这个人很厉害。这师徒俩在塔尔塔利亚工作的基础上，很快发现了所有一元三次方程的解法，我们可以把它称为是通解。他们俩自然兴奋不已。但是由于之前发了誓要保守秘密，因此他们不能向外宣布自己的发现，这让他们非常郁闷。 几年后，也就是1541年，塔尔塔利亚也发现了所有的一元三次方程的解法，但是他依然保守秘密，不和别人说。 1543年，也就是塔尔塔利亚和菲奥尔的挑战赛过去八年之后，卡尔达诺和费拉里访问了博洛尼亚，在那里他们见到了费罗的女婿，得知费罗早就发现了第一类和第二类一元三次方程的解法，这下让这师徒二人兴奋不已，因为觉得憋在心里的话终于可以说出来了。 于是卡尔达诺决定不需要再恪守对塔尔塔利亚的承诺了，便于1545年将所有一元三次方程的解法发表了，这本书的中译名叫做《大术》（Arts Magn，就是《数学大典》的意思），这是过去关于代数学一本非常重要的书。 在书中，卡尔达诺讲，费罗是第一个发现了一元三次方程的解法的人，他所给出的解法其实就是费罗的思想。同时在三次方程解法的基础上，费拉里还给出了一元四次方程的一般性解法。 塔尔塔利亚知道了这件事，当然对卡尔达诺极为愤怒，认为他失信。失信在当时学术圈是一件了不得的事情。不过卡尔达诺解释道，他没有发表对方的工作，而发表的是费罗很多年前的工作，因此没有失信。 这件事在当时就成为了一件很轰动的事情，而双方各执一词，旁人也分不出是非，于是只好采用“决斗”的方式来解决，当然，这种决斗是数学家们比拼智力，而非武力相向。 卡尔达诺这一边决定由学生费拉里出战，他和塔尔塔利亚各给对方出了些难题，结果费拉里大获全胜。从此塔尔塔利亚就退出了学术圈。不过今天三次方程的标准解法公式依然被称为费拉里-塔尔塔利亚公式，大家并没有完全否认他的功绩。 说到这里有人可能会问，既然一元三次方程有标准的解法公式，为什么我们中学的时候，老师不讲，而让我们费劲巴拉地用各种技巧来算呢？更糟糕的是，解每一道题的技巧都不一样，以至于我们学习得特别辛苦。 要回答这个问题，我先把标准解法的公式，即费拉里-塔尔塔利亚公式给大家看一眼： 要算出它的第一个解，需要先算下面三个中间变量。 然后再根据这三个中间变量，按照下面的公式算出第一个解。 有了一个解，三次方程就可以简化为二次的，接下来就好解决了。 我估计你看了上面这一堆密密麻麻的公式，头已经开始大了。因此，中学不教这个公式是对的，否则会把学生们都吓回去。但是，老师又不能完全不讲怎样解一元三次方程，于是学校就教了一大堆解特殊方程的方法，聪颖用功一点的学生学得多一些，成绩就好一些，条件差的学生学会的技巧就少一些。但是那些技巧你无论学多少，都很难举一反三。 相比之下，我倒觉得美国中学的教法更好一些，它除了教学生们最简单的，谁都能学会的技巧，还有就是让学生们使用一种叫做Mathematica的软件工具来自动解决。 根据我个人的体会，今天学习数学，重要的是把实际问题变成数学问题，然后知道如何利用各种软件工具来解决，而不是花很多时间学一大堆无法举一反三的技巧。讲到Mathematica，我还要说一句题外话，这款软件可以推导你能遇到的几乎所有数学公式，他的编写者沃夫兰姆是一位真正的天才。20岁便博士毕业了。 因此我想对很多家长说，不要高估自己孩子的智商，当然，也不要埋没他们在某些方面的天赋。大部分人老老实实学好数学的基本方法，理解其中的思维方式最重要，不要苦练解题技巧。需要技巧的时候，我们应该善于利用沃夫兰姆的大脑，不要自己傻推公式。 现在，我想让你再看一眼上面这一大堆密密麻麻的公式，把注意力集中在那个根号上。我们知道，如果根号里的数字是负数，那么它在过去是没有意义的。在解二次方程时，我们可对这个问题视而不见，直接宣布它没有实数解即可。 但是三次方程是一定有实数解的（原因以后再讲），因此这个根号里面负数的问题就回避不掉，为此，数学家们就不得不正视这个问题，并且引入了虚数的概念。关于虚数我们明天会详细讲，今天只是通过这段历史，介绍它的来源和存在的必要性。 要点总结： 首先，通过数学史上这段著名的公案，说明了数学定理发明的过程。通常先有引理，你可以把引理看成是一个简单、辅助性的定理，它们存在的目的是为了后面证明定理。在一元三次方程的解法里，无论是费罗对第一类三次方程，还是塔尔塔利亚对第二类三次方程的解法，只能算是引理，它们能解决部分问题，但不具有普遍意义，不能算定理。 后来卡尔达诺、费拉里和塔尔塔利亚发现的对于任意三次方程的解法，则可以看成是定理，它是建立在引理之上的。定理具有里程碑的意义，但它不是凭空产生的。数学的发展是层层叠加的，学习数学也应该如此，理解这一点是学习好理科课程的关键。 其次，我们要特别强调数学是个工具，学习数学是练习自己使用工具的能力，花很多时间在学习小的解题技巧上不值得。因此不要因为掌握不了一个小技巧而沮丧。最要注重学习的是概念，以及概念之间的联系，然后能够把现实的问题转化为数学问题。接下来怎么解决，工具是很多的。 那么三次方程的解到底是怎么得出来的？这就需要人类再次抽象对数的认识，虚构出一个认知工具来，我们下一讲再见。 13 ｜ 虚数：虚构这个工具有什么用# 我们上一讲讲了一元三次方程的解法，说里面可能涉及到一种并不存在的虚数。也就是说它们自身的平方是负数。 虚数在现实中显然不存在，我这讲会通过这个例子告诉你，数学家是如何虚构一个现实中不存在的概念，解决现实问题的。 我们在初中学到平方根这个概念时，老师会说，只有正数和零才有平方根，没有哪个数字自己乘以自己会等于负数。在解二次方程时，我们可能会遇到根号里面有一个负数的情况，但是老师说，不用管它，我们就认定它无实数解即可。 但是当学到了三次方程时，这个问题就回避不了了，因为根据上一讲介绍的公式，即使一个有实数解的三次方程，在求解的过程中，也会遇到要对负数开根号的情况。比如下面这个方程： X^3-15X-4=0 显然X=4是一个解。 但是，如果我们利用昨天说的费拉里-塔尔塔利亚公式算，得到的是这样一个解，听音频的朋友可以看一眼，你不用关注细节，只要留心里面有√-121就好。 于是给负数开根号这件事就绕不过去了。数学家们只好虚构出一个数，让它的平方等于-1，这个数我们常常把它写成字母i，就是拉丁语中imagini（相当于英语中的image）“影像”一词的首字母，它代表非真实、幻影的意思。 有了这个人造的、虚幻的数，上面那个复杂的一堆根号的式子就能计算下去了，而且算出来就是4。你可能会问其中的虚数去哪里了，很有意思的是，它们正负抵消了，数学基础比较好的同学可以自己推导一下，算是留给你的思考题。 这件事你如果细想是很有意思的。如果我们真实的世界里有一个三次方程，比如给一些限制条件后计算一个长方体的尺寸，也就是解三次方程的问题，卡尔达诺等人找到了一个公式，可以计算出问题的答案，但是算到一半你就遇到一堵墙越不过去了，于是你引入一个不存在的工具，用了一下就翻过墙了。 这在哲学上其实很有意思，明明是现实世界的问题，而且在现实世界里也有答案，但是却无法直接得到，非要发明一个不存在的东西作为桥梁。 怎么能够形象地理解虚数这种抽象概念的作用呢？我们的数学课基本上不讲，老师只是说，记住它的定义就好，回头学生们就一头雾水了。我通常用三个例子来形容它的作用。 一个是化学中的催化剂。我们知道，催化剂在化学反应完成前后是不改变的，它只是起到一个媒介的作用，但是没有它，化学反应要么特别慢，要么干脆进行不下去。 另一个例子不算太确切，但是好理解，就是传话筒。我们经常看到这样的现象，夫妻俩吵架后，谁也不愿意和对方说话，但是都清楚这个交流不能中断，要继续下去，于是就找孩子带话，比如教孩子说：“去，和你妈说明天的家长会我去，她就不用去了。”孩子把这个意思传递后，又带回一句话：“妈妈说，你要是去开家长会，她就先回家做饭了。” 这样传几次话，可能夫妻间的问题就解决了。在这个过程中，夫妻间的问题不涉及到孩子，孩子在传话时甚至不明白其中的含义，但是没有这个局外的传话筒，夫妻之间的问题可能就解决不了了。 最后一个例子是虫洞。我们接下来就开一下脑洞。假如你和一个相爱的人在同一个宇宙中，但相隔几十光年，你想对她说一句我爱你，但哪怕你搭载光速飞船去找她，她听到的时候都已经老了。 现在有一个虫洞，你可以从中穿过去，在瞬间到达另一个平行宇宙中，然后再从另一个虫洞穿回现在的宇宙，这也是瞬间的事情，这样你就能很快到她身边了。你们二人本来是在同一个宇宙中，但是却要依赖另一个和你们无关的宇宙来回穿越。 虚数也是如此，在上面的式子中，我们把它创造出来，又把它正负相抵消，该得到实数的答案依然是实数的。从更广义的角度讲，很多数学工具都是如此，它们并非我们这个世界存在的东西，而是完全由逻辑虚构出来的。但是我们现实世界的事情，却要用这些虚构的工具来解决。 那么虚数除了解三次方程还有什么用？它的用途可以归结为三个层面。 **第一个层面是对于数学本身的影响。**引入虚数的概念后，数学的一些逻辑上可能的漏洞就被补上了。 比如说，在实数的范围内，X^2+1=0是无解的，这样一来，有的多项式方程有解，有的无解，数学就不完美了。引入一个虚拟的概念，虚数i，就让所有的方程都变得有解了。更漂亮的是，引入虚数的概念后，所有的一元N次方程都会有N个解，没有例外。 **第二个层面是作为工具的作用。**有了虚数之后，很多复杂的数学问题，可以用简单的方法解决，这就如同前面介绍的三次方程的解法问题。这个问题虽然引出了虚数的概念，但是并不是它最大的用途。虚数作为数学工具最大的用途，可能是便于将直角坐标变成极坐标。 关于这两种坐标我们后面还会讲，简单地讲，在飞行、航海等场景里，极坐标更方便使用，比如我们说往两点钟的方向飞行20公里，这就是极坐标的描述方式。在极坐标的计算中，如果只用实数，非常复杂，如果引入虚数，就极为简单。 **第三个层面是应用层面。**量子力学、相对论、信号处理、流体力学和控制系统的发展都离不开虚数。 通过虚数这个例子，我首先想说的是，人类可能是唯一一个能够构想出不存在的事物的物种，这个能力对我们来讲非常重要。在我们生活的世界里，存在着大量的构想出来的东西。比如早期的人类要靠宗教崇拜团结起来，虽然最后一起去打仗，去探险的都是人，但是要没有宗教，人和人直接沟通，达不到团结的目的。 今天虽然大家不太需要宗教了，但是很多虚拟的概念已经深入我们人心，比如法律、有限公司、法人团体等概念便是如此，它们在自然界中并不存在，只是人们脑子里构建出的概念，但是如果没有它们，这个社会就运行不下去。当我们习惯于使用这些虚构的概念后，就会把它们真实化，感觉和真的一样。 为了让大家更好地理解这一点，我们不妨看一个法律学的概念——法人。 在早期的罗马法中，提出了法律主体的概念，它最初只涉及到自由人，后来因为要处理经济纠纷，就把一些机构看成是法律的主体，当作人一样看待，这就是法人概念的来源。这些法人，其实就相当于数学中所说的虚数的概念。 我们今天和一个公司打官司，其实在打官司的过程中接触到的还是人，但是你不会去告里面某个具体的人，而是针对这个虚构出的组织。当你打赢这个官司后，是里面具体的人执行对你的赔偿，但是你拿到的赔偿却是法人这个机构给你的。这就如同解方程时，我们需要借助于虚数，得到实数的解一样。 今天，衡量一个人认知水平的一个方法，就是看他接受虚拟概念的能力有多强，如果他只停留在看得见摸得着的东西，这个人的水平就不是很高。我们经常说那些只知道买房置地，收藏奢侈品的人是土财主，其实也是这个道理。 其次，虚数的出现，标志着人类对数这个概念认识的进步，特别是从形象思维到抽象思维的进步。 人类早期认识的数字都是正整数，1，2，3，4……因为大家接触到的周围的世界就是这样实实在在一个又一个的东西。事实上除了古印度，其他文明在早期数字中都没有零这个数，因为零这个概念比较抽象，人类从有数字开始花了几千年才搞明白。 接下来有了数字就要做运算，两个自然数相加或者相乘，结果还是自然数。但是，到做减法和除法时就出现了问题，因为2-3=？，2/3=？在自然数中找不到。于是人们就发明了负数和分数（就是有理数）的概念。这两个概念就比自然数要抽象一些了。 很多人觉得数学越到后来越难学，就是没有能突破抽象思维的瓶颈。有了正负的概念，有了分数的概念，就形成了有理数的概念，加减乘除和乘方五种运算就都没有问题了。自从毕达哥拉斯定理被发现，人类就不得不面对开方这件事，就不得不定义出无理数。 再往后，又因为要对负数开方，便发明了虚数的概念。实数和虚数合在一起，就形成了复数。我把人类认识数的过程用一张图表示出来，它是从中心往四周扩散的： 那么复数有什么用呢？为什么要搞出这么一个在现实世界中完全不存在的概念呢？仅仅是为了让开方运算变得完备么？当然不是。复数是一个非常强大的数学工具，使用这个建立在现实生活中所不具备的事实的基础之上的数学工具，可以解决很多现实世界里的问题。 这句话可能听起来有点绕口，换一种方式讲是这样的，复数的基础在现实世界里并不存在，但是建立在不存在基础上的工具，却能解决实际问题。 比如我们使用的三相交流电是实实在在地存在的，它里面的很多问题，用复数这个工具解决，要比用实数加上三角函数解决起来容易得多。实际上，涉及到电磁波的几乎所有问题，都需要使用复数这个工具来解决。 对于今天的内容，你如果体会到像虚数这样媒介工具的作用，以及通过数字的扩展历史，体会到人类认知升级的过程，就算是掌握精髓了。 下一讲，我们再继续突破认知，去理解无限的世界。欢迎你把文章分享到自己的家长群，帮助家长朋友们重新理解数学，帮孩子把数学变得更容易。我们下一讲再见。 14 ｜ 无穷：我们为什么难以理解无限的世界？# 我们在前几讲的课程中讲了人在数学上认知进步的过程，从具体数字、具体问题到用方程解决类型问题，用抽象的虚数解决现实问题。今天我们看看人类怎样进一步突破对数的认知局限，动态认识数的。当然，讲突破之前，先要讲讲人是如何受困于认知局限性的。 庄子有句话：“夏虫不可以语于冰者，笃于时也。”意思是说，夏天的虫子无法理解冰雪，因为它受限于生命的时长，等不到能看见冰雪的冬天就死了。其实在庄子看来，人的生命也很短暂，认识也很有限。 他说，“吾生也有涯，而知也无涯”，就是说用短暂、有限的生命，无法理解无限世界的事情。不过，人具有想象力，虽然看不到无限的事物，却能想象出一些规律，并且通过逻辑保留合理的。有些人做到了这一点，他们的认知水平就比其他人高出好几个层次了。 我们今天就从无穷大说起，说说认知升级的事情。 说起无穷大，先要说大数字。小孩子们常常爱比谁说的数大，比如一个孩子说出一百，另外一个孩子说一万。别的孩子就问了，一万有多大？他说，一万就是一百个一百，别人只好不说话认输了，因为孩子们还是有基本逻辑的，知道一百个一百显然比一个一百多。 当然，过两天输了的孩子跑去问家长，从家长那里知道一亿这个数，他就又赢回来了。这时，如果输了的孩子脑瓜子灵，会说出两亿来翻盘，最后孩子们就不断地喊，一亿亿亿亿亿亿……，最后是肺活量最大、气最长的那个孩子赢。 接下来，可能又有孩子要回去问家长，家长告诉他无穷大，这回，他就可以回去秒杀那些一亿亿亿……不断喊下去的孩子们了。但是你要问他无穷大是多少，谁也说不出来，大家只是接受了这个虚构的概念，认为它是世界上最大的数。 下面我就问大家一个问题，无穷大是一个数吗？它可以被看成是数轴的终点吗？它在数学上和某个具体的大数一样大吗？ 这些很基本的问题很多人在大学里学完高等数学其实也没有一个明确的概念，在绝大多数人心目中，无穷大是一个数，只是它比你能想象的数更大而已，人们依然会用理解一些具体数字的方式去理解它。无穷大的世界和我们日常认知的世界完全不一样。 当然人类也是直到现代才开始正确认识无穷大。1924年，大数学家希尔伯特讲了一个旅馆悖论，让人们重新认识无穷大的哲学意义。他的悖论是这样讲的： 假如一个酒店有很多房间，每一个都住满了客人，这时你去酒店问，还能给我安排一间房子吗？老板一定说：“对不起，所有的房间都住上了客人，没有办法安排您了。” 但是，如果你去一家拥有无限多个房间的旅馆，情况可能就不同了。虽然所有的房间均已客满，但是老板还是能帮你“挤出”一间空房的。 他只要这样做就可以了。他对服务生讲，将原先在1号房间的客人安排到2号房间，将2号房间原有的客人安排到3号房间，以此类推，这样空出来的1号房间就可以给你了。类似的，如果来了十个、八个人，也可以用这种方式安排进“已经满客”的酒店。 接下来的问题来了，既然每个房间都被现有的客人占据了，怎么又能挤下新的客人？因此我们说这是悖论。但是“旅馆悖论”其实并不是真正意义上的数学悖论，它仅仅是与我们直觉相悖而已。 在我们的直觉中，每个房间都被占据，和无法再增加客人是等同的，但这只是在有限的世界里的等价性，在无穷大的世界里，数学中的很多逻辑都需要重新梳理一遍。我们在有限的世界里得到的很多结论，放到无穷大的世界里，需要重新检验，有些能够成立，有些不成立。 比如说在有限的世界里，一个数加上1就不等于这个数了，因为比它大1，但是在无穷大的世界里，这条结论就不成立，因为无穷大加1还是无穷大，就如酒店悖论中的那个酒店一样，再增加一个客人，酒店依然能够容纳得下。 事实上，在希尔伯特做完那个报告后，全世界数学家不得不回去把所有的数学结论在无穷大的世界里又推导了一遍，看看有没有什么漏洞。 在上面的问题中，客满的、无穷多房间的旅馆，不仅可以增加有限个客人，甚至能增加无限个新客人。那么当无限的客人来住店，怎么办呢？具体的做法是这样的，我们让原来住在第1间的客人搬到第2间，第2间的客人搬到第4间，第3间的搬到第6间。 总之，就是让第N间的客人搬到第2N间即可。这样就腾出无数间的客房安排新的客人了。我们知道一万乘以2是两万，不等于原来的一万，但是无穷大乘以2还是无穷大，并不是两个无穷大。 无限集合的性质与有限集合的性质并不相同。对于拥有有限个房间的旅馆，其偶数号房间的数量显然总是小于其房间总数的，比如1万个房间，偶数号的有5000间，不等于总数。然而，在无穷房间的旅馆中，偶数号房间的数量与总房间数量是相同的。 类似的，我们可以证明一条长5厘米的线段上的点，和一条长10厘米线段上的点是“一样多”的。这个证明也很简单： 在图中，下面的线段长度是10厘米，上面的是5厘米。我们将它们平行放置，于是将它们两端相连（虚线），就会交会到一个点S处。接下来，对于10厘米长线上的任意一个点X，我们将X和S相连，就和5厘米短线有一个交点，我们假设为Y，这就说明长线上的任意点，在短线上都可以找到对应点。 因此，短线上的点应该不少于长线上的点。这样，在无穷大的世界里，我们可以认为10厘米线段上点的数量和它的一个子集，即5厘米线段上的点是“相同的”。当然更准确的说法是基数相同。 接下来就有一个问题了，不同类型的无穷大，比如整数的个数，或者10厘米长线段上的点数，它们彼此能比较么？答案是可以，这里面的细节我们省略了，在这里我直接给大家答案，就是一根很短的线段上的点数，要比所有的有理数数量都多，前者的基数比后者大。我知道这可能有点颠覆你的直觉，但这个结论是正确无疑的。 讲到这里，我们一开始的问题，“无穷大是不是一个特别特别大的数？”现在有答案了。它不是一个具体的数，它和万亿、googol数（10的一百次方）等等都不同。它不是静态的，而是动态的，它反映一种趋势，一种无限增加的趋势。在增大的过程中，有的无穷大会比其它的更大，因为它变化的趋势比其他的无穷大更快，这一点我们后面会仔细讲。 对于无穷大的概念，关键要理解它是动态变化到了最终尽头的描述。事实上，无穷大（和以后要介绍的无穷小）代表着一种新的科学世界观，就是让我们关注动态变化的趋势，特别是发展变化延伸到远方之后的情况。 上面这些关于无穷大世界的特点可能有些颠覆你的认知，这并不是说你原先的认知有问题，而是说我们在有限世界里得到的认知太狭隘了，相比浩瀚的宇宙和人类的知识体系，我们的认知可能就如同夏天的虫子，受限于我们的生活环境。这也是我们比较接受通识教育的原因，因为这样可以让我们以最快速度走出我们认知的围墙。 当然，有些同学可能会问，了解无穷大世界这件事情有什么现实的意义？它的意义很多，这里我不妨说一个具体的例子。 我在《谷歌方法论》中讲到了关于计算机算法的衡量标准。假如有三个完全相同功能的算法，A、B和C。 算法A要进行100,000*N次运算； 算法B要进行N^2次运算； 算法C要进行N次运算。 请问哪种算法好？ 很多人会说，当然是算法C好，至于A和B，要看情况。如果N&lt;100,000，那么算法B更好，否则就是算法A好。比如，N是20万时，A方案就相当于10万20万，B方案相当于20万20万，可见B是很大的。 但是，在计算机科学中，衡量两个算法的复杂度时，只会考虑这两种算法在处理近乎无穷大的问题上的表现，也就是N趋近于无穷大的情况。因为它关心的是，当问题越来越复杂后，每一种算法所需要消耗的计算机资源（比如计算时间）的增长趋势。这样一来，算法B显然是计算量最大的。 至于两个算法在复杂度上只差出常数倍，在计算机科学上就认为它们是等价的。对计算机科学家们来讲，将一个算法从平方的复杂度降低到线性，这是捡西瓜的事情，将一个线性复杂度的算法的计算量再减小几倍，这是捡芝麻的事情。这些内容我们在后面会更仔细地分析。 要点总结： 首先，我们通过希尔伯特旅馆悖论，说明生活在有限世界的人，其实很难想象无穷大的世界，在那里，很多规律和有限世界是不同的。比如说，在无穷大的世界里，部分可以完全和整体等价。 因此，我们不能以有限的认知，去理解无限的事物，也不能把那些从很少的经验中得到的结论，放大后用于更大的场景。比如，有些人受过一两次骗，就得到一个结论，世界上没有一个是好人。这就陷入了以有限的经验理解无限事物的误区。 接下来我们强调了，无穷大并非是一个静态的、具体的大数字，而是一个动态的、不断扩大的变化趋势，希望通过这个概念，提示大家能够以动态的眼光看待世界。 至于无穷大这个概念的现实意义，我们举了计算机科学中算法复杂度的例子，量级的差异，要比同量级之间几倍的差异重要得多。我们在工作中，要优先考虑量级的提高，而不是捡芝麻的事情。 接下来三讲，我会拿无穷小为例，详细解释什么是动态地看世界。我们下一讲再见。 15 ｜ 无穷小（一）：如何说服杠精“芝诺”？# 上一讲我们讲了无穷大，主要是从突破认知局限的角度来讲的。在接下来的三讲里，我们来讲讲无穷小。 你可能会奇怪，为什么无穷小要花三讲来介绍？它不就是零么？有什么好讲的。如果你把无穷小看成是一个数，确实没什么好讲的。但遗憾的是，无穷小并不是一个确定的数，更不是零，它和无穷大一样，是一种趋势，一种帮助我们把握“动态”和“变化”的工具，也是一种新的认知世界的方式。 一个人是小学数学水平，还是高等数学水平，不在于是否会做高等数学的练习题，而在于他在把握世界变化方面处在什么层次上，那么他是否掌握了无穷小这个概念，就是很好的检验标准。 因此，从概念的来龙去脉到数学家最后的应用，我有必要花3讲，来为你解释清楚。 世界上最初认认真真思考无穷小这个概念的，是公元前五世纪时古希腊的芝诺，后世虽然把芝诺说成是数学家，但其实他一生没有留下什么数学成果，因此对他的生平鲜有记载。 由于他是一个“杠精”，喜欢和人辩论，而且还提出了好几个自己搞不清楚，别人也解释不了的问题，因此被亚里士多德写进了书中，后人才知道有这个人存在。 我们不妨看看他的四个著名的悖论： 悖论一（二分法悖论）：从A点到B点是不可能的。 看了这个命题，你会马上说，这怎么不可能？别着急，我们先来看看芝诺的逻辑。 芝诺讲，要想从A到B，先要经过它们的中点，我假设是C点，而要想到达C点，则要经过A和C的中点，假设是D点……这样的中点有无穷多个，找不到最后一个。因此从A点出发的第一步其实都迈不出去。 悖论二（阿喀琉斯悖论）：阿喀琉斯追不上乌龟。 我们知道阿喀琉斯是古希腊神话中著名的飞毛腿，但是芝诺讲如果他和乌龟赛跑，只要乌龟跑出去一段路程，阿喀琉斯就永远追不上了。按照我们的常识，芝诺的讲法当然是错的。不过我们还是听听他的逻辑。 为了方便起见，我们简单地假设阿喀琉斯奔跑的速度是乌龟的10倍。如果乌龟先跑出10米。等阿喀琉斯追上了这10米，乌龟又跑出1米，等阿喀琉斯追上这1米，乌龟又跑出0.1米……总之阿喀琉斯和乌龟的距离在不断接近，却追不上。 这两个悖论其实本质上是一个。我们如果从常识出发，觉得芝诺的观点不值一驳。我们从天安门出发，一步就走过了芝诺所说的无数中点，阿喀琉斯一步迈得大一点，不就超越乌龟了吗？在这里我们的常识当然没有错。 但是，如果按照芝诺的逻辑来思考，他似乎也有道理，只是忽略了一些事实，因此要想驳倒他，让他心服口服，就不能绕过他的逻辑！在解释这个问题之前，我们再来看看他的另两个悖论。 悖论三（飞箭不动悖论）：射出去的箭是静止的。 在芝诺的年代，运动最快的是射出去的箭。但是芝诺却说它是不动的，因为在任何一个时刻，它有固定的位置，既然有固定的位置，就是静止的。而时间则是由每一刻组成，如果每一刻飞箭都是静止的，那么总的说来，飞箭就是不动的。 这个悖论，可能就比前两个难辩驳了。 悖论四（基本空间和相对运动悖论）：两匹马跑的总距离等于一匹马跑的距离。 如果有两匹马分别以相同的速度往两个方向远离我们而去，我们站在原地不动。在我们看来，单位时间里它们各自移动了一个单位Δ（Δ通常表示增量），显然一匹马跑出去的总距离就是很多Δ相加。但是如果两匹马上有人，那么在彼此看来，对方在单位时间却移动了两个Δ长度，彼此的距离应该是很多两倍的Δ相加。 那么，如果Δ非常非常小，小到无限接近于零，芝诺就干脆认为Δ=0，0乘以任何数还是0，那么1Δ＝2Δ。但是左右两匹马跑出去的总距离怎么可能等于一匹马跑的距离呢？其实芝诺的错误就是把无穷小直接当做了0。 听了这些问题不知道你有何感觉。我想，除了当年庄子和惠子也讨论过类似的问题之外，绝大部分时候中国人讲究的是要学以致用，因此，在古代，士大夫们是不屑于理会芝诺的这种没有用的傻问题。 直到今天这种情况其实也没有太多的改变，我在大学时，一些老师还觉得这一类的问题是唯心主义的。但是正是这些问题，让古希腊文明和其它文明有所不同，而这种严守逻辑的思维方式，才让数学和自然科学成体系地发展。 当逻辑和我们的经验有了矛盾时，有两个结果，一个结果是我们的经验错了。比如说，到底是地球围绕太阳转，还是太阳围绕地球转？在这件事上，我们的经验就错了。当然还有一个可能性就是，我们看似正确的逻辑，本身可能有问题，因为有概念的缺失，芝诺的这两个悖论就属于第二种。 在这种情况下，找到了所缺失的概念，或者分清了不该混淆的概念，数学或者科学就获得一次巨大的发展。我们前面讲的从毕达哥拉斯定理引出无理数的概念，也属于这一种。今天回答芝诺的问题其实很容易，因为有了无穷小的概念，以及微积分中关于导数的概念，这个缺失被补上了。 今天我们就用无穷小的概念回答芝诺的第1、2和第4个悖论，由于第一个和第二个悖论其实是一回事，我们只讨论第二个，也就是阿喀琉斯和乌龟赛跑的例子。至于第三个悖论，我们下一讲讲到导数的时候会回答。 话说在芝诺之后的上千年里，欧洲总有人不断地试图找出芝诺逻辑上的破绽，包括阿基米德和亚里士多德，但都没有给出好的回答。不过亚里士多德的思考还是道破了这几个悖论的本质，就是一方面距离是有限的，另一方面又可以把时间分成无穷多份，以至于有限和无限对应不上。 直到牛顿、莱布尼茨等人发明了微积分，发明了无穷小量和极限的概念，才作出了比较圆满的解释。 接下来，就让我们一层层抽丝剥茧，来解决这些悖论。 我们知道，在阿喀琉斯悖论中，芝诺其实把阿喀琉斯追赶的时间分成了无限份，每一份逐渐变小却又不等于零。比如我们假设阿喀琉斯一秒钟跑10米，那么芝诺所分的每一份时间就是1秒、0.1秒、0.01秒，等等。如果我们把它们加起来，就是之前讲的等比级数。 S=1+0.1+0.01+0.001+…… 接下来的问题是，这样无限份的时间加起来是多少？假如每一份时间都存在一个最小的、具体的长度，那么这样子的无限份加起来显然就是无限大，这是矛盾所在。但是，如果我们能够定义一个被称为“无穷小”的量，它满足这样两个条件，芝诺的悖论就能够解决了。 它不是零； 它的绝对值小于任何一个你能够给定的数。比如你说10-100（10的负100次方就是10的100次方分之一）非常小，那么我这个无穷小比你说的还小，如果你说再来一个更小的数10-10000，那么我这个无穷小依然比你的数字小。 具体到芝诺悖论的例子中，这两个条件如何理解呢？当我们把时间分为无穷多份之后，到后来，不仅每一份是一个无穷小量，而且无穷多个无穷小量加起来依然是无穷小。 那么怎么证明在上面的等比级数S中，无穷多个无穷小量加起来不会是无穷大呢？这在数学上有好几种方法可以证明，我们就不细讲了。在这里我们提示两个要点： 无穷多个无穷小量加在一起可以有三种情况，分别是一个有限的数，无穷大，或者是无穷小，我们在后面介绍无穷大和无穷小的比较时会详细讲。 在这个具体情况中，无限个无穷小量加起来是一个有限的数，这一点我们在后面讲到极限的概念时会说明，S这个级数的极限是10/9。 因此引入了无穷小的概念，就解决了阿喀琉斯悖论。可以讲，正是阿喀琉斯悖论帮助我们补上了数学上的一个缺失。 至于第四个相对运动悖论，其实说起来就更简单了。芝诺所说的Δ，其实就是无穷小，虽然它趋近于零，但是不等于零，因此Δ≠2Δ。 要点总结： 无穷小的本质是什么？它补上了关于数字在连续性方面的一个定义的缺失。我们随便画一个数轴，数轴上的每一个点都应该是连续的，当然数轴中间那个点是零。 如果我要问你，在数轴上紧挨着零的那个点等于多少呢？你就没法回答了，你如果说是10-100，遇到一个抬杠的，会说10-1000离0点更近，只要你能说一个，他都可以和你抬杠。 因此，我们定义一个新的概念，叫做无穷小，它无限接近零。从它的定义可以看出，无穷小不是一个具体的数，而是一个概念、一个趋势，就和无穷大一样。 当我们的头脑开始接受数的概念可以超出一个具体的数，而是一个趋势时，我们的思维就进步了，我们看待世界也不会一个点一个点地去看了，而是一个趋势一个趋势地去看。 举一个具体的例子，你可能听说过现代物理学上的弦论，它被认为是到目前为止最有可能统一相对论和量子力学的工具，相比今天建立在基本粒子上的物理学模型，弦论讲的就不是一个个具体的点，而是一个个趋势。 牛顿和莱布尼茨等人虽然通过无穷小和极限的概念，解决了芝诺悖论，但是他们当时对无穷小以及极限的定义还不准确，以至于受到了大哲学家贝克莱的挑战。这一点我们下一讲再讲。 欢迎你把课程分享到家长群，帮家长们重新理解数学背后的道理。 16 ｜ 无穷小（二）：牛顿和贝克莱在争什么？# 17 ｜ 无穷小（三）：用动态和极限的眼光看世界# 18 ｜# 19 ｜# 模块五 ｜ 微积分# 30 ｜ 微积分（上）：如何从宏观变化了解微观趋势# 我们在前面讲到，线性代数和微积分是高等数学中最重要的两门课，前者有很强的实用价值，后者能提高思维水平，虽然大家平时在工作中未必有机会直接使用它。就拿我来说，工作后用线性代数的机会可能是微积分的100倍。 ... 但是，学没学过微积分，思维方式会不同，眼中的世界也会有差别。因此，作为数学通识课，我们还是有必要解释微积分的思想，但是我们也就是停留在它的思想方法上，而非细节上。 微积分有两位主要的发明人，牛顿和莱布尼茨。牛顿发明微积分的一个重要原因是，他需要一个数学工具解决力学问题，比如如何计算速度。可能有人会说，这还不容易，在小学我们就教了，就是距离除以时间。 没有错，我们从小学到中学都是这么教的，但这只是一段时间𝛥t的平均速度。如果我要问你，在某一时刻的瞬间速度是多少？你就不知道了，或者只能拿平均速度来近似瞬间速度。或者说，拿宏观的规律近似微观的。 但是在很多场合，我们要了解的是瞬间速度，而不是平均速度。比如一个警察抓超速，依据的就是驾驶者的瞬间速度，而不是他一路开过来的平均速度。对于瞬间速度，牛顿之前的科学家并没有太多的了解，当然也不会计算了。 那么牛顿是怎么解决这个问题的呢？他采用了无限逼近的方法。具体的想法是这样的： 首先我们回到速度的定义，就是一段时间里的位移量𝛥S除以相应的时间𝛥t，我们可以写成速度v=𝛥S/𝛥t。我把这种关系用一个示意图表示出来： 在左边的图中，横轴是时间轴，纵轴是位移，那条曲线是位移随着时间变化的函数S(t)。我在图中标记了从t0开始的一段时间𝛥t，以及相应的位移量𝛥S，它们构成一个直角三角形的两条直角边。位移量除以时间，就是斜边的斜率。 当时间间隔𝛥t逐渐变小时，这个比值会变化，会越来越反映出在t0点附近的速度。我们在前面介绍了极限的概念，当𝛥t趋近于0时，那条反映速度的斜线，就是曲线在t0点的切线，牛顿就把那个切线的斜率，定义为在t0点的瞬间速度。我们不妨这么写，v(t0)=𝛥S/𝛥t，当𝛥t→0（趋近于0）时。 通过上述方式，牛顿就从平均速度出发，定义了瞬间速度，也就是说，某个时刻的瞬间速度，是这个时刻附近一个无穷小的时间内的平均速度。 如果我们用曲线来考察这种瞬间变化，那么瞬间速度就是距离函数曲线在某个点切线的斜率。由于在每一个时间点，切线的斜率是变化的，因此如果把各个点的切线斜率画出来，它也是一条函数曲线。 牛顿把这个由每个点切线斜率构成的函数，称为原来函数的流数，我们今天称之为导数。通常我们用y=f(x)表示原函数，用y=f’(x)表示它的导数。在上面的例子中，位移的变化函数S(t)是原函数，速度变化的函数v(t)则是原函数的导数，我们可以写成v(t)=S’(t)。 正如同速度反映的是距离的变化速率，一个函数的导数所反映的也是原函数变化的速率，比如在上面的图中，我们可以看出原函数增长越来越慢，因此它的导数，也就是增速，是逐渐下降的。 现在我们回顾一下函数这个概念，它反映的是一个变量随着另一个变量的变化，而导数这个概念，则反映函数变化的快慢。比如抛物线函数y=x^2，它在x=1这个点，导数是2，也就是说x增加一小份（无穷小），y要增加两小份。 相比之下，直线y=x在同一个点的增速就要慢一点，它的导数是1，也就是说x增加一小份，y也增加一小份，因此我们说抛物线在x=1这个点的变化比直线更快。· 对于同一根曲线，我们前后也能对比，比如抛物线在x=2这个点的导数是4，因此我们说，它在x=2时，比x=1时，变化更快。 我们过去也会说，某个函数变化快，某个函数变化慢，但是这些都是宏观的描述，没有量化度量。导数解决了这个问题。我们还说，某个函数，越变越快，这也只是宏观的、定性的分析。 有了导数的概念之后，我们就可以准确地度量任意一个函数在某一个点的变化。因此导数的本质是对变化快慢的准确量化度量。 导数是微积分中最重要的概念之一，从导数出发我们稍微往前走一小步，就进入到微积分的微分了。 什么是微分呢？它其实就是在前面有关速度的例子中，𝛥t趋近于零时，𝛥S的值。对此一般性的函数，我们用dx表示自变量趋于零的情况，用dy表示函数的微分。 如果我们对比一下导数的定义f’(x) = 𝛥y/𝛥x，其中𝛥x趋近于零，以及微分的定义dy =f’(x)dx，就可以看出它们讲的其实是一回事，因为𝛥x和𝛥y趋近于零之后，就是dx和dy。有时人们直接将导数写成f’(x) =dy/dx。 如果我们孤立地看微分dy，它是个无穷小，搞出这样一个新概念有什么必要呢？我们用一个具体的例子，也就是有关圆柱体积变化趋势的例子来说明。 我们知道，圆柱体的体积：V=𝛑R^2 h，如果我要问，这个体积随半径变化快，还是随高度变化快？在没有微分这个概念时，一般人根据直觉，会觉得随半径变化快，因为是平方关系，而它随高度变化只是线性关系。 但真实情况是什么样呢？我们可以把体积函数分别对半径和高度各做一次微分，得到下面两个结果： 体积对半径R微分：dV/dR=2𝛑Rh 体积对高度h微分：dV/dh=𝛑R^2 大家不必关心细节，了解一下这样两个结论： 由于半径增加所带来的体积增量，和圆柱体当前的半径成正比，也和它的高度成正比。 由于高度增加所带来的体积增量，和圆柱体当前半径的平方成正比，但和它的高度无关。 这时，你如果对比一下两个微分函数就会发现，哪个变化的速率快，还真不好说。假如R等于10，h也等于10，体积就随半径变化快。如果R=10，h只有1，那就是随着高度变化快。 假如你是一个工程师，要建造一个巨大的储油罐，无论你增大半径，还是增加高度，都有相当的工程难度。现在你的研发经费有限，只能在一个维度，增大储油罐的体积，你应该怎么做呢？ 如果你没有学过微积分，你可能会觉得该增加半径。但是听了今天的课程之后你就知道，在这个储油罐比较“扁平”时，应该增加高度。总的来讲，当高度没有达到半径的1/2时，都应该增加高度。 我们在工作和生活中，其实经常遇到这样的问题，一个函数取决于很多变量，这时我们不知道该在哪个方向改变，怎样才能以最快的速度进步。微分这个工具，其实给解决这一类的问题提供了很好的方法。它引出了一个梯度的概念，利用梯度，我们就能解决这个问题了。 梯度是微分的一个扩展。在上面的圆柱体问题中，对圆柱体函数，我们可以针对半径求微分dV/dR，也可以针对高度求微分dV/dh。如果我们把这两个微分的结果放到一起，就是梯度，也就是说圆柱体积函数的梯度是（2𝛑Rh，𝛑R^2）。 梯度的物理含义可以这样理解，如果你去登山，怎样沿着最陡的方向，最快地爬到山顶呢？梯度函数告诉你在任意一点，往不同方向走的上升速度是不一样的，因此你很容易找到前进的目标。在圆柱体函数中的梯度是上面那个式子，我们在前面得到的结论是，只要高度小于1/2的半径，就应该优先增加高度。 如果是一个长方体，情况又如何呢？我们先把体积函数写出来，体积等于长乘以宽乘以高度，即 V=LWH。接下来，我们可以用微分计算出它的梯度函数。 这里面过程我就省略了，我直接给出答案。这时体积的梯度为 （宽度乘以高度，长度乘以高度，长度乘以宽度），一共三个分量。这时你会发现，长宽高，哪个最小，就应该优先增加哪一个。 比如说，长为10，宽和高分别是4和6，这时梯度函数为（24，60，40），你应该增加宽度。这其实和我们的直觉是一致的，如果我们这样不断优化，最后的结果是长方体变成立方体时，体积达到最大。 不只是数学问题，其实很多时候，我们都面临在限制要素中作选择的问题。很多时候，我们总想全方位改进自己，但是人的精力和资源有限，因此在某一时刻，可能只能向一个方向努力。 希望梯度这个概念在你选择方向时能够给你启发。很多人从直觉出发，觉得该补短板，另一些人则觉得，该把长板变得更长。第一类人会和你讲木桶理论，第二类人会和你讲长板理论，每一类都有很多成功的例子，也有很多失败的教训。 于是很多人就不知道该用哪一个理论了。事实上你今天学了梯度理论后，就很容易作决断了，那就是在任何时刻算出梯度，然后沿着最陡，但是收益最大的路径前进就好。 在增加长方体体积时，显然是在采用补短板的策略，但是在增加圆柱体体积时，就看情况而定了，如果高度太低，它是严重的短板，需要弥补，但是只要它超过圆柱体半径的一半时，就要增加长板（半径）的优势了。 如果说你有一个目标函数，它可能受到多个变量的影响，那是你长期进步的趋势，但是在每一个时刻，你需要计算一下那个函数针对各个变量的微分，也就是梯度函数，找到进步最显著的方向去努力。这就是通过宏观趋势把握微观变化。 要点总结： 我们从导数出发，介绍了微分的概念，它是我们从函数的宏观趋势，把握每一个点细节变化的工具。然后我们介绍了多变量函数的微分，也就是梯度的概念，并且说明了如何在有大量不确定性，或者说大量的变量中找到前进方向的方法，具体讲就是往坡度最高的方向努力。 因此，微积分给我们的第一个思维提升就是练习从宏观趋势中把握微观变化的趋势，让我们认清每一步的方向。 下一讲，我们还讲微积分，透过微积分讨论企业增长里的奇点和连续性。我们下一讲再见。 N-1 ↩]]></content>
      <tags>
        <tag>吴军,数学,电子书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL是怎样运行的：从根儿上理解 MySQL]]></title>
    <url>%2F2019%2F09%2F20%2F2019-9-20%2F</url>
    <content type="text"><![CDATA[重新认识MySQL 客户端 + 服务器 启动服务器程序 UNIX Windows 启动客户端程序 客户端与服务器的通信 TCP/IP 命名管道和共享内存 UNIX域套接字文件 服务器处理客户端请求 存储引擎 启动选项和系统变量 在命令行上使用选项 配置文件中使用选项 Windows UNIX 系统变量 查看系统变量 设置系统变量 状态变量 字符集和比较规则 字符集的转换 InnoDB记录存 InnoDB页 InnoDB行格式 Compact行格式 行数据溢出 行溢出的临界点 InnoDB数据页 数据页结构 记录在页中的存储 记录头信息 Page Directory Page Header File Header File Trailer B+树索引 无索引查找 在页内查找 在多页中查找 索引 目录项 用页存放目录项 聚簇索引 二级索引 B+树索引的使用 合理使用索引 全值匹配 匹配左边的列 匹配列前缀 回表的代价 二级索引 + 回表 or 全表扫码 覆盖索引 合理地建立索引 MySQL的数据目录 数据库和文件系统的关系 数据目录 数据目录和安装目录的区别 查找数据目录 数据目录的结构 数据库在文件系统中的表示 表在文件系统中的表示 文件系统对数据库的影响 MySQL系统数据库简介 本文为敝人的学习记录，感兴趣的请在掘金小册购买同名原著 😎 重新认识MySQL# 客户端 + 服务器# MySQL服务器进程(也叫数据库实例) MySQL客户端进程 进程：进程号(PID，由操作系统随机分配)、进程名称 MySQL服务器进程的默认名称为mysqld， MySQL客户端进程的默认名称为mysql 启动服务器程序# UNIX# 使用安装目录下(比如 /usr/local/mysql/bin/): 1mysqld 1mysqld_safe mysqld_safe是一个启动脚本的命令，调用了mysqld，并启动一个监控进程(重启，日志) 12mysql.server startysql.server stop mysql.server是一个链接文件， 会调用mysqld_safe Windows# 使用安装目录下(比如 D:\Program Files\mysql-5.7.26-winx64\bin\) mysqld.exe 可执行文件 使用 Windows服务。把某个程序注册为Windows服务的格式： &quot;可执行文件路径&quot; --install [-manual] [服务名称] 123D:\Program Files\mysql-5.7.26-winx64\bin\mysqld --install [MySQL_Service]net start MySQL_Servicenet stop MySQL_Service 启动客户端程序# mysql -h主机名 -u用户名 -p密码 123mysql -hlocalhost -uroot -p123abcmysql -u root -pmysql --host=localhost --user=root --password=123abc 退出客户端 123quitexit\q 客户端与服务器的通信# 本质是两个进程间的通信 TCP/IP# 每台计算机都有一个唯一的IP地址 每个进程向操作系统申请一个端口号(0~65535) 通过IP地址 + 端口号来与某个进程通信 MySQL服务器进程的默认端口号为3306，自定义MySQL服务器进程的端口号如下 1mysqld -P3307 命名管道和共享内存# Windows系统中的进程间通信方式 命名管道 12345mysqld --enable-named-pipemysql --pipeormysql --protocol=pipe 共享内存 123mysqld --shared-memorymysql --protocol=memory UNIX域套接字文件# 1mysql --protocol=socket 服务器程序默认监听的套接字文件路径为/tmp/mysql.sock，指定套接字文件路径： 12mysqld --socket=/tmp/a.txtmysql -hlocalhost -uroot --socket=/tmp/a.txt -p 服务器处理客户端请求# 存储引擎# XA列代表是否支持分布式事务 Savepoints代表是否支持部分事务回滚 启动选项和系统变量# 在命令行上使用选项# 12mysqld --skip-networkingmysqld --default-storage-engine=MyISAM \\ 等号两边不能有空格 使用mysql --help可以看到mysql程序支持的启动选项 使用mysqld --verbose --help查看mysqld支持的启动选项 配置文件中使用选项# Windows# 12345678910111213%WINDIR%\my.ini%WINDIR%\my.cnf C:\my.iniC:\my.cnfBASEDIR\my.ini \\ MySQL安装路径BASEDIR\my.cnf defaults-extra-file 命令行指定的额外配置文件路径，如mysqld --defaults-extra-file=C:\Users\chiangtao ho\my_extra_file.txt%APPDATA%\MySQL\.mylogin.cnf 登录路径选项（仅限客户端） UNIX# 12345678910/etc/my.cnf /etc/mysql/my.cnf SYSCONFDIR/my.cnf $MYSQL_HOME/my.cnf 特定于服务器的选项（仅限服务器）defaults-extra-file ~/.my.cnf 用户特定选项~/.mylogin.cnf 用户特定的登录路径选项（仅限客户端） 系统变量# 查看系统变量# 12SHOW VARIABLES like 'max_connections';SHOW VARIABLES LIKE 'default%'; 系统变量的单词之间必须使用下划线_连接 设置系统变量# 变量的作用范围 GLOBAL：全局变量，影响服务器的整体操作 SESSION (LOCAL)：会话变量，影响某个客户端连接的操作 123456SET GLOBAL default_storage_engine = MyISAM;SET @@GLOBAL.default_storage_engine = MyISAM;SET SESSION default_storage_engine = MyISAM;SET @@SESSION.default_storage_engine = MyISAM;SET default_storage_engine = MyISAM; \\ 默认作用范围是LOCAL 那我们的SHOW VARIABLES语句默认查看的是SESSION作用范围的系统变量 并不是所有系统变量都具有GLOBAL和SESSION的作用范围 状态变量# 与系统变量类似，状态变量也有GLOBAL和SESSION两个作用范围的 1SHOW STATUS LIKE 'thread%'; 字符集和比较规则# 查看字符集 12SHOW CHARSET;SHOW CHARACTER SET; Default collation表示字符集默认的比较规则 Maxlen代表该字符集表示一个字符最多需要几个字节 查看比较规则 MySQL中utf8是utf8mb3的别名，所以在MySQL中utf8就意味着使用1~3个字节来表示一个字符，如果大家有使用4字节编码一个字符的情况，比如存储一些emoji表情，使用utf8mb4 MySQL有4个级别的字符集和比较规则，分别是： 服务器级别 character_set_server, collation_server 数据库级别 character_set_database, collation_database 表级别 列级别 编码和解码使用的字符集不一致将导致乱码 字符集的转换# character_set_client 服务器解码请求语句时使用的字符集 character_set_connection 服务器处理请求时会把请求字符串从character_set_client转为character_set_connection character_set_results 服务器向客户端返回数据时使用的字符集 通常把 character_set_client 、character_set_connection、character_set_results 这三个系统变量设置成和客户端使用的相同的字符集 12345SET NAMES 字符集名;SET character_set_client = 字符集名;SET character_set_connection = 字符集名;SET character_set_results = 字符集名; InnoDB记录存# InnoDB页# InnoDB是一个将表中的数据存储到磁盘上的存储引擎。磁盘读写的速度比内存的读写速度差了几个数量级，因此设计InnoDB时将数据划分为若干个页并以页作为磁盘和内存之间交互的基本单位，页的大小一般为 16 KB。 InnoDB行格式# 4种行格式: Compact Redundant Dynamic Compressed 1CREATE TABLE 表名 ROW_FORMAT=行格式名称 Compact行格式# 所有变长字段的真实数据占用的字节长度都被存放在变长字段长度列表 把值为NULL的列统一存储到NULL值列表中 记录头信息是由固定的5个字节组成 MySQL会为每个记录默认的添加一些列（隐藏列），包括：row_id（DB_ROW_ID）、transaction_id（DB_TRX_ID）、roll_pointer（DB_ROLL_PTR）。 行数据溢出# 对于MySQL的每条记录，除了BLOB或者TEXT类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。这个65535个字节除了列本身的数据之外，还包括一些其他的数据，即 真实数据本身 真实数据占用字节的长度标识（&lt;= 2 bytes） NULL值标识（&lt;= 1 byte），当列都有NOT NULL属性时为0 因此，上图中设置变长类型VARCHAR(M)（M表示允许的字符数量）M=65535时导致了溢出。 真实数据：65533 = 65529(c1)+ 4(c2) 长度标识：2 NULL值标识：1 共65536 &gt; 65535溢出。 更换字符集后溢出。 VARCHAR(M)类型的列就最多可以存储65533个字节，而一个页的大小一般是16KB，也就是16384字节，因此在Compact和Reduntant行格式中，在本记录只会存储该列的前768个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中；而在Dynamic和Compressed行格式中，记录中只存储其他页的地址。 行溢出的临界点# MySQL中规定一个页中至少要存放两行记录 每个页除了存放记录外，也需要存储一些额外的信息，这些额外信息加起来需要132个字节 每个记录的额外信息需要27字节 真实数据的长度标识 1B NULL值标识 1B 记录头信息 5B row_id 6B transaction_id 6B roll_pointer 7B 不溢出的临界条件：132 + 2×(27 + n) &lt; 16384 InnoDB数据页# 数据页结构# 记录在页中的存储# 记录头信息# 以 page_demo 表为例 123456CREATE TABLE page_demo( c1 INT, c2 INT, c3 VARCHAR(10000), PRIMARY KEY (c1)) CHARSET=ascii ROW_FORMAT=Compact; 由于指定 c1 为主键，所以在行格式中就没有隐藏列 row_id。 插入数据4条记录 1234INSERT INTO page_demo VALUES(1, 100, 'aaaa'), (2, 200, 'bbbb'), (3, 300, 'cccc'), (4, 400, 'dddd'); delete_mask 标记当前记录是否被删除，值为0的时候代表记录没有被删除，1则被删除了； 所有被删的记录会组成一个垃圾链表，新记录插入到表时可以覆盖这些被删除的记录占用的存储空间。 n_owned 见Page Directory heap_no 表示当前记录在本页中的位置，从上图中可以看出，插入的4条记录在本页中的位置分别是：2、3、4、5。最小记录和最大记录分别为0、1。 record_type 记录类型，共4种： 0：普通记录 1：B+树非叶节点记录 （或目录项记录，见目录项） 2：最小记录 3：最大记录 min_rec_mask 代表B+树的每层非叶节点中的最小记录 （或者主键值最小的目录项记录的min_rec_mask值为1） next_record 表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。例如第一条记录的next_record值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。记录按照主键从小到大的顺序形成了一个单链表 如果删除第二条记录 1DELETE FROM page_demo WHERE c1 = 2; 删除第2条记录前后的主要变化： 第2条记录的delete_mask值设置为1； 第2条记录的next_record值变为了0，意味着该记录没有下一条记录了； 第1条记录的next_record指向了第3条记录； 最大记录的n_owned值从5变成了4。 Page Directory# 设计页目录是为了方便快速查找记录，就像书的目录那样，创建 page directory 的步骤： 将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组； 每个组内最大的那条记录的头信息的 n_owned 表示组内记录的数量； 将每个组的最大的那条记录的地址偏移量（也称槽，slot）集中起来存放，构成 Page Directory； InnoDB规定最小记录所在的分组只能有 1 条记录，最大记录所在的分组的记录条数在 1~8 条之间，其它分组中记录的条数则在是 4~8 条之间。 利用页目录查找指定主键的记录的过程分为两步： 通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录； 通过记录的 next_record 属性遍历组中的各个记录。 Page Header# 存储数据的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等。 File Header# 不同类型的页都会以File Header作为第一个组成部分，它记录了针对各种页都通用的一些信息。 索引页（数据页）通过 file header 构成双向链表 File Trailer# 与file header一样对不同类型的页通用，主要用于校验页数据的完整性。 B+树索引# 无索引查找# 在页内查找# 以主键查找 依据页目录（槽）采用二分查找定位分组，再遍历分组 以主键以外的列查找 遍历页内的记录链表 在多页中查找# 定位记录所在的页 页内查找 索引# 建立索引是为了快速定位记录所在的数据页。 对数据页进行排序。即让下一个数据页的记录的主键值大于上一个页的记录的主键值，因此在插入新的记录时涉及数据页间的记录的调整 对页进行排序后，全部记录的主键值就构成了一个递增的序列，从而可以利用二分法实现快速查找。 对每个页设置目录项 目录项# 目录项包括 数据页中的记录的最小主键值，用key来表示； 页号，用page_no表示。 用页存放目录项# 用户记录都存放在B+树的叶节点上，而目录项都存放在非页节点上。 聚簇索引# 特性包括： 依据记录的主键值排序 页内的记录是按照主键的大小顺序排成一个单向链表 数据页根据主键大小顺序排成一个双向链表 存放目录项记录的页根据主键大小分为不同的层次 B+树的叶节点存储的是完整的记录，即记录的所有列的值（包括隐藏列） 二级索引# 依据记录的其它列（比如c1）的值排序形成的B+树。将聚簇索引的主键值换为c1的值，此外，叶节点存储的不是完整的记录而只有主键和c1。 通过二级索引来查找完整记录：通过二级索引找到主键值之后再通过聚簇索引查找完整记录。 B+树索引的使用# 合理使用索引# 考虑表 person_info 123456789CREATE TABLE person_info( id INT NOT NULL auto_increment, name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, PRIMARY KEY (id), KEY idx_name_birthday_phone (name, birthday, phone)); idx_name_birthday_phone 为二级索引 全值匹配# 1SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone = '15123983239'; 由于查询优化器的存在，调换name、birthday、phone这几个搜索列的顺序不影响查询的执行过程。 匹配左边的列# 1SELECT * FROM person_info WHERE name = 'Ashburn'; 可以使用索引idx_name_birthday_phone，而 1SELECT * FROM person_info WHERE birthday = '1990-09-27'; 不能使用索引idx_name_birthday_phone。 匹配列前缀# 比如查询名字以 As 开头的记录 1SELECT * FROM person_info WHERE name LIKE 'As%'; 回表的代价# 1SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow'; 二级索引搜索到的结果（即值在Asa～Barlow之间的记录）在磁盘中的存储是相连的，集中分布在一个或几个数据页中，因此可以很快从磁盘中读出，这种读取方式可以称为顺序I/O。而回表是根据不连续的id值到聚簇索引中读出完整的用户记录（可能分布在不同的数据页中），这种读取方式可以称为随机I/O。一般情况下，顺序I/O比随机I/O的性能高很多。 二级索引 + 回表 or 全表扫码# 需要回表的记录越多，使用二级索引的性能就越低，甚至不如使用聚簇索引全表扫码； 使用LIMIT限制回表次数，使优化器倾向于使用二级索引 + 回表的方式执行查询。 覆盖索引# 如果需要查询的列包含在二级索引中，就可以避免回表查询，这种只需要用到索引的查询方式称为索引覆盖。例如对于索引idx_name_birthday_phone 1SELECT name, birthday, phone FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow' 合理地建立索引# 只给搜索、排序、分组的列创建索引 即只给出现在 WHERE、ORDER BY、GROUP BY 子句中的列创建索引； 列的方差越大越适合建立索引 列的数据越分散，越适合索引查询。举个极端的例子，数据都相同的列，对这样的列建立索引毫无意义； 列的数据类型越小越适合建立索引 比较数据大小更快，占用的存储空间更小； 索引字符串的前缀 1234567CREATE TABLE person_info( name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone CHAR(11) NOT NULL, country varchar(100) NOT NULL, KEY idx_name_birthday_phone (name(10), birthday, phone)); 其中 name(10) 表示在建立的B+树索引中只保留记录的前10个字符的编码，但是该索引不支持 name 排序 1SELECT * FROM person_info ORDER BY name LIMIT 10; 让索引列在比较表达式中单独出现 12WHERE my_col * 2 &lt; 4WHERE my_col &lt; 4/2 如果列是以某个表达式或者函数调用形式出现是用不到索引的，比如上面的my_col * 2； 开启主键AUTO_INCREMENT属性 可减少页分裂和记录移位的次数。 MySQL的数据目录# 数据库和文件系统的关系# InnoDB、MyISAM等存储引擎都是把表存储在磁盘上。操作系统通过文件系统管理磁盘。 InnoDB、MyISAM等存储引擎 $ \Leftrightarrow $ 文件系统 $ \Leftrightarrow $ 磁盘 数据目录# 数据目录和安装目录的区别# 数据目录是用来存储MySQL在运行过程中产生的数据，要与MySQL的安装目录区别开来。 查找数据目录# 数据目录的结构# 数据库在文件系统中的表示# 每新建一个数据库，MySQL执行了： 在数据目录下创建一个和数据库名同名的子目录； 并在该子目录下创建一个db.opt文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则等。 查看数据库 查看数据目录 除了information_schema这个系统数据库外，其他的数据库在数据目录下都有对应的子目录。 表在文件系统中的表示# 每个表包含两部分信息： 表结构的定义 用表名.frm文件来描述表结构 表中的数据 InnoDB: 数据存在独立表空间(file-per-table tablespace)中，即 test.ibd 文件 MyISAM: 表名.MYD表示表的数据文件、表名.MYI表示表的索引文件 文件系统对数据库的影响# 数据库名和表名不得超过文件系统所允许的最大长度 特殊字符 MySQL会把数据库名和表名中除数字和拉丁字母外的所有字符在文件名里都映射成 @+编码值的形式，如test?.frm $ \rightarrow $ test@003f.frm 文件大小受文件系统限制 MySQL系统数据库简介# mysql 存储了MySQL的账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息、以及时区信息等 information_schema 这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如表、视图、触发器、列、索引等 performance_schema 这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，包括统计最近执行的语句，执行时间，内存使用情况等 sys 这个数据库主要是通过视图的形式把information_schema和performance_schema结合起来]]></content>
      <tags>
        <tag>MySQL, 长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL Notes]]></title>
    <url>%2F2019%2F09%2F05%2F2019-9-5%2F</url>
    <content type="text"><![CDATA[联表查询 字符替换 正则查询 导入SQL文件 排序 联表查询# 12345678SELECT library.id, library.name, r.reader_sum, b.book_sum FROM library INNER JOIN( SELECT library_id, count(*) AS reader_sum FROM reader WHERE library_group_id = 10 GROUP BY library_id ) AS rON r.library_id = library.id INNER JOIN( SELECT library_id, count( * ) AS book_sum FROM book WHERE library_group_id = 10 GROUP BY library_id ) AS bON b.library_id = library.id; 字符替换# 1UPDATE account SET grade = replace(grade,'級','级'); 正则查询# 12SELECT * FROM account WHERE grade REGEXP '級'; -- 查询包含SELECT name FROM person WHERE name REGEXP '^[aeiou]|ok$'; -- aeiou开头，或ok结尾 导入SQL文件# 1234SET @@global.max_allowed_packet = 1024*1024*1024;SET @@global.sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';SET @@sql_mode ='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; 排序# 1SELECT * FROM book WHERE library_id = 257 AND (title REGEXP "我" OR author REGEXP "我") ORDER BY LOCATE("我", CONCAT(title, author)), LENGTH(title), LENGTH(author); 1SELECT * FROM table WHERE id IN (3,6,9,1,2,5,8,7) ORDER BY field(id,3,6,9,1,2,5,8,7); 123SELECT * FROM( SELECT isbn13, cn_title, count(*) total FROM book_info WHERE isbn13 != '' AND source IN ('yidi', 'guotu', 'douban', 'dangdang') GROUP BY isbn13, cn_title ) t1WHERE total &gt; 1 ORDER BY total DESC;]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麻省理工 MapReduce 实验]]></title>
    <url>%2F2019%2F04%2F30%2F2019-4-30%2F</url>
    <content type="text"><![CDATA[MapReduce执行概述 序言：熟悉源代码 Part I: Map/Reduce 输入和输出 Part II: Single-worker单词统计 Part III: 分布式 MapReduce 任务 Part IV: worker错误处理 原文链接 MapReduce执行概述# 论文地址 通过自动将输入数据划分为$M$个片段，Map调用分布在多台机器上。 不同片段的输入数据可以由不同的机器并行处理。 Reduce调用的分布式则通过使用分区函数(即 $hash(key)$ $mod$ $R$)将键空间划分为$R$个部分来实现，$R$的大小和分区函数由用户指定。上图显示了MapReduce操作的总体流程。 当用户程序调用MapReduce函数时，会发生以下操作序列(图中的编号标签对应于下面的数字)： 用户程序中的MapReduce库首先将输入文件拆分为16MB到64MB(用户可通过参数设置)的$M$个片段。 然后，它会在一组计算机上启动该程序的许多副本； master为副本之一，其余的是由master分配工作的workers。 有$M$个Map任务和$R$个Reduce任务需要分配。master为每个空闲的worker分配一个Map任务或Reduce任务； 被分配Map任务的worker读取相应输入片段。 它从输入片段中解析键/值对，并将键/值对传递给用户定义的Map函数。 Map函数生成的中间键/值对缓存在内存中； 内存中的键\值对被周期性地写入到本地磁盘，并通过分区函数划分为$R$个分区。 键\值对在本地磁盘的位置将被传回到master，master再将位置信息转发给Reduce worker； 当Reduce worker收到来自master的位置信息后，它使用远程过程调用(RPC)从Map worker的本地磁盘读取缓冲数据。 当Reduce worker读取了所有中间数据时，它会根据中间键进行排序，以便将所有相同的中间键组合在一起。 之所以需要排序是因为通常有许多不同的键映射到同一个reduce任务。 如果中间数据量太大而无法容纳在内存中，则使用外部排序； Reduce worker对排好序的中间数据进行遍历。对遇到的每个唯一中间键，它将键和相应的一组中间值传递给用户的Reduce函数。 Reduce函数的输出附加到此Reduce分区的最终输出文件。 完成所有Map任务和Reduce任务后，master会唤醒用户程序。 此时，用户程序中的MapReduce()将返回用户代码。 序言：熟悉源代码# 提供的Map/Reduce代码支持两种操作模式，即串行和分布式。 在前者中，map和reduce任务每次执行一个：首先是第一个map任务执行完成，然后是第二个，然后是第三个，等等。当所有map任务完成后，执行第一个reduce任务，然后是第二个，等等。这种模式虽然不快，但方便调试。 分布式模式运行着许多worker线程，这些线程先并行执行map任务，然后reduce任务。 这要快得多，但也难以调试。mapreduce包提供了一个简单的Map/Reduce库。 应用程序通常调用master.go中的Distributed()来启动分布式模式，而调用master.go中的Sequential()来获取调试的串行执行。 代码如下执行： 该应用程序提供了许多输入文件、一个map函数、一个reduce函数和reduce任务的数量（$nReduce$）； 创建master。 master启动一个RPC服务器(参见master_rpc.go)，并等待worker注册(使用RPC调用Register()，在master.go中定义)。 当任务变得可用时(在步骤4和5中)，schedule()(位于schedule.go)决定如何将这些任务分配给workers以及如何处理worker故障； master将每个输入文件视为一个 Map任务，并为每个Map任务至少调用一次(at-least-once)doMap()(common_map.go)，可以通过直接使用Sequential()或通过向worker (worker.go)发出DoTask RPC来实现。每次调用doMap()都会读取适当的文件，调用该文件中的map函数，并将生成的键/值对写入$nReduce$个中间文件。doMap() 对每个键哈希化以便挑选中间文件和 将会处理键的reduce任务。 完成所有map任务后，将会有$nMap \times nReduce$个文件。 每个文件名都包含一个前缀，map任务编号和reduce任务编号。 如果有两个map任务和三个reduce任务，map任务将创建如下六个中间文件： mrtmp.xxx-0-0 mrtmp.xxx-0-1 mrtmp.xxx-0-2 mrtmp.xxx-1-0 mrtmp.xxx-1-1 mrtmp.xxx-1-2 每个worker必须能够读取由任何其他worker写入的文件以及输入文件。 现实部署利用分布式存储系统(如GFS)来允许此读取，即使workers在不同的计算机上运行。 在本实验中，您将在同一台计算机上运行所有workers，并使用本地文件系统； 接下来master为每个reduce任务至少调用一次(at-least-once) doReduce()(common_reduce.go)。 与doMap()一样，可以直接或通过worker来完成。 用于reduce任务r的`doReduce()从每个map任务中收集第$r$个中间文件，并为这些文件中出现的每个键调用reduce函数。 reduce任务生成$nReduce$个结果文件； master调用mr.merge()(master_splitmerge.go)，将上一步生成的所有$nReduce$个文件合并为单个输出； master向每个woker发送Shutdown RPC，然后关闭自己的RPC服务器。 说明：在后续的练习中，您必须编写/修改doMap()，doReduce()和schedule()，它们分别位于common_map.go、common_reduce.go和schedule.go中。 您还必须在../main/wc.go中编写map函数和reduce函数。 Part I: Map/Reduce 输入和输出# 提供的Map/Reduce实现缺少部分代码。 在编写第一个Map/Reduce函数对之前，您需要修改sequential的实现代码。 特别是，提供的代码缺少两个关键部分：分配一个map任务输出的函数，以及收集一个reduce任务所有输入的函数。 这些任务分别由common_map.go中的doMap()函数和common_reduce.go中的doReduce()函数执行。 为了帮助您确定是否正确实现了doMap()和doReduce()，我们为您提供了一个Go测试套件(test_test.go)用于检查文件中实现。 例如测试修改后的sequence实现代码，请运行： go test -run Sequential or go test -v -run Sequential 解答： 该部分任务只需要补全common_map.go中的doMap()和common_reduce.go中的doReduce()的代码，补全的结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package mapreduceimport ( "hash/fnv" "io/ioutil" "encoding/json" "log" "os")func doMap( jobName string, // the name of the MapReduce job mapTask int, // which map task this is inFile string, nReduce int, // the number of reduce task that will be run ("R" in the paper) mapF func(filename string, content string) []KeyValue,) &#123; // // doMap manages one map task: it should read one of the input files // (inFile), call the user-defined map function (mapF) for that file's // content, and partition mapF's output into nReduce intermediate files. // // There is one intermediate file per reduce task. The file name // includes both the map task number and the reduce task number. Use // the filename generated by reduceName(jobName, mapTask, r) // as the intermediate file for reduce task r. Call ihash() (see // below) on each key, mod nReduce, to pick r for a key/value pair. // // mapF() is the map function provided by the application. The first // argument should be the input file name, though the map function // typically ignores it. The second argument should be the entire // input file content. mapF() returns a slice containing the // key/value pairs for reduce; see common.go for the definition of // KeyValue. // // Look at Go's ioutil and os packages for functions to read // and write files. // // Coming up with a scheme for how to format the key/value pairs on // disk can be tricky, especially when taking into account that both // keys and values could contain newlines, quotes, and any other // character you can think of. // // One format often used for serializing data to a byte stream that the // other end can correctly reconstruct is JSON. You are not required to // use JSON, but as the output of the reduce tasks *must* be JSON, // familiarizing yourself with it here may prove useful. You can write // out a data structure as a JSON string to a file using the commented // code below. The corresponding decoding functions can be found in // common_reduce.go. // // enc := json.NewEncoder(file) // for _, kv := ... &#123; // err := enc.Encode(&amp;kv) // // Remember to close the file after you have written all the values! // // Your code here (Part I). //读取输入文件 content, err := ioutil.ReadFile(inFile) if err != nil &#123; log.Fatal("doMap读取输入文件错误",err) &#125; //map操作 kvPairs := mapF(inFile, string(content)) //调用mapF，返回键值对 //将键值对写入到中间文件 tmpFiles := make([] *os.File, nReduce) //R个中间文件 encoders := make([] *json.Encoder, nReduce) for i := 0; i &lt; nReduce; i++ &#123; tmpFileName := reduceName(jobName, mapTask, i) //中间文件名,mrtmp.test-mapTask-i tmpFiles[i], err = os.Create(tmpFileName) //创建中间文件mrtmp.test-mapTask-i if err != nil &#123; log.Fatal("doMap生成中间文件错误", err) &#125; defer tmpFiles[i].Close() encoders[i] = json.NewEncoder(tmpFiles[i]) if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125; for _ , kv := range kvPairs &#123; hashKey := ihash(kv.Key) % nReduce //根据键将键值对分成R组 err := encoders[hashKey].Encode(&amp;kv) //将R个键值对写入R个中间文件 if err != nil &#123; log.Fatal("doMap编码错误", err) &#125; &#125;&#125;func ihash(s string) int &#123; h := fnv.New32a() h.Write([]byte(s)) return int(h.Sum32() &amp; 0x7fffffff)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package mapreduceimport ( "encoding/json" "log" "os" "sort")func doReduce( jobName string, // the name of the whole MapReduce job reduceTask int, // which reduce task this is outFile string, // write the output here nMap int, // the number of map tasks that were run ("M" in the paper) reduceF func(key string, values []string) string,) &#123; // // doReduce manages one reduce task: it should read the intermediate // files for the task, sort the intermediate key/value pairs by key, // call the user-defined reduce function (reduceF) for each key, and // write reduceF's output to disk. // // You'll need to read one intermediate file from each map task; // reduceName(jobName, m, reduceTask) yields the file // name from map task m. // // Your doMap() encoded the key/value pairs in the intermediate // files, so you will need to decode them. If you used JSON, you can // read and decode by creating a decoder and repeatedly calling // .Decode(&amp;kv) on it until it returns an error. // // You may find the first example in the golang sort package // documentation useful. // // reduceF() is the application's reduce function. You should // call it once per distinct key, with a slice of all the values // for that key. reduceF() returns the reduced value for that key. // // You should write the reduce output as JSON encoded KeyValue // objects to the file named outFile. We require you to use JSON // because that is what the merger than combines the output // from all the reduce tasks expects. There is nothing special about // JSON -- it is just the marshalling format we chose to use. Your // output code will look something like this: // // enc := json.NewEncoder(file) // for key := ... &#123; // enc.Encode(KeyValue&#123;key, reduceF(...)&#125;) // &#125; // file.Close() // // Your code here (Part I). //遍历属于自己的中间文件，将键值对合并到kvs中 kvs := make(map[string][]string) for i := 0; i &lt; nMap; i++ &#123; fileName := reduceName(jobName, i, reduceTask) file, err := os.Open(fileName) //打开中间文件mrtmp.test-i-reduceTask if err != nil &#123; log.Fatal("doReduce打开文件错误", err) &#125; dec := json.NewDecoder(file) for &#123; //每个中间文件可能包含多个键值对 var kv KeyValue err = dec.Decode(&amp;kv) //解码一个键值对 if err != nil &#123; break &#125; _, ok := kvs[kv.Key] if !ok &#123; //出现新的键则初始化kvs kvs[kv.Key] = []string&#123;&#125; &#125; kvs[kv.Key] = append(kvs[kv.Key], kv.Value) //加入与键对应的值 &#125; file.Close() &#125; //将键集合到一起并排序 var keys []string for k := range kvs &#123; keys = append(keys, k) &#125; sort.Strings(keys) //创建输出文件 out := mergeName(jobName, reduceTask) file, err := os.Create(out) if err != nil &#123; log.Fatal("doReduce创建输出文件错误", err) &#125; enc := json.NewEncoder(file) //reduce操作 for _, k := range keys &#123; res := reduceF(k, kvs[k]) //调用客户端的reduceF，进行reduce enc.Encode(KeyValue&#123;k, res&#125;) //reduce后的键值对写入到输出文件 &#125; file.Close()&#125; 运行go test -run Sequential，结果如下： Part II: Single-worker单词统计# 在该部分，您将要实现一个简单的Map/Reduce示例——单词统计。 具体是需要实现main/wc.go中的mapF()和reduceF()函数。 您的工作是插入代码，以便wc.go返回输入文件中每个单词出现的次数。 一个单词是任意连续的字母序列，其中字母可用Golang的unicode.IsLetter函数来判断。 在~/6.824/src/main目录中提供了一些路径名为pg-*.txt形式的输入文件， 可用如下命令给wc.go使用输入文件运行： go run wc.go master sequential pg-*.txt 查看MapReduce论文的第2部分。mapF()和reduceF()函数与论文第2.1节中的函数略有不同。mapF()将接收一个文件名和该文件的内容，并将内容分成单词最终输出一个mapreduce.KeyValue型切片。 对于单词统计可将单词作为键。对输出中的每个键都将调用一次reduceF()，其中包含mapF()为该键生成的所有值的切片。 reduceF()返回一个包含键出现总数的字符串。 提示1：关于Go的字符串处理，可以参读 Go Blog on strings 提示2：可以使用strings.FieldsFunc函数将字符串拆分成单词 提示3： 利用Go的strconv包可以很方便地将字符串转换成整型 使用如下命令来验证答案： go run wc.go master sequential pg-*.txt 答案： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt" "mapreduce" "os" "strconv" "strings" "unicode")//// The map function is called once for each file of input. The first// argument is the name of the input file, and the second is the// file's complete contents. You should ignore the input file name,// and look only at the contents argument. The return value is a slice// of key/value pairs.//func mapF(filename string, contents string) []mapreduce.KeyValue &#123; // Your code here (Part II). var res []mapreduce.KeyValue f := func(c rune) bool &#123; //不是字母 return !unicode.IsLetter(c) &#125; words := strings.FieldsFunc(contents, f) //在不是字母地方拆分字符串contents for _, key := range words &#123; res = append(res, mapreduce.KeyValue&#123;key, "1"&#125;) &#125; return res&#125;//// The reduce function is called once for each key generated by the// map tasks, with a list of all the values created for that key by// any map task.//func reduceF(key string, values []string) string &#123; // Your code here (Part II). count := 0 for _, value := range values &#123; num, _ := strconv.ParseInt(value, 10, 64) // 将字符串value（例如："157"）按照十进制转换成整型 count = count + int(num) &#125; return strconv.Itoa(count) //整型转换成字符串&#125;// Can be run in 3 ways:// 1) Sequential (e.g., go run wc.go master sequential x1.txt .. xN.txt)// 2) Master (e.g., go run wc.go master localhost:7777 x1.txt .. xN.txt)// 3) Worker (e.g., go run wc.go worker localhost:7777 localhost:7778 &amp;)func main() &#123; if len(os.Args) &lt; 4 &#123; fmt.Printf("%s: see usage comments in file\n", os.Args[0]) &#125; else if os.Args[1] == "master" &#123; var mr *mapreduce.Master if os.Args[2] == "sequential" &#123; mr = mapreduce.Sequential("wcseq", os.Args[3:], 3, mapF, reduceF) &#125; else &#123; mr = mapreduce.Distributed("wcseq", os.Args[3:], 3, os.Args[2]) &#125; mr.Wait() &#125; else &#123; mapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil) &#125;&#125; 运行go run wc.go master sequential pg-sherlock_holmes.txt和sort -n -k2 mrtmp.wcseq | tail -10的结果： Part III: 分布式 MapReduce 任务# 在当前的实现中，是通过串行的方式来执行Map任务和Reduce任务。 Map/Reduce最大的卖点之一是它可以自动地并行执行原始的串行代码而无需开发人员的任何额外工作。 在这一部分中，您将完成一个分布式MapReduce版本，即将工作拆分为在多核上运行的一组worker线程。 尽管不像真实的Map/Reduce部署被分布在多台机器上那样，但你本部分的实现中将使用RPC来模拟分布式计算。 mapreduce/master.go中的代码完成了管理MapReduce的大部分工作。 我们还为您提供了mapreduce/worker.go中worker线程的完整代码以及在mapreduce/common_rpc.go中处理RPC的一些代码。 你的任务是实现mapreduce/schedule.go中的schedule()函数。 master在MapReduce期间将两次调用schedule()，一次用于Map阶段，一次用于Reduce阶段。 schedule()的功能是将任务分发给可用的worker。 任务的数量通常比worker线程多，因此schedule()必须为每个worker分配一系列任务，一次一个。 schedule()应该等到所有任务都完成后再返回。 schedule()通过读取registerChan参数来了解一组worker。 该channel为每个worker生成一个包含worker的RPC地址的字符串。所有的worker都会出现在registerChan，其中一些worker可能在调用schedule()之前就存在，而另一些worker可能在schedule()运行时才启动。schedule()应该充分利用所有的worker，包括启动后出现的worker。 schedule()通过向worker发送Worker.DoTaskRPC来通知worker执行任务。 此RPC的参数由mapreduce/common_rpc.go中的DoTaskArgs定义。File元素仅由Map任务使用，代表要读取的文件的名称；schedule()可以在mapFiles中找到这些文件名。 使用mapreduce/common_rpc.go中的call()函数将RPC发送给worker。 第一个参数是worker的地址，从registerChan读取，第二个参数是Worker.DoTask， 第三个参数是DoTaskArgs结构，最后一个参数是nil。 您对在第III部分的解答仅涉及对schedule.go的修改；如果您在调试过程中修改了其他文件，请恢复其原始内容。请先测试再提交。 使用go test -run TestParallel来测试您的答案。 该命令将执行两个测试，TestParallelBasic和TestParallelCheck，后者验证您的schedule()是否使worker并行执行任务。 提示1：schedule()应该并行地向worker发送RPC，以便worker可以并发执行任务。 你会发现go语句对此很有用，参见Concurrency in Go。 提示2：schedule()必须等待worker完成一个任务后才能给它另下一个任务，Go的channel对此很有用。 提示3： sync.WaitGroup 提示4：追踪错误的最简单的方法是插入print语句（在common.go中可能是调用debug()），使用go test -run TestParallel &gt; out将输出收集到一个文件中，然后分析输出是否与你对代码的预期相符。 最后一步是最重要的。 提示5：检查您的代码是否有竞争的情况可在测试中运行race detector。 注意：我们提供的代码是在单个UNIX进程中将worker作为线程运行，并且可以在单台机器上使用多核。 要想在使用网络进行通信的多台机器上运行worker必须进行一些修改：RPC必须使用TCP而不是UNIX-domain套接字；需要有一种方法来启动所有机器上的worker进程；所有的机器都必须通过某种网络文件系统共享存储。 答案见Part IV。 Part IV: worker错误处理# 在这部分中，您将实现master处理失败的worker的功能。由于worker的状态不是持久的，该功能在MapReduce中相对容易实现。 如果worker在处理来自master的RPC时发生错误，master的call()最终会因超时而返回false。在这种情况下，master会将该任务重新分配给另一个worker。 RPC故障并不一定意味着worker没有执行任务；worker可能已执行任务但是返回结果丢失，或者worker可能仍在执行但master的RPC超时。因此，可能会发生两个worker接收相同任务、计算并产生输出的情况。 需要对map或reduce函数进行两次调用才能为给定输入生成相同的输出，因此如果后续处理读取一个输出或者读取另一个输出，则不会出现不一致。 此外，MapReduce框架确保map和reduce函数输出以原子方式出现：输出文件要么不存在，要么包含单个map或单个reduce函数执行的整个输出（提供的代码不涉及这部分）。 您的实现必须通过test_test.go中剩下的两个测试用例。 第一个用例测试一个worker的失败，而第二个测试用例测试对多个worker的失败的处理。 测试用例会定期启动新的worker，master可以使用这些worker来推进程序过程，但这些worker在处理完一些任务后会失败。 使用下面的命令来运行测试： go test -run Failure 在第IV部分，只涉及对schedule.go的修改。 如果您在调试过程中修改了其他文件，请恢复其原始内容，然后再进行测试、提交。 Part III、Part IV答案： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mapreduceimport "fmt"//// schedule() starts and waits for all tasks in the given phase (mapPhase// or reducePhase). the mapFiles argument holds the names of the files that// are the inputs to the map phase, one per map task. nReduce is the// number of reduce tasks. the registerChan argument yields a stream// of registered workers; each item is the worker's RPC address,// suitable for passing to call(). registerChan will yield all// existing registered workers (if any) and new ones as they register.//func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) &#123; var ntasks int var n_other int // number of inputs (for reduce) or outputs (for map) switch phase &#123; case mapPhase: ntasks = len(mapFiles) n_other = nReduce case reducePhase: ntasks = nReduce n_other = len(mapFiles) &#125; fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other) // All ntasks tasks have to be scheduled on workers. Once all tasks // have completed successfully, schedule() should return. // // Your code here (Part III, Part IV). // done := make(chan bool) for i := 0; i &lt; ntasks; i++ &#123; go func(num int) &#123; args := DoTaskArgs&#123;jobName, mapFiles[num], phase, num, n_other&#125; var worker string reply := new(struct&#123;&#125;) ok := false for ok != true &#123; worker = &lt;-registerChan ok = call(worker, "Worker.DoTask", args, reply) &#125; done &lt;- true //任务完成 registerChan &lt;- worker //该worker工作完毕，处于空闲，加入channel中以分配给其它任务 &#125;(i) &#125; for i := 0; i &lt; ntasks; i++ &#123; //等待所有任务完成 &lt;-done &#125; fmt.Printf("Schedule: %v done\n", phase)&#125; 运行go test -run TestParallel的结果：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[远程过程调用和线程(RPC and Thread)]]></title>
    <url>%2F2019%2F03%2F25%2F2019-3-25%2F</url>
    <content type="text"><![CDATA[MIT Distributed System Course: Lecture 2 Remote Procedure Call (RPC) 目标： 建立编程友好的客户端/服务器通信 RPC消息图： 客户端 服务器 请求---&gt; &lt;---响应 软件结构： client app handlers stubs dispatcher RPC lib RPC lib net ------------ net Go rpc包： 官方文档 import &quot;net/rpc rpc包提供对通过网络或其他I / O连接的对象的导出方法的访问。 服务器注册一个对象，并作为一种服务可见。 注册的对象其导出方法可以被远程访问。 服务器可以注册不同类型的多个对象（服务），但是注册相同类型的多个对象是错误的。 只有满足下列标准的方法（method）才能被远程访问： the method's type is exported. the method is exported. the method has two arguments, both exported (or builtin) types. the method's second argument is a pointer. the method has return type error. 实际上，该方法必须看起来像 1func (t *T) MethodName(argType T1, replyType *T2) error 其中T1和T2可以通过 encoding/gob包来编码。即便使用不同的编解码器，上述标准仍然适用。 第一个参数T1表示调用者提供的参数;第二个参数T2表示要返回给调用者的结果参数。服务器可以通过调用ServeConn来处理单个连接上的请求。更典型的例子有创建网络侦听器并调用Accept，创建HTTP侦听器并调用HandleHTTP和http.Serve。 希望使用该服务的客户端首先和服务器建立连接，然后在连接的基础上调用NewClient。可以使用Dial函数（DialHTTP）方便地执行原始网络连接（HTTP连接）的两个步骤。新建的客户端对象具备Call方法和Go方法。 Call方法等待远程调用完成，而Go方法使用Call结构的Done通道启动异步调用和发出完成信号。 除非设置了显式编解码器，否则一般使用encoding/gob包来传输数据。 一个服务器导出Arith类型的对象的例子： 123456789101112131415161718192021222324252627package serverimport "errors"type Args struct &#123; A, B int&#125;type Quotient struct &#123; Quo, Rem int&#125;type Arith intfunc (t *Arith) Multiply(args *Args, reply *int) error &#123; *reply = args.A * args.B return nil&#125;func (t *Arith) Divide(args *Args, quo *Quotient) error &#123; if args.B == 0 &#123; return errors.New("divide by zero") &#125; quo.Quo = args.A / args.B quo.Rem = args.A % args.B return nil&#125; 服务器端调用 HTTP service： 12345678arith := new(Arith)rpc.Register(arith)rpc.HandleHTTP()l, e := net.Listen("tcp", ":1234")if e != nil &#123; log.Fatal("listen error:", e)&#125;go http.Serve(l, nil) 现在，客户端拥有了一项服务Arith，该服务提供了Arith.Multiply和Arith.Divide方法。要调用这些方法，客户端得先拨通服务器： 1234client, err := rpc.DialHTTP("tcp", serverAddress + ":1234")if err != nil &#123; log.Fatal("dialing:", err)&#125; 然后进行远程调用： 12345678// Synchronous callargs := &amp;server.Args&#123;7,8&#125;var reply interr = client.Call("Arith.Multiply", args, &amp;reply)if err != nil &#123; log.Fatal("arith error:", err)&#125;fmt.Printf("Arith: %d*%d=%d", args.A, args.B, reply) 或者 12345// Asynchronous callquotient := new(Quotient)divCall := client.Go("Arith.Divide", args, quotient, nil)replyCall := &lt;-divCall.Done // will be equal to divCall// check errors, print, etc. 服务器通常会为客户端提供一个简单的、类型安全的封装。 net/rpc包已冻结，不会增加新的功能属性。 Go举例： 一个简单的key/value存储服务器——Put(key,value), Get(key)-&gt;value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package mainimport ( "fmt" "log" "net" "net/rpc" "sync")//// RPC request/reply definitions//const ( OK = "OK" ErrNoKey = "ErrNoKey")type Err stringtype PutArgs struct &#123; Key string Value string&#125;type PutReply struct &#123; Err Err&#125;type GetArgs struct &#123; Key string&#125;type GetReply struct &#123; Err Err Value string&#125;//// Client//func connect() *rpc.Client &#123; client, err := rpc.Dial("tcp", ":1234") if err != nil &#123; log.Fatal("dialing:", err) &#125; return client&#125;func get(key string) string &#123; client := connect() args := GetArgs&#123;Key: key&#125; reply := GetReply&#123;&#125; err := client.Call("KV.Get", &amp;args, &amp;reply) //远程调用KV.Get，等待它完成，并返回其错误状态。 if err != nil &#123; log.Fatal("error:", err) &#125; client.Close() log.Println(reply.Err) return reply.Value&#125;func put(key string, val string) &#123; client := connect() args := PutArgs&#123;Key: key, Value: val&#125; reply := PutReply&#123;&#125; err := client.Call("KV.Put", &amp;args, &amp;reply) //远程调用KV.Put if err != nil &#123; log.Fatal("error:", err) &#125; client.Close()&#125;//// Server//type KV struct &#123; mu sync.Mutex data map[string]string&#125;func server() &#123; kv := new(KV) kv.data = map[string]string&#123;&#125; rpcs := rpc.NewServer() rpcs.Register(kv) l, e := net.Listen("tcp", ":1234") if e != nil &#123; log.Fatal("listen error:", e) &#125; go func() &#123; for &#123; conn, err := l.Accept() if err == nil &#123; go rpcs.ServeConn(conn) &#125; else &#123; break &#125; &#125; l.Close() &#125;()&#125;func (kv *KV) Get(args *GetArgs, reply *GetReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() val, ok := kv.data[args.Key] if ok &#123; reply.Err = OK reply.Value = val &#125; else &#123; reply.Err = ErrNoKey reply.Value = "" &#125; return nil&#125;func (kv *KV) Put(args *PutArgs, reply *PutReply) error &#123; kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value reply.Err = OK return nil&#125;//// main//func main() &#123; server() put("passwd", "2w6C*kcXWWmzK$Jg") //客户端存储密码 fmt.Println(get("passwd")) //客户端获取密码&#125;command-line-arguments2019/04/02 18:34:11 OK2w6C*kcXWWmzK$Jg 共同：必须为每种RPC类型声明Args和Reply结构 Client: connect()的Dial()创建与服务器的TCP连接 Call()要求RPC库执行远程调用 指定server function name, args,reply library marshalls args, sends request, waits, unmarshally reply Call()的返回值表示是否收到回复 usually you'll also have a reply.Err indicating service-level failure server： Go要求您声明一个带有方法的对象作为RPC处理程序(RPC handler) 然后，您使用RPC库注册该对象 您接受TCP连接，并给它们提供RPC库 RPC库 读取每个请求 为此请求创建一个新的goroutine unmarshalls request 调用命名方法（调度） marshalls reply 在TCP连接上写回复 服务器的Get()和Put()处理程序 必须锁定，因为RPC库给每个请求创建goroutines 解读args; 修改reply 线程: 线程是一种有用的结构化工具 Go称他们为goroutines;其他人称他们为线程 他们可能很棘手 Why threads? 用它们实现并发，在分布式系统中自然地出现 I / O并发： 在等待来自其他服务器的响应时，处理下一个请求 多核： 线程在多个核心上并行运行 Thread =“执行线程” 线程允许一个程序（逻辑上）一次执行许多事情 线程共享内存 each thread includes some per-thread state，包括：程序计数器，寄存器，堆栈 程序中有多少个线程？ 由结构驱动 例如每个客户端一个线程，一个用于后台任务 多核并行 one active thread per core。Go的 runtime 自动地在可用内核上调度可运行的goroutine I / O并发 数量由延迟和容量决定 继续增加直到吞吐量停止增长 Go threads are pretty cheap 100或1000是好的，但可能达不到数百万的量级 创建线程比方法调用更昂贵 Threading challenges： 共享数据 一个线程读取另一个线程正在改变的数据？例如当两个线程执行count = count + 1时，this is a &quot;race&quot; -- and is usually a bug ——使用互斥锁（或其他同步） ——或避免共享 线程之间的协调 如何等待所有Map线程完成？ ——使用Go channel或WaitGroup 并发的粒度 粗粒度(coarse-grained) —— 简单，但并发/并行很少 细粒度 —— 更多的并发、竞争(race)和死锁 什么是爬虫？ 目标是获取所有网页，例如提供给索引器(indexer) 网页形成一个图(graph) 每个页面的多个链接 graph has cycles Crawler challenges 安排I / O并发 同时获取多个URL 增加每秒获取的URL 由于网络延迟远远超过网络容量 Fetch each URL only once 避免浪费网络带宽 对远程服务器很好 需要记住访问过的URL 知道什么时候完成 Crawler solutions： 串行爬虫： fetched map 避免重复、进入死循环 它是一个单一的映射，通过递归调用传递 一次只能爬取一页 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// 串行爬虫func Serial(url string, fetcher Fetcher, fetched map[string]bool) &#123; if fetched[url] &#123; // 已经爬取 return &#125; fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; for _, u := range urls &#123; Serial(u, fetcher, fetched) &#125; return&#125;func main() &#123; Serial("http://golang.org/", fetcher, make(map[string]bool))&#125; ConcurrentMutex爬虫： 为每个页面的爬取创建一个线程，因此可以并发爬取，爬取率更高 线程共享 fetched map Why the Mutex (== lock)? 没有锁： 两个网页包含指向同一URL的链接，导致两个线程同时获取这这个页面 T1、T2检查获取[url]，当两者都看到url尚未获取，两者都取，导致错误 同时读写（或写入+写入）是竞争 如果我注释掉Lock()/Unlock()调用会发生什么？ go run crawler.go go run -race crawler.go The lock causes the check and update to be atomic How does it decide it is done? sync.WaitGroup implicitly waits for children to finish recursive fetches 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt" "sync")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with shared state and Mutextype fetchState struct &#123; mu sync.Mutex fetched map[string]bool&#125;func makeState() *fetchState &#123; f := &amp;fetchState&#123;&#125; f.fetched = make(map[string]bool) return f&#125;func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) &#123; f.mu.Lock() if f.fetched[url] &#123; // 已经爬取 f.mu.Unlock() return &#125; f.fetched[url] = true f.mu.Unlock() urls, err := fetcher.Fetch(url) if err != nil &#123; return &#125; var done sync.WaitGroup for _, u := range urls &#123; done.Add(1) go func(u string) &#123; defer done.Done() //等价于defer done.Add(-1) ConcurrentMutex(u, fetcher, f) &#125;(u) &#125; done.Wait() //等待所有的goroutine完成 return&#125;func main() &#123; ConcurrentMutex("http://golang.org/", fetcher, makeState())&#125; ConcurrentChannel爬虫 Go channel： channel是一个对象,可能有很多个, ch：= make（chan int） channel允许一个线程将对象发送到另一个线程： ch &lt; - x，sender等待goroutine接收 y：= &lt; - ch; for y := range ch，receiver等待goroutine发送 可以用channel来进行通信和同步 多个线程可以在一个channel上发送和接收 在发送时握住锁可能很危险... ConcurrentChannel master（） master()创建一个worker goroutine来获取每个页面 worker()在channel上发送URL 多个worker在一个channel上发送 master()从channel中读取URL [图：主人，通道，工人] 无需锁定 fetched map，因为它不是共享的！ 有共享数据吗？ channel 通道上发送的切片和字符串 master()传递给worker()的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( "fmt")type Fetcher interface &#123; Fetch(url string) (urls []string, err error) //由一个URL返回多个URL&#125;type fakeResult struct &#123; body string urls []string&#125;type fakeFetcher map[string]*fakeResultfunc (f fakeFetcher) Fetch(url string) ([]string, error) &#123; if res, ok := f[url]; ok &#123; fmt.Printf("found: %s\n", url) return res.urls, nil &#125; fmt.Printf("missing: %s\n", url) return nil, fmt.Errorf("not found: %s", url) //打印字符串错误&#125;var fetcher = fakeFetcher&#123; "http://golang.org/": &amp;fakeResult&#123; "The Go Programming Language", []string&#123; "http://golang.org/pkg/", "http://golang.org/cmd/", &#125;, &#125;, "http://golang.org/pkg/": &amp;fakeResult&#123; "Packages", []string&#123; "http://golang.org/", "http://golang.org/cmd/", "http://golang.org/pkg/fmt/", "http://golang.org/pkg/os/", &#125;, &#125;, "http://golang.org/pkg/fmt/": &amp;fakeResult&#123; "Package fmt", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;, "http://golang.org/pkg/os/": &amp;fakeResult&#123; "Package os", []string&#123; "http://golang.org/", "http://golang.org/pkg/", &#125;, &#125;,&#125;// Concurrent crawler with channelsfunc worker(url string, ch chan []string, fetcher Fetcher) &#123; urls, err := fetcher.Fetch(url) if err != nil &#123; ch &lt;- []string&#123;&#125; &#125; else &#123; ch &lt;- urls &#125;&#125;func master(ch chan []string, fetcher Fetcher) &#123; n := 1 fetched := make(map[string]bool) for urls := range ch &#123; for _, u := range urls &#123; if fetched[u] == false &#123; fetched[u] = true n += 1 go worker(u, ch, fetcher) &#125; &#125; n -= 1 if n == 0 &#123; break &#125; &#125;&#125;func ConcurrentChannel(url string, fetcher Fetcher) &#123; ch := make(chan []string) go func() &#123; ch &lt;- []string&#123;url&#125; &#125;() master(ch, fetcher)&#125;func main() &#123; ConcurrentChannel("http://golang.org/", fetcher)&#125; **什么时候使用sharing和locks，而不是channels？** - 大多数问题都可以用任何一种方式解决 - 最有意义的取决于程序员的想法 state(状态) -- sharing and locks communication -- channels waiting for events -- channels - 使用Go的竞争检测器： [Data Race Detector](https://golang.org/doc/articles/race_detector.html) go test -race]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>RPC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go并发模式 (Cocurrency Pattern)]]></title>
    <url>%2F2019%2F02%2F10%2F2019-2-10%2F</url>
    <content type="text"><![CDATA[这篇博客的原创来自Go的官方博客，其中提供了丰富的关于Go的并发的相关资料。本文仅仅是对 Rob Pike 的演讲 Go Concurrency Patterns 和 Sameer Ajmani 的续集 Advanced Go Concurrency Patterns 的学习，相关内容的视频和ppt在网上都可以找到。 1. 函数返回 channel# 12345678910111213141516171819202122232425262728293031323334package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(3e3)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("boring!") // 通道作为返回的函数 for i := 0; i &lt; 5; i++ &#123; fmt.Printf("You say: %q\n", &lt;-c) &#125; fmt.Println("You're boring; I'm leaving.")&#125;输出：You say: "boring! 0"You say: "boring! 1"You say: "boring! 2"You say: "boring! 3"You say: "boring! 4"You're boring; I'm leaving. 2. 通道作为服务# 12345678910111213141516171819202122func main() &#123; joe := boring("Joe") ann := boring("Ann") for i := 0; i &lt; 5; i++ &#123; fmt.Println(&lt;-joe) fmt.Println(&lt;-ann) &#125; fmt.Println("You're both boring; I'm leaving.")&#125;输出：Joe 0Ann 0Joe 1Ann 1Joe 2Ann 2Joe 3Ann 3Joe 4Ann 4You're both boring; I'm leaving. 3.多重通道(扇入函数，fan-in function)# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &#125; &#125;() return c&#125;func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; fmt.Println("You're both boring; I'm leaving.")&#125; 4. 通道发送通道，使 goroutine 有序# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( "fmt" "math/rand" "time")type Message struct &#123; str string wait chan bool&#125;func boring(msg string) chan Message &#123; c := make(chan Message) waitForIt := make(chan bool) // 被所有 Message 共享 go func() &#123; for i := 0; ; i++ &#123; c &lt;- Message&#123;fmt.Sprintf("%s: %d", msg, i), waitForIt&#125; time.Sleep(time.Duration(rand.Intn(1e3)) * time.Millisecond) &lt;-waitForIt // 进入等待 &#125; &#125;() return c&#125;func fanIn(input1, input2 chan Message) chan Message &#123; c := make(chan Message) go func() &#123; for &#123; c &lt;- &lt;-input1 &#125; &#125;() go func() &#123; for &#123; c &lt;- &lt;-input2 &#125; &#125;() return c&#125;func main() &#123; c := fanIn(boring("Joe"), boring("Ann")) for i := 0; i &lt; 5; i++ &#123; msg1 := &lt;-c fmt.Println(msg1.str) msg2 := &lt;-c fmt.Println(msg2.str) // 当 Joe 和 Ann 的信息都收到后，才开放下一次消息接收 msg1.wait &lt;- true msg2.wait &lt;- true &#125;&#125; 5. select 语句# 使用 select 来写扇入函数，减少 goroutine 数量 123456789101112func fanIn(input1, input2 &lt;-chan string) &lt;-chan string &#123; c := make(chan string) go func() &#123; for &#123; select &#123; case s := &lt;-input1: c &lt;- s case s := &lt;-input2: c &lt;- s &#125; &#125; &#125;() return c&#125; select设置超时 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( "fmt" "math/rand" "time")func boring(msg string) &lt;-chan string &#123; // 返回字符串通道，仅接收 c := make(chan string) go func() &#123; for i := 0; ; i++ &#123; c &lt;- fmt.Sprintf("%s %d", msg, i) time.Sleep(time.Duration(rand.Intn(1500)) * time.Millisecond) &#125; &#125;() return c&#125;func main() &#123; c := boring("Joe") for &#123; select &#123; case s := &lt;-c: fmt.Println(s) case &lt;-time.After(1 * time.Second): fmt.Println("You're too slow.") return &#125; &#125;&#125;输出：Joe 0Joe 1Joe 2Joe 3Joe 4You're too slow.]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL驱动]]></title>
    <url>%2F2018%2F12%2F31%2F2018-12-31%2F</url>
    <content type="text"><![CDATA[启动、以密码登入和创建数据库 windows: ubuntu: 编写Go文件 MySQL基础见菜鸟教程; 本文参考了astaxie/build-web-application-with-golang. 启动、以密码登入和创建数据库# windows:# 在bin目录下，运行(git-bash以管理员运行，加winpty) mysqld --remove 删除之前的mysql服务 mysqld -install mysql 安装windows服务，服务名称为mysql(任意取) mysqld --initialize-insecure 可无密码登陆root net start mysql 启动服务(关闭的命令是 net stop mysql) ubuntu:# service mysql start 启动服务 service mysql stop 关闭服务 service restart stop 重启服务 ps -ef | grep mysqld 查看mysql进程列表 执行如下SQL语句以密码登入 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; 或者编写 test.sql 创建 source test.sql 文件 编写Go文件# test.go 内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( "database/sql" "fmt" _ "github.com/go-sql-driver/mysql")func main() &#123; db, err := sql.Open("mysql", "root:123456@/test") //Linux用户名:MySQL密码@/数据库名test checkErr(err) stm, err := db.Prepare("DROP TABLE IF EXISTS userinfo;") //准备SQL语句，删除数据表 checkErr(err) _, err = stm.Exec() //Excute, 执行语句 checkErr(err) stm, err = db.Prepare(`CREATE TABLE userinfo ( uid INT(10) NOT NULL AUTO_INCREMENT, name VARCHAR(64) NOT NULL DEFAULT '匿名', city VARCHAR(64) NULL DEFAULT '不详', moment DATE NOT NULL DEFAULT '1949-10-10', PRIMARY KEY (uid) ) DEFAULT CHARSET=utf8;`) //创建数据表，设置utf8以支持中文字符 checkErr(err) _, err = stm.Exec() checkErr(err) //增加数据 stm, err = db.Prepare("INSERT userinfo SET name=?, city=?, moment=?") //准备SQL语句 checkErr(err) _, err = stm.Exec("诸葛亮", "山东临沂", "234-10-8") //Excute, 传入参数并执行 checkErr(err) _, err = stm.Exec("关羽", "山西运城", "220-1-1") checkErr(err) _, err = stm.Exec("荀彧", "河南许昌", "212-1-1") checkErr(err) stm, err = db.Prepare("INSERT userinfo SET city=?") checkErr(err) res, err := stm.Exec("河南禹州") id, err := res.LastInsertId() checkErr(err) fmt.Println("最后插入的用户序号为:", id) //查询数据 rows, err := db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; //删除数据 stm, err = db.Prepare("DELETE FROM userinfo WHERE uid=?") checkErr(err) res, err = stm.Exec(2) checkErr(err) fmt.Println("删除了第2行") //更改数据 stm, err = db.Prepare("UPDATE userinfo SET name=? WHERE uid=? OR uid=?") checkErr(err) res, err = stm.Exec("郭嘉", id-1, id) checkErr(err) affect, err := res.RowsAffected() checkErr(err) fmt.Println("总共有", affect, "行的信息发生了更改") //查询数据 rows, err = db.Query("SELECT * FROM userinfo") checkErr(err) fmt.Println("打印数据表的每行信息:") fmt.Println("---------------------") for rows.Next() &#123; var uid int var name string var city string var moment string err = rows.Scan(&amp;uid, &amp;name, &amp;city, &amp;moment) checkErr(err) fmt.Print(uid, " ") fmt.Print(name, " ") fmt.Print(city, " ") fmt.Println(moment) &#125; db.Close()&#125;func checkErr(err error) &#123; if err != nil &#123; panic(err) &#125;&#125; 运行结果： 进入MySQL查看数据表：]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构]]></title>
    <url>%2F2018%2F12%2F20%2F2018-12-20%2F</url>
    <content type="text"><![CDATA[3.4 顺序存储结构 3.6 链式存储结构 3.11 单链表结构与顺序存储结构 3.12 静态链表 3.13 循环链表 3.14 双向链表 4.2 栈 4.10 队列 4.12 循环队列 6.4 树的存储结构 6.5.2 特殊二叉树 6.6 二叉树性质 6.8 遍历二叉树 6.8.6 推导遍历结果 6.10 线索二叉树 6.11.1 树转换为二叉树 6.12 赫夫曼树 7.4.1 邻接矩阵(adjacency matrix) 7.4.2 邻接表 7.5.1 深度优先遍历(Depth First Search) 7.5.2 广度优先遍历(Breadth First Search) 8.4.1 二分查找 8.6 二叉查找树(Binary Sort Tree) 8.6.2 二叉查找树插入 8.6.3 二叉查找树删除 8.7 平衡二叉树(AVL树) 9.2.1 排序的稳定性 9.2.2 内排序和外排序 9.3.2 冒泡排序算法(Bubble Sort) 9.3.3 冒泡排序优化 9.4.1 简单选择排序(Simple Selection Sort) 9.5.1 直接插入排序(Straight Insertion Sort) 9.6 希尔排序(Shell Sort) 9.7 堆排序 9.8 归并排序 9.9 快速排序 3.4 顺序存储结构# 数值data(起始位置)；数组长度MaxSize；线性表长度length LOC($a_{i}$)=LOC($a_{1}$)+(i-1)c 3.6 链式存储结构# 单链表，每个节点只包含一个指针域 头指针，头节点，第一个节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( "fmt")type Node struct &#123; data string next *Node&#125;type LinkList struct &#123; length int head *Node rear *Node&#125;func NewLinkList(head *Node) *LinkList &#123; return &amp;LinkList&#123;0, head, head&#125;&#125;func (this *LinkList) Append(data string) &#123; if this.rear == nil &#123; return &#125; node := &amp;Node&#123;data: data&#125; this.rear.next = node this.rear = node this.length++&#125;func (this *LinkList) Reverse() *LinkList &#123; head := this.head if head == nil || head.next == nil &#123; return this &#125; var pre *Node = nil cur := head.next //head不为空时，当前为第1节点 this.rear = head.next //第1节点不为空时，作为最后节点 for cur != nil &#123; cur.next, pre, cur = pre, cur, cur.next //buf := cur.next //cur.next = pre //pre = cur //cur = buf &#125; head.next = pre //指向第最后一个节点 return this&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.Append("4") bl.Reverse() for node := bl.head; node != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125;&#125;&gt; Output:command-line-arguments 4 3 2 1 3.11 单链表结构与顺序存储结构# 内存分配；时间复杂度(查找，插入和删除)；空间复杂度 3.12 静态链表# 3.13 循环链表# 尾指针rear 头节点rear-&gt;next 第一个节点rear-&gt;next-&gt;next 合并： p=rearA-&gt;next q=rearB-&gt;next rearA-&gt;next=rearB-&gt;next-&gt;next rearB-&gt;next=p free(q) 3.14 双向链表# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")type Node struct &#123; data string pre *Node next *Node&#125;type BiLinkList struct &#123; length int head *Node rear *Node&#125;func NewBiLinkList(head *Node) *BiLinkList &#123; return &amp;BiLinkList&#123;0, head, head&#125;&#125;func (this *BiLinkList) Append(data string) &#123; node := &amp;Node&#123;data: data&#125; this.rear.next = node node.pre = this.rear this.rear = node this.length++&#125;func (this *BiLinkList) InsertNext(p *Node, e string) &#123; //省略判断 nd 不为空且属于链表 if p.next == nil &#123; this.Append(e) &#125; else &#123; s := &amp;Node&#123;data: e&#125; s.pre = p s.next = p.next p.next.pre = s p.next = s &#125; this.length++&#125;func main() &#123; head := &amp;Node&#123;&#125; bl := NewBiLinkList(head) bl.Append("1") bl.Append("2") bl.Append("3") bl.InsertNext(head.next.next, "2.5") //for i := 0; i &lt; bl.length; i++ &#123; // fmt.Print(head.next.data, " ") // head = head.next //&#125; for node := bl.head; node.next != nil; node = node.next &#123; fmt.Print(node.data, " ") &#125; fmt.Print(bl.rear.data) //打印末节点&#125;&gt; Output:command-line-arguments 1 2 2.5 3 使用标准库 1234567891011121314151617181920212223package mainimport ( "container/list" "fmt")func main() &#123; bl := list.New() for i := 1; i &lt; 4; i++ &#123; bl.PushBack(i) &#125; head := bl.Front() rear := bl.Back() for p := head; p != rear; p = p.Next() &#123; fmt.Print(p.Value, " ") &#125; fmt.Print(rear.Value)&#125;&gt; Output:command-line-arguments1 2 3 4.2 栈# 123依次进栈，出栈次序不可能有312(12同时在栈中,2一定先出) s-&gt;top 栈顶指针 栈顶指针为-1表示控栈 s-&gt;data[s-&gt;top]栈顶元素 12345678910111213type Stack struct &#123; //用于存放 int 的栈 nums []int&#125;func (this *Stack) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Stack) Pop() int &#123; res := this.nums[len(this.nums)-1] this.nums = this.nums[:len(this.nums)-1] return res&#125; 4.10 队列# 12345678910111213type Queue struct &#123; //Queue 是用于存放 int 的队列 nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125; 4.12 循环队列# 队列满的条件: (rear+1)%QueueSize == front 队列长度:(rear-front+QueueSize)%QueueSize 6.4 树的存储结构# 双亲表示(数组)，孩子兄弟表示(数组)，孩子表示(数组+链表) 6.5.2 特殊二叉树# 斜树，满二叉树，完全二叉树 6.6 二叉树性质# 总结点数：$n=n_{0}+n_{1}+n_{2}$ 分支线总数： $n-1=n_{1}+2n_{2}$ 完全二叉树深度：$[log_{2}n]+1$ 完全二叉树按层序排号：节点$i$的左节点为$2i$ 6.8 遍历二叉树# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func main() &#123; node9 := &amp;BinaryTree&#123;data: "I"&#125; node8 := &amp;BinaryTree&#123;data: "H"&#125; node7 := &amp;BinaryTree&#123;data: "G"&#125; node6 := &amp;BinaryTree&#123;data: "F"&#125; node5 := &amp;BinaryTree&#123;data: "E", right: node9&#125; node4 := &amp;BinaryTree&#123;"D", node7, node8&#125; node3 := &amp;BinaryTree&#123;"C", node5, node6&#125; node2 := &amp;BinaryTree&#123;data: "B", left: node4&#125; root := &amp;BinaryTree&#123;"A", node2, node3&#125; PreOrderRec(root) fmt.Println() MidOrderRec(root) fmt.Println() PostOrderRec(root)&#125;&gt; Output:command-line-argumentsA B D G H C E I F G D H B A E I C F G H D B I E F C A 6.8.6 推导遍历结果# 前序遍历序列+中序遍历序列-&gt;二叉树 后序遍历序列+中序遍历序列-&gt;二叉树 前中后：BAC ABC ACB 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package mainimport ( "fmt")type BinaryTree struct &#123; data string left *BinaryTree right *BinaryTree&#125;func PreOrderRec(bt *BinaryTree) &#123; //前序 if bt == nil &#123; return &#125; fmt.Print(bt.data, " ") PreOrderRec(bt.left) PreOrderRec(bt.right)&#125;func MidOrderRec(bt *BinaryTree) &#123; //中序 if bt == nil &#123; return &#125; MidOrderRec(bt.left) fmt.Print(bt.data, " ") MidOrderRec(bt.right)&#125;func PostOrderRec(bt *BinaryTree) &#123; //后序 if bt == nil &#123; return &#125; PostOrderRec(bt.left) PostOrderRec(bt.right) fmt.Print(bt.data, " ")&#125;func PreMid2Tree(pre, mid []string) *BinaryTree &#123; //前序+中序推导二叉树 if len(pre) != len(mid) &#123; panic("两个切片的长度不相等") &#125; if len(mid) == 0 &#123; return nil &#125; root := &amp;BinaryTree&#123; //前序第一个元素为root data: pre[0], &#125; if len(mid) == 1 &#123; return root &#125; position := IndexOf(root.data, mid) //找出root在中序的位置 root.left = PreMid2Tree(pre[1:position+1], mid[:position]) //递归 root.right = PreMid2Tree(pre[position+1:], mid[position+1:]) return root&#125;func IndexOf(ele string, seq []string) int &#123; for i, v := range seq &#123; if v == ele &#123; return i &#125; &#125; panic("IndexOf错误，元素不存在")&#125;func main() &#123; bt := PreMid2Tree([]string&#123;"A", "B", "D", "G", "H", "C", "E", "I", "F"&#125;, []string&#123;"G", "D", "H", "B", "A", "E", "I", "C", "F"&#125;) PostOrderRec(bt)&#125;&gt; Output:command-line-argumentsG H D B I E F C A 6.10 线索二叉树# 将节点的空指针改为指向在遍历序列中的前驱或后继的指针。 12345678910111213141516171819202122232425262728293031type ThreadBiTree struct &#123; data string left *ThreadBiTree right *ThreadBiTree lTag *ThreadBiTree //一个bit位，区分是指向孩子还是线索 rTag *ThreadBiTree&#125;var pre *ThreadBiTree //保存前驱func MidThreading(bt *ThreadBiTree) &#123; //中序遍历线索化 if bt == nil &#123; return &#125; MidThreading(bt.left) if bt.left == nil &#123; //若bt有左空指针，则把pre设为bt的前驱，并设置标志位 bt.left = pre bt.lTag = 1 &#125; if bt.right == nil &#123; //若bt有右空指针，则把bt设为pre的后继，并设置标志位 pre.right = bt pre.rTag = 1 &#125; pre = bt MidThreading(bt.right)&#125; 6.11.1 树转换为二叉树# 兄弟连线；只保留第一个孩子的连线 6.12 赫夫曼树# 带权路径长度(WPL)最小的二叉树 WPL(a)= 51+152+403+304+104 WPL(b)= 53+153+402+302+102 构造 排序：A5, E10, B15, D30, C40 7.4.1 邻接矩阵(adjacency matrix)# 无向图： 有向图： 有向网： 无向网的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport ( "fmt")const ( INFINITY int32 = 65536 // 无穷)type Edge struct &#123; //边的顶点和权值 v0 string v1 string weight int32&#125;type Graph struct &#123; //无向网 v []string //顶点数组 e []Edge //边的权值&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjMatrix() [][]int32 &#123; vertexNum := len(this.v) adjM := make([][]int32, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int32, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; if j == i &#123; adjM[i][j] = 0 &#125; else &#123; adjM[i][j] = INFINITY &#125; &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = edge.weight adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = edge.weight //因为是无向图所以是对称矩阵 &#125; return adjM&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D"&#125; e := []Edge&#123; Edge&#123;"A", "B", 5&#125;, Edge&#123;"A", "C", 3&#125;, Edge&#123;"A", "D", 6&#125;, Edge&#123;"B", "C", 7&#125;, Edge&#123;"C", "D", 9&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向网 fmt.Println(graph.AdjMatrix()) // A B C D //A [ 0 5 3 6 ] //B [ 5 0 7 65536 ] //C [ 3 7 0 9 ] //D [ 6 65536 9 0 ]&#125;&gt; Output:command-line-arguments[[0 5 3 6] [5 0 7 65536] [3 7 0 9] [6 65536 9 0]] 7.4.2 邻接表# 无向图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func main() &#123; v := []string&#123;"v0", "v1", "v2", "v3"&#125; e := []Edge&#123; Edge&#123;"v0", "v1"&#125;, Edge&#123;"v0", "v2"&#125;, Edge&#123;"v0", "v3"&#125;, Edge&#123;"v1", "v2"&#125;, Edge&#123;"v2", "v3"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(node.adjvex, " ") &#125; fmt.Println() &#125;&#125;&gt; Output:command-line-argumentsv0 1 2 3 v1 0 2 v2 0 1 3 v3 0 2 有向网： 7.5.1 深度优先遍历(Depth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package mainimport ( "fmt")var flag []bool //全局变量type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;func (this *Graph) AdjMatrix() [][]int &#123; vertexNum := len(this.v) adjM := make([][]int, vertexNum) //生成矩阵用两次make() for i := 0; i &lt; vertexNum; i++ &#123; //初始化 adjM[i] = make([]int, vertexNum) for j := 0; j &lt; vertexNum; j++ &#123; adjM[i][j] = 0 &#125; &#125; e := this.e v := this.v for _, edge := range e &#123; adjM[IndexOfVertex(v, edge.v0)][IndexOfVertex(v, edge.v1)] = 1 adjM[IndexOfVertex(v, edge.v1)][IndexOfVertex(v, edge.v0)] = 1 &#125; return adjM&#125;func IndexOfVertex(vs []string, v string) int &#123; for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func DFSTraverse(adjM [][]int) &#123; //输入无向图的邻接矩阵 vertexNum := len(adjM) flag = make([]bool, vertexNum) //初始化flag，注意这里不能用 := for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; for i := 0; i &lt; vertexNum; i++ &#123; //对未访问的节点执行深度搜索 if !flag[i] &#123; DFS(vertexNum, i, adjM) &#125; &#125;&#125;func DFS(vertexNum int, i int, adjM [][]int) &#123; flag[i] = true fmt.Print(i, " ") //打印被访问的节点序号 for j := 0; j &lt; vertexNum; j++ &#123; //对未被访问的邻节点递归 if adjM[i][j] == 1 &amp;&amp; !flag[j] &#123; DFS(vertexNum, j, adjM) &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjM := graph.AdjMatrix() for i := 0; i &lt; len(adjM); i++ &#123; fmt.Println(adjM[i]) &#125; fmt.Println("-------------------") DFSTraverse(adjM)&#125;&gt; Output:command-line-arguments[0 1 0 0 0 1 0 0 0][1 0 1 0 0 0 1 0 1][0 1 0 1 0 0 0 0 1][0 0 1 0 1 0 1 0 0][0 0 0 1 0 1 0 1 0][1 0 0 0 1 0 1 0 0][0 1 0 1 0 1 0 1 0][0 0 0 0 1 0 1 0 0][0 1 1 0 0 0 0 0 0]-------------------0 1 2 3 4 5 6 7 8 7.5.2 广度优先遍历(Breadth First Search)# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169package mainimport ( "fmt")type Edge struct &#123; //给定顶点定义边 v0 string v1 string&#125;type Graph struct &#123; //无向图 v []string //顶点数组 e []Edge //边数组&#125;type Node struct &#123; //邻接表的边表节点 adjvex int next *Node&#125;type Vertex struct &#123; //邻接表的顶点 data string firstedge *Node&#125;type LinkList struct &#123; //邻接表的链表 head *Vertex rear *Node&#125;type Queue struct &#123; nums []int&#125;func (this *Queue) Push(n int) &#123; this.nums = append(this.nums, n)&#125;func (this *Queue) Pop() int &#123; res := this.nums[0] this.nums = this.nums[1:] return res&#125;func (this *LinkList) Append(adjvex int) &#123; newNode := &amp;Node&#123;adjvex: adjvex&#125; if this.rear == nil &#123; this.head.firstedge = newNode &#125; else &#123; this.rear.next = newNode this.rear = newNode &#125; this.rear = newNode&#125;func IndexOfVertex(vs []string, v string) int &#123; //顶点在顶点数组的位置 for i, value := range vs &#123; if value == v &#123; return i &#125; &#125; panic("边的顶点不在顶点数组中！")&#125;func (this *Graph) AdjList() []LinkList &#123; vertexNum := len(this.v) v := this.v e := this.e adjL := make([]LinkList, vertexNum) //用一个单向链表的数组来表示邻接表 //for i := 0; i &lt; vertexNum; i++ &#123; //初始 // adjL[i].head.data = v[i] 因为此时head为nil，没有data字段 //&#125; for i := 0; i &lt; vertexNum; i++ &#123; //初始 adjL[i].head = &amp;Vertex&#123;data: v[i]&#125; &#125; for _, edge := range e &#123; i := IndexOfVertex(v, edge.v0) j := IndexOfVertex(v, edge.v1) adjL[i].Append(j) adjL[j].Append(i) &#125; return adjL&#125;func BFSTraverse(adjL []LinkList) &#123; //输入邻接表 vertexNum := len(adjL) flag := make([]bool, vertexNum) //标记被访问的节点 for i := 0; i &lt; vertexNum; i++ &#123; flag[i] = false &#125; Q := new(Queue) //队列 for i := 0; i &lt; vertexNum; i++ &#123; if !flag[i] &#123; //如果顶点未被访问 flag[i] = true Q.Push(i) for len(Q.nums) &gt; 0 &#123; //队列不为空 j := Q.Pop() fmt.Print(adjL[j].head.data, " ") //打印节点 for node := adjL[j].head.firstedge; node != nil; node = node.next &#123; if flag[node.adjvex] == false &#123; flag[node.adjvex] = true Q.Push(node.adjvex) &#125; &#125; &#125; &#125; &#125;&#125;func main() &#123; v := []string&#123;"A", "B", "C", "D", "E", "F", "G", "H", "I"&#125; e := []Edge&#123; Edge&#123;"A", "B"&#125;, Edge&#123;"A", "F"&#125;, Edge&#123;"B", "C"&#125;, Edge&#123;"B", "G"&#125;, Edge&#123;"B", "I"&#125;, Edge&#123;"F", "G"&#125;, Edge&#123;"F", "E"&#125;, Edge&#123;"C", "D"&#125;, Edge&#123;"C", "I"&#125;, Edge&#123;"G", "D"&#125;, Edge&#123;"G", "H"&#125;, Edge&#123;"E", "D"&#125;, Edge&#123;"E", "H"&#125;, &#125; graph := &amp;Graph&#123;v, e&#125; //生成无向图 adjL := graph.AdjList() for _, v := range adjL &#123; fmt.Print(v.head.data, " ") for node := v.head.firstedge; node != nil; node = node.next &#123; fmt.Print(adjL[node.adjvex].head.data, " ") &#125; fmt.Println() &#125; fmt.Println("-----------------") BFSTraverse(adjL)&#125;&gt; Output:command-line-argumentsA B F B A C G I C B D I D C G E E F D H F A G E G B F D H H G E I B C -----------------A B F C G I E D H 8.4.1 二分查找# 123456789101112131415161718192021222324252627282930313233package mainimport ( "fmt")func BiSearch(a []int, n, key int) int &#123; var low, high, mid int low = 1 high = n for low &lt;= high &#123; mid = (low + high) / 2 //mid = low + (high-low)(key-1)/(99-1) 插值 if key == a[mid] &#123; return mid &#125; else if key &lt; a[mid] &#123; high = mid - 1 &#125; else &#123; low = mid + 1 &#125; &#125; return 0&#125;func main() &#123; a := []int&#123;0, 1, 16, 24, 35, 47, 59, 62, 73, 88, 99&#125; fmt.Println(BiSearch(a, 10, 62))&#125;&gt; Output:command-line-arguments7 8.6 二叉查找树(Binary Sort Tree)# 左小右大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func SearchBST(root *BinaryTree, key int) bool &#123; if root == nil &#123; return false &#125; switch &#123; case key &lt; root.data: return SearchBST(root.left, key) case key &gt; root.data: return SearchBST(root.right, key) default: return true &#125;&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(SearchBST(root, 73), " ") fmt.Print(SearchBST(root, 99), " ") fmt.Print(SearchBST(root, 37), " ") fmt.Print(SearchBST(root, 48), " ") fmt.Print(SearchBST(root, 100))&#125;&gt; Output:command-line-argumentstrue true true false false 8.6.2 二叉查找树插入# 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func main() &#123; node10 := &amp;BinaryTree&#123;data: 37&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;data: 51&#125; node7 := &amp;BinaryTree&#123;data: 35, right: node10&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; fmt.Print(root.right.right.left.data, root.right.right.left.right, " ") _, root = InsertBST(root, 95) fmt.Print(root.right.right.left.right.data)&#125;&gt; Output:command-line-arguments93 &lt;nil&gt; 95 8.6.3 二叉查找树删除# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport ( "fmt")type BinaryTree struct &#123; data int left *BinaryTree right *BinaryTree&#125;//删除data为key的节点，并返回该二叉树的根节点。func DeleteBST(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return nil &#125; switch &#123; case key &gt; root.data: //在右子树中 root.right = DeleteBST(root.right, key) case key &lt; root.data: //在左子树中 root.left = DeleteBST(root.left, key) default: //key == root.data if root.left == nil &amp;&amp; root.right == nil &#123; //该节点为叶节点 return nil &#125; else if root.left == nil &amp;&amp; root.right != nil &#123; //该节点仅有右子树 return root.right &#125; else if root.left != nil &amp;&amp; root.right == nil &#123; //该节点仅有左子树 return root.left &#125; else &#123; //该节点有左、右子树 success := FindMin(root.right) //找到key的后继节点,即48 root.right = DeleteBST(root.right, success) root.data = success &#125; &#125; return root&#125;//找到BST中data最小的节点func FindMin(root *BinaryTree) int &#123; if root.left == nil &#123; //最小值在根节点 return root.data &#125; return FindMin(root.left) //最小值在左子树&#125;func main() &#123; node16 := &amp;BinaryTree&#123;data: 50&#125; node15 := &amp;BinaryTree&#123;data: 48&#125; node14 := &amp;BinaryTree&#123;data: 36&#125; node13 := &amp;BinaryTree&#123;data: 56&#125; node12 := &amp;BinaryTree&#123;49, node15, node16&#125; node11 := &amp;BinaryTree&#123;data: 37, left: node14&#125; node10 := &amp;BinaryTree&#123;data: 29&#125; node9 := &amp;BinaryTree&#123;data: 93&#125; node8 := &amp;BinaryTree&#123;51, node12, node13&#125; node7 := &amp;BinaryTree&#123;35, node10, node11&#125; node6 := &amp;BinaryTree&#123;data: 99, left: node9&#125; node5 := &amp;BinaryTree&#123;data: 73&#125; node4 := &amp;BinaryTree&#123;data: 47, left: node7, right: node8&#125; node3 := &amp;BinaryTree&#123;88, node5, node6&#125; node2 := &amp;BinaryTree&#123;data: 58, left: node4&#125; root := &amp;BinaryTree&#123;62, node2, node3&#125; root = DeleteBST(root, 47) NewNode := root.left.left fmt.Print(NewNode.data, " ") //打印代替删除位置的新节点 fmt.Print(NewNode.left.data, NewNode.right.data)&#125;&gt; Output:command-line-arguments48 35 51 8.7 平衡二叉树(AVL树)# 平衡因子(BF)=左子树的深度-右子树的深度 旋转： 123456789//右旋func RRotate(k2 *BinaryTree) *BinaryTree &#123; k1 := k2.left y := k1.right k1.right = k2 k2.left = y return k1&#125; 双旋转： 12345//左右旋转func LRRotate(k3 *BinaryTree) *BinaryTree &#123; k3.left = LRotate(k3.left) return RRotate(k3)&#125; 将任意二叉树一次性调整AVL 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185package mainimport ( "fmt")type BinaryTree struct &#123; data int bf int //Balance Factor left *BinaryTree right *BinaryTree&#125;//右旋func R_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.left b := a.right a.right = root root.left = b return a&#125;//左旋func L_Rotate(root *BinaryTree) *BinaryTree &#123; a := root.right b := a.left a.left = root root.right = b return a&#125;//左右旋转func LR_Rotate(root *BinaryTree) *BinaryTree &#123; root.left = L_Rotate(root.left) return R_Rotate(root)&#125;//右左旋转func RL_Rotate(root *BinaryTree) *BinaryTree &#123; root.right = R_Rotate(root.right) return L_Rotate(root)&#125;//将任意二叉树转化成AVLfunc Balance(root *BinaryTree) *BinaryTree &#123; a := &amp;BinaryTree&#123;left: root&#125; //给二叉树生成一个父母节点 _, isAVL := Bal(root) //调整二叉树的子树并判断二叉树是否平衡 for !isAVL &#123; Bal(a) //处理a的左子树，即二叉树 _, isAVL = Bal(a.left) //判断二叉树是否平衡 &#125; return a.left //返回二叉树&#125;//调整子树func Bal(root *BinaryTree) (int, bool) &#123; if root == nil &#123; return 0, true &#125; leftHeight, leftIsBalanced := Bal(root.left) rightHeight, rightIsBalanced := Bal(root.right) if !leftIsBalanced &#123; root.left = Rotate(root.left) //调整左子树 leftHeight = UpdateBF(root.left) //刷新左子树的BF和高度 &#125; if !rightIsBalanced &#123; root.right = Rotate(root.right) rightHeight = UpdateBF(root.right) &#125; root.bf = leftHeight - rightHeight //计算本身的BF if Abs(root.bf) &lt;= 1 &#123; return Max(leftHeight, rightHeight) + 1, true &#125; return Max(leftHeight, rightHeight) + 1, false&#125;//对不平衡树进行旋转调整func Rotate(root *BinaryTree) *BinaryTree &#123; if root.bf &gt; 0 &#123; //左边太重，需要右旋 if root.left.bf &lt; 0 &#123; return LR_Rotate(root) &#125; return R_Rotate(root) &#125; if root.right.bf &gt; 0 &#123; return RL_Rotate(root) &#125; return L_Rotate(root)&#125;func UpdateBF(root *BinaryTree) int &#123; if root == nil &#123; return 0 &#125; leftHeight := UpdateBF(root.left) rightHeight := UpdateBF(root.right) root.bf = leftHeight - rightHeight return Max(leftHeight, rightHeight) + 1&#125;func Max(a, b int) int &#123; if a &gt; b &#123; return a &#125; return b&#125;func Abs(a int) int &#123; if a &gt; 0 &#123; return a &#125; return -a&#125;func InsertBST(root *BinaryTree, key int) (bool, *BinaryTree) &#123; //if SearchBST(root, key) &#123; //假设不存在 // return false, root //&#125; return true, Insert(root, key)&#125;func Insert(root *BinaryTree, key int) *BinaryTree &#123; if root == nil &#123; return &amp;BinaryTree&#123;data: key&#125; //插入的本质要生成新的节点 &#125; if key &lt; root.data &#123; root.left = Insert(root.left, key) &#125; else &#123; // 没有key = root.data 的情况 root.right = Insert(root.right, key) &#125; return root&#125;func PrintBF(root *BinaryTree) &#123; if root == nil &#123; return &#125; PrintBF(root.left) fmt.Print(root.bf, " ") PrintBF(root.right)&#125;func main() &#123; root := &amp;BinaryTree&#123;data: 1&#125; InsertBST(root, 7) InsertBST(root, 2) InsertBST(root, 4) InsertBST(root, 8) InsertBST(root, 3) InsertBST(root, 10) InsertBST(root, 5) InsertBST(root, 9) InsertBST(root, 6) UpdateBF(root) PrintBF(root) //二叉树的BF fmt.Println() PrintBF(Balance(root)) //平衡调整后的二叉树的BF&#125;&gt; Output:command-line-arguments-5 -3 0 -1 -1 0 1 -2 0 1 0 0 0 -1 -1 0 0 0 0 0 9.2.1 排序的稳定性# 9.2.2 内排序和外排序# 内排序是在排序的整个过程中，待排序的所有记录全部在内存中。外排序的整个过程则需要在内外存之间交换数据。 9.3.2 冒泡排序算法(Bubble Sort)# 冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改 变，所以冒泡排序是一种稳定排序算法。 12345678910111213141516171819202122232425262728package mainimport ( "fmt")package mainimport ( "fmt")func BubbleSort(a []int) &#123; length := len(a) for i := 1; i &lt; length-1; i++ &#123; //需要交换(length-2)次，从后往前排 for j := 1; j &lt; length-i; j++ &#123; //当i=1时，j可以取到(length-2) if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort(a) fmt.Println(a)&#125; 递归实现. for 循环找出最大值排到末尾，去掉末尾把对新的序列递归 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot;)func RecurBubble(a []int) &#123; length := len(a) if length &lt; 3 &#123; //递归跳出条件 return &#125; for j := 1; j &lt;= length-2; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] &#125; &#125; a = a[0 : length-1] //不包括第 length-1 个元素 RecurBubble(a)&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; RecurBubble(a) fmt.Println(a)&#125; 9.3.3 冒泡排序优化# 123456789101112131415161718192021222324252627package mainimport ( "fmt")func BubbleSort2(a []int) &#123; flag := true // 有数据交换 length := len(a) for i := 1; i &lt; length-1 &amp;&amp; flag; i++ &#123; flag = false for j := 1; j &lt; length-i; j++ &#123; if a[j] &gt; a[j+1] &#123; a[j], a[j+1] = a[j+1], a[j] flag = true &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; BubbleSort2(a) fmt.Println(a)&#125; 9.4.1 简单选择排序(Simple Selection Sort)# 复杂度与冒泡排序同为$O(n^{2})$,但性能更优(数据交换次数更少)。选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; var min int length := len(a) for i := 1; i &lt; length-1; i++ &#123; //插入次数(length-2)，从前往后排；把后面序列中较小的数插 min = i // 循环找出序列中的最小数的下标 for j := i + 1; j &lt; length; j++ &#123; //j取到i后的所有数 if a[j] &lt; a[min] &#123; //之后有更小的数 min = j &#125; &#125; if i != min &#123; //下标改变，交换，防止数据丢失 a[i], a[min] = a[min], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 反过来排 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot;)func SelectionSort(a []int) &#123; var max int length := len(a) for i := length - 1; i &gt; 0; i-- &#123; 从大到小排 max = i for j := 1; j &lt; i; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != i &#123; a[i], a[max] = a[max], a[i] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 递归 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt")func SelectionSort(a []int) &#123; length := len(a) if length &lt; 3 &#123; return &#125; max := length - 1 for j := 1; j &lt; length-1; j++ &#123; if a[j] &gt; a[max] &#123; max = j &#125; &#125; if max != length-1 &#123; a[length-1], a[max] = a[max], a[length-1] &#125; SelectionSort(a[:length-1])&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; SelectionSort(a) fmt.Println(a)&#125; 9.5.1 直接插入排序(Straight Insertion Sort)# 插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开 始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳 定的。 复杂度同为为$O(n^{2})$，性能：插入排序&gt;选择排序&gt;冒泡排序 123456789101112131415161718192021222324252627package mainimport ( "fmt")func InsertionSort(a []int) &#123; length := len(a) var j int for i := 2; i &lt; length; i++ &#123; //第二个数到最后一个数 if a[i] &lt; a[i-1] &#123; //第i个数比前面的数小，需要插入 a[0] = a[i] //哨兵 for j = i - 1; a[j] &gt; a[0]; j-- &#123; //j取 i-1 到 1 a[j+1] = a[j] //将大于第i个数的数后移一位，留出空位 &#125; a[j+1] = a[0] //将第i个数放入空位 &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; InsertionSort(a) fmt.Println(a)&#125; 9.6 希尔排序(Shell Sort)# 希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 12345678910111213141516171819202122232425262728293031package mainimport ( "fmt")func ShellSort(a []int) &#123; var i, j int length := len(a) - 1 //去掉第0位 inc := length //增量 for inc &gt; 1 &#123; inc = inc/3 + 1 for i = 1 + inc; i &lt;= length; i++ &#123; //第(1+inc)个数到最后一个数 if a[i] &lt; a[i-inc] &#123; a[0] = a[i] for j = i - inc; j &gt; 0 &amp;&amp; a[j] &gt; a[0]; j -= inc &#123; a[j+inc] = a[j] &#125; a[j+inc] = a[0] &#125; &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; ShellSort(a) fmt.Println(a)&#125; 9.7 堆排序# 时间复杂度$O(nlogn)$ 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func HeapSort(a []int) &#123; length := len(a) - 1 //循环后a[1]为最大值 for i := length / 2; i &gt; 0; i-- &#123; //(length/2)是最后一个节点的父节点到根节点 HeapAdjust(a, i, length) &#125; for i := length; i &gt; 1; i-- &#123; //从最后节点到第二个节点 a[1], a[i] = a[i], a[1] //排序第i位 HeapAdjust(a, 1, i-1) //将1到i-1中的最大数放到a[1] &#125;&#125;func HeapAdjust(a []int, s, m int) &#123; var temp, j int temp = a[s] for j = 2 * s; j &lt;= m; j *= 2 &#123; //以s为父节点开始 if j &lt; m &amp;&amp; a[j] &lt; a[j+1] &#123; //取出较大的孩子节点 j = j + 1 &#125; if temp &gt;= a[j] &#123; //父节点已经最大 break &#125; a[s] = a[j] //将最大的值替换给父节点 s = j //将当前节点作为父节点，进行下一轮操作 &#125; a[s] = temp&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 2&#125; HeapAdjust(a, 1, 9) fmt.Println(a)&#125; 9.8 归并排序# 归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有 序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结 果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 递归方法 Merge()归并排序示意图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt")// 将a排序到bfunc MergeSort(a []int) []int &#123; length := len(a) b := make([]int, length) MSort(a, b, 1, length-1) return b&#125;func MSort(a, b []int, s, t int) &#123; if s == t &#123; b[s] = a[s] //将a复制到到b &#125; else &#123; m := (s + t) / 2 MSort(a, b, s, m) MSort(a, b, m+1, t) Merge(b, s, m, t) //将b归并排序 &#125;&#125;func Merge(SR []int, i, m, n int) &#123; TR := make([]int, len(SR)) //归并的序列暂存到TR s := i //保存起始位置 j := m + 1 k := i //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p] &#123; SR[p] = TR[p] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16&#125; fmt.Println(MergeSort(a))&#125; 非递归方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "fmt")func MergeSort2(a []int) &#123; length := len(a) - 1 for k := 1; k &lt; length; &#123; MergePass(a, k, length) k = k * 2 &#125;&#125;func MergePass(a []int, s, n int) &#123; i := 1 for i &lt;= n-2*s+1 &#123; Merge2(a, i, i+s-1, i+2*s-1) //i+2*s-1&lt;=n i = i + 2*s &#125; if i &lt; n-s+1 &#123; //n&gt;i+s-1,归并最后两个子块 Merge2(a, i, i+s-1, n) &#125;&#125;func Merge2(SR []int, i, m, n int) &#123; TR := make([]int, n-i+1) //与Merge相比栈空间更小 s := i //保存起始位置 j := m + 1 k := 0 //TR序号 for i &lt;= m &amp;&amp; j &lt;= n &#123; if SR[i] &lt; SR[j] &#123; TR[k] = SR[i] i++ &#125; else &#123; TR[k] = SR[j] j++ &#125; k++ &#125; if i &lt;= m &#123; for l := 0; l &lt;= m-i; l++ &#123; TR[k+l] = SR[i+l] &#125; &#125; if j &lt;= n &#123; for l := 0; l &lt;= n-j; l++ &#123; TR[k+l] = SR[j+l] &#125; &#125; for p := s; p &lt;= n; p++ &#123; //将排好序的TR写回到SR if SR[p] != TR[p-s] &#123; SR[p] = TR[p-s] &#125; &#125;&#125;func main() &#123; a := []int&#123;0, 9, 1, 5, 8, 3, 7, 4, 6, 5, 16, 3, 41, 7, 55, 21&#125; MergeSort2(a) fmt.Println(a)&#125; 9.9 快速排序# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport ( "fmt")func QuickSort(a []int) &#123; Qsort(a, 1, len(a)-1)&#125;func Qsort(a []int, low, high int) &#123; if low &lt; high &#123; pivot := Partition(a, low, high) Qsort(a, low, pivot-1) Qsort(a, pivot+1, high) &#125;&#125;func Partition(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low], a[high] = a[high], a[low] //将a[hign]放到pivoValue左边 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[low], a[high] = a[high], a[low] //将a[low]放到pivoValue右边 &#125; return low&#125;func Partition2(a []int, low, high int) int &#123; pivotValue := a[low] for low &lt; high &#123; for pivotValue &lt;= a[high] &#123; //找出a[high]&lt;pivotValue high-- &#125; a[low] = a[high] //将a[hign]放到较低的位置 for low &lt; high &amp;&amp; pivotValue &gt;= a[low] &#123; //找出a[low]&gt;pivotValue low++ &#125; a[high] = a[low] //将a[low]放到较高的位置 &#125; a[low] = pivotValue return low&#125;func main() &#123; a := []int&#123;0, 50, 10, 90, 30, 70, 40, 80, 60, 20&#125; QuickSort(a) fmt.Println(a)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go内存模型]]></title>
    <url>%2F2018%2F11%2F14%2F2018-11-14%2F</url>
    <content type="text"><![CDATA[1. 什么是 Go内存模型？ 2. Happens Before 3. Synchronization 3.1 Initialization 3.2 Goroutine creation 3.3 Goroutine destruction 3.4 Channel communication 3.5 Locks 3.6 Once 4. Incorrect synchronization 本文主要翻译自官方文档 The Go Memory Model 1. 什么是 Go内存模型？# 我们知道不同的 goroutine 可以对同一个变量进行读写操作。Go内存模型指定了在什么样的条件下可以保证一个 goroutine 写入到变量的值可以被另外一个 goroutine 正确的读取。 2. Happens Before# 在单个 goroutine 中，读、写操作按照程序设计的顺序进行。需要注意的是，在不改变 goroutine 程序行为的前提下，这些读、写顺序在编译的过程中可能会被重排。因此导致对相同变量的读、写操作在不同的 goroutine 看来执行顺序可能不同。例如，如果在某个 goroutine 中执行 a = 1; b = 2;，另一个 goroutine 可能观察到变量 b 比 a 先被赋值。 Happens Before 是针对Go语言编程中内存操作的一种局部排序。 如果 $e_{1}$ happens before $e_{2}$，那么也可以说 $e_{2}$ happens after $e_{1}$。进一步，如果 $e_{1}$ 既不 happens before $e_{2}$，也不 happens after $e_{2}$，那么我们称 $e_{1}$ 和 $e_{2}$ happen concurrently (并发)。 在单个 goroutine 中，Happens Before顺序就是程序设计的顺序 $v$：某个变量 $w$: 对$v$的写 $w'$: 对$v$的写，不同于$w$ $r$: 对$v$的读 $w$可以被$r$获取的条件： $r$ 不 happen before $w$. (包括 happen after 和 happen concurrently) 不存在另一个 $w'$ happens after $w$ but before $r$. $w$保证能被$r$获取的条件(该条件不允许$w'$与$w$或者$r$并发，因此比上面的条件更强): $w$ happens before $r$. 任何其它的 $w'$ 要么 happens before $w$，要么 happens after $r$. 当有多个 goroutine 可以访问$v$时，必须利用同步事件(synchronization events)来建立 happens before 以保证 $r$能够获取想要的$w$。 在初始化过程中，赋给$v$以其类型的零值的操作可以看作是内存模型中的一种$w$ 3. Synchronization# 3.1 Initialization# 程序的初始化在一个 goroutine 中进行，并且在该 goroutine 中还可以创建其它的 goroutine 如果包 $p$导入了包$q$，那么包$q$在被导入之前就完成了初始化，函数main.main在所有的init函数完成后开始执行，见astaxie的main函数和init函数一文 3.2 Goroutine creation# 启动一个新的 goroutine 的 Go声明发生在该 goroutine开始执行之前 12345678910111213141516package mainvar a stringfunc f() &#123; print(a)&#125;func hello() &#123; a = "hello, world" go f()&#125;func main() &#123; hello()&#125; 调用hello()将会在未来某个时间点( 可能在hello()返回之后 )打印hello, world 3.3 Goroutine destruction# 无法保证 goroutine 在其创建程序中的某个位置退出 123456var a stringfunc hello() &#123; go func() &#123; a = "hello" &#125;() print(a)&#125; 对 a 的写(赋值)没有进行任何同步操作，无法被其它 goroutine 获取，在激进的编译器中甚至可能会删除整个 go 声明。 3.4 Channel communication# 通道通信(channel communication)是同步两个 goroutine 的主要方法。 send 发生在完成相应的 receive 之前 程序： 12345678910111213141516var c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" c &lt;- 0 // send&#125;func main() &#123; go f() &lt;-c // receive print(a)&#125;&gt; Output:command-line-argumentshello, world 会保证打印 hello, world，因为： 对 a 的写 happens before 通道 c 的 send 通道 c 的 send happens before 通道 c 的 receive 通道 c 的 receive happens before print(a)，因此 , 对 a 的写 happens before print(a), 即保证 main() 获取了 goroutine 对 a的写 channel 的关闭发生在完成 receive(此时得到的是通道类型的零值)之前 123456789101112131415161718package mainvar c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" close(c) // 关闭&#125;func main() &#123; go f() print(a, "\n", &lt;-c) // receive&#125;&gt;Output:command-line-argumentshello, world0 无缓存通道的 receive 发生在完成 send 之前 调换 c &lt;- 0 // send 和 &lt;-c // receive的位置，得到程序 123456789101112131415var c = make(chan int)var a stringfunc f() &#123; a = "hello, world" &lt;-c //receive&#125;func main() &#123; go f() c &lt;- 0 // send print(a)&#125;&gt; Output:command-line-argumentshello, world 仍然保证打印 hello, world 但如果channel具有缓存，例如当c = make(chan int, 1)，那么程序无法保证打印 hello, world 当通道的容量为$c$时，第 $k$ 次 receive 发生在完成第 $k+c$ 次 send 之前 下面的程序给 work 的每个条目(函数类型)启动一个 goroutine，由于通道limit的容量为3，因此最多允许3个 goroutine 调用调用了函数w() 1234567891011var limit = make(chan int, 3)func main() &#123; for _, w := range work &#123; go func(w func()) &#123; limit &lt;- 1 w() &lt;-limit &#125;(w) &#125;&#125; 3.5 Locks# sync 包实现了两种 lock 数据类型, sync.Mutex和 sync.RWMutex. 对任意的 sync.Mutex 或者 sync.RWMutex变量 l且$n&lt;m$，第$n$次调用 l.Unlock() 发生在 第 $m$次调用 l.Lock()返回之前 程序 1234567891011121314151617181920212223package mainimport ( "sync")var l sync.Mutexvar a stringfunc f() &#123; a = "hello, world" l.Unlock() //第一次 l.Unlock()&#125;func main() &#123; l.Lock() go f() l.Lock() //第二次 l.Lock() print(a)&#125;&gt; Output:command-line-argumentshello, world 保证打印hello, world，因为， 第一次 l.Unlock() happens before 第二次 l.Lock() 返回 第二次 l.Lock() 返回 happens before print(a) 对于任意的l.RLock，存在$k$满足： 第 $k$ 次调用 l.Unlock happens before l.RLock； 与l.RLock对应的l.RUnlock happens before 第 $k+1$次调用 l.Lock 3.6 Once# 对某个函数f()，可以有多个线程通过once.Do(f)来对其调用，但仅有线程能够调用执行函数f()，其它的调用会被阻塞知道f()返回。 程序 123456789101112131415161718192021222324252627282930313233package mainimport ( "sync" "time")var a stringvar once sync.Oncefunc setup() &#123; a = "hello, world"&#125;func SETUP() &#123; a = "HELLO, WORLD"&#125;func doprint() &#123; once.Do(setup) //注意不要括号 once.Do(SETUP) print(a, "\n")&#125;func main() &#123; go doprint() go doprint() time.Sleep(time.Second)&#125;&gt; Output:command-line-argumentshello, worldhello, world 会打印两次 hello, world，但是仅在第一次调用 doprint 时执行了 setup 4. Incorrect synchronization# 程序 12345678910111213141516171819202122232425package mainvar a, b intfunc f() &#123; a = 1 b = 2&#125;func g() &#123; print(b, "\n") print(a)&#125;func main() &#123; go f() g()&#125;&gt; Output: //大多数输出结果00&gt; Output: //少数输出结果01 也可能先打印2，然后打印0 程序 1234567891011121314151617181920212223242526272829303132package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world \n" done = true&#125;func doprint() &#123; if !done &#123; setup() &#125; print(a)&#125;func twoprint() &#123; go doprint() go doprint()&#125;func main() &#123; twoprint()&#125;//有3种输出的可能&gt; Output:hello, world hello, world &gt; Output:hello, world &gt; Output: 下面的程序，由于不能保证main()先获取对done的写，因此print()可能打印空字符串。甚至main()完全没有获取对done的写，此时main()进入死循环 12345678910111213141516171819202122232425package mainvar a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; print(a)&#125;&gt; Output:hello, world&gt; Elapsed: 3.703s //等待了较长的时间&gt; Result: Success&gt; Output:hello, world&gt; Elapsed: 0.704s &gt; Result: Success 类似的程序如下 1234567891011121314151617181920package maintype T struct &#123; msg string&#125;var g *Tfunc setup() &#123; t := new(T) t.msg = "hello, world" g = t&#125;func main() &#123; go setup() for g == nil &#123; &#125; print(g.msg)&#125;]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建IPFS 私有网络]]></title>
    <url>%2F2018%2F11%2F05%2F2018-11-5%2F</url>
    <content type="text"><![CDATA[在servers上安装 Go 环境 生成 ifps 节点 创建共享密钥 添加启动节点 启动私有网络 本例为建立包含三个节点的IPFS私有网络，节点分别为： server a: root@45.32.28.71 server b: root@207.148.109.110 本地 mac 在servers上安装 Go 环境# 1234567891011cd ~ $wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz$tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz //解压到得到的 go 目录，放到 /usr/local 目录下$vim .bashrcexport GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN$source .bashrc$go version go version go1.11.2 linux/amd64 //安装成功 mac 上的安装类似。 生成 ifps 节点# 在三台机器上执行 12345678910111213141516171819202122232425262728$go get -u -d github.com/ipfs/go-ipfs $cd $GOPATH/src/github.com/ipfs/go-ipfs$make installCommand &apos;make&apos; not found, but can be installed with:sudo apt install makesudo apt install make-guile$apt update \\ 需要安装 make ， 先检查安装包...$apt upgrade \\ 更新安装包...$apt install make \\ 安装 make...$make install/usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exec: &quot;gcc&quot;: executable file not found in $PATHcmd/ipfs/Rules.mk:37: recipe for target &apos;cmd/ipfs-install&apos; failedmake: *** [cmd/ipfs-install] Error 2$apt install gcc...$gcc -v...gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)$make install...$ipfs init... 记下每个节点的ID，比如本例 server a 的ID: QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 server b 的ID: QmRyxoe9JpkDZuMK4G7PkXUy7nGv8VdM98d6Vr2wxFSa3V mac 的ID: QmWKKVUy9XqWEGhrikJW8ugHuFzKJJGP5DCGFyvzUJFjzL 创建共享密钥# 先在任意一台机器上创建密钥，然后拷贝到剩余节点。本例在mac上创建 12$go get -u github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen$ipfs-swarm-key-gen &gt; ~/.ipfs/swarm.key 手动拷贝 1$vim ~/.ipfs/swarm.key \\ 打开swarm.key, 拷贝内容 在servers上新建swarm.key 1$vim ~/.ipfs/swarm.key \\ 将拷贝的内容粘贴 使用 scp 命令 12$scp ~/.ipfs/swarm.key root@45.32.28.71:~/.ipfs/$scp ~/.ipfs/swarm.key root@207.148.109.110:~/.ipfs/ 添加启动节点# pfs init后的默认启动节点是连接ipfs公网的节点。建立私有网络需要在每一个节点上删掉默认启动节点 1$ipfs bootstrap rm --all 将网络中任意其他节点作为启动节点。例如将 server a 作为mac的启动节点 1$ipfs bootstrap add/ip4/45.32.28.71/tcp/4001/ipfs/QmQ9RjTGVDjhZ2kRVx9tjL4CciiKdNrQzknSyUnCMmB3m2 启动私有网络# 给三个节点添加了启动节点后，启动所有节点，便建立起了含有三个节点的IPFS私有网络。分别执行 1$ipfs daemon 可以使用 bootstrap list```查看节点所包含的启动节点，使用```ipfs swarm peers```查看节点连接了哪些其他节点。使用```ipfs add file```上传文件到节点，比如给mac节点上传pdf文件，并得到该文件的ID12```$ipfs add ~/files/GO语言编程.pdf 该文件的ID：QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi。现在与mac建立了连接的server就可以下载该文件了，在server上执行 1$ipfs get QmRDqZoSMCLMP2GH66MKKnduqgTqKBfqNeysPugp9xadUi \\在当前目录会多出一个新的文件便是get到的文件]]></content>
      <tags>
        <tag>IPFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A Study for the Reed-Solomon Code]]></title>
    <url>%2F2018%2F10%2F18%2F2018-10-18%2F</url>
    <content type="text"><![CDATA[Introduction Galois Field Galois Field Arithmetic Addition and Subtraction Multiplication and Division RS Code Coding Matrix Method Generator Polynomial Method RS Code in Distributed Storage Systems 5.1 Rotated Reed-Solomon code Local Reconstruction Code (LRC) References Introduction# Reed-Solomon (RS) code is an error-correcting code first proposed by Reed and Solomon in 1960, which is the most frequently applied digital error correction code around the word. The applications include data storage(hard drives, CD/DVD/Blue Ray), data transmission and common commercial activities(bar codes, QR codes) . RS code has the advantage of high capability of correcting random or burst errors since it encodes groups of bits instead of one bit at a time. Redundant datas are generated so that the original data can be reconstructed with part of the stored or received data loss. People often back up important files which can be regarded as kind of data loss protection with redundant data. However, backup is just a copy of the original datas while the redundant data generated in the RS code is a fusion of the all the original data parts, which is more efficient for storage and error correction. In this article, I have run through the procedure of the RS code and hope it is usefull for you to understand what is going on with this erasure code. Its application in the distributed strorage system are briefly introduced at the end. Part of implementations in pure Go are also provided whose source files can be found on the Githup website . Galois Field# The finite field is also called Galois field which has finite elements and the property that arithmetic operations on field elements always have a result in the field. In the sequel, we illustrate two kind of representations of the finite elements and its arithmetic operations. Proposition 1. For any prime $ p $ and any natual number$ r $ there exists a finite field with $ p^{r} $ elements and vice versa. With the proposition 1, the Galois Field is denoted as $ GF(p^{r}) $. In fact, the nature of RS encoding is mapping $ k $ elments of $ GF(2^{r}) $ into another $ n $ elements of $ GF(2^{r}) $ and $k+2\leq n\leq 2^{r} $. This Galois fields can be represented with the help of $ \mathbf{Z}{2}[x] $, the set of polynomials with coefficients in the field of two elements $ \mathbf{Z}{2} $, namely the polynomial representation as $$0,1,x,x+1,x{2},..,x{r-1}+x^{r-2}+...+1 \tag{1}$$ This representation can also be seen as a $r$-bit digit or binary vector. Proposition 2. $ GF(q) $ has cyclic the multiplicative group $ {\alpha, \alpha{2},...,\alpha{q-1}=1}$, where $ \alpha $ is the primitive element. Thus, $ GF(2^{r}) $ has the exponential representation as $$0, 1(=\alpha^{255}), \alpha, \alpha^{2},..., \alpha{2{r}-2} \tag{2}$$ which is a better choice for the '$ \times $' and '$ / $' operation. Even a binary matrix can be used to represente the elements. For example, we can establish a bijection between the vector representation and matrix representation over $ GF(2^{4}) $ as follows where the first column is the vector representation and the columns satisfy $column(i)=2\times column(i-1)$. This matrix representation transforms arithmetic over $ GF(2^{4}) $ into arithmetic over $ GF(2) $ which only has XOR, AND operations. Galois Field Arithmetic# In this section, we discuss arithmetic in $ GF(2^{8}) $, whose element corresponds a byte data. Addition and Subtraction# Addition and subtraction are operated under the polynomial representation (also a byte in $ GF(2^{8}) $) and both are equivalent to XOR operation 1234567func galAdd(a, b byte) byte &#123; return a ^ b&#125;func galSub(a, b byte) byte &#123; return a ^ b&#125; Multiplication and Division# The multiplication is operated with the exponential representation $(2)$, before that we should establish a bijection (injection and surjection) between the two representations. Suppose $$\alpha^{i} -&gt; 2^{i}$$ where $0\leq i \leq 2^{8}-2=254$. According to proposition 2, $\forall j\geq 255,\alpha{j}=\alpha{j-255}$. Proposition 3.$ GF(2^{8}) $ has the irreducible polynomial $ f(x)=x{8}+x{4}+x{3}+x{2}+1 $ which has no factors of smaller polynomials. The irreducible polynomial is necessary to establish the bijection since some $2^{i}$ term are no longer in $GF(2^{8})$. Let $ f(\alpha) =0$, we have $$\alpha{8}=\alpha{4}+\alpha{3}+\alpha{2}+1=2{4}+2{3}+2^{2}+1=00011101$$ or 0x1d . For convenience, we record the bijection with a table, namely called exponent table, whose indexs is the exponents of elements in exponential representation and value is elements in byte representation. 1var expTable = [255]byte&#123;0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, ..., 0x8e&#125; Use logTable[expTable[$i$]]=$i$, the logarithmic table is generated, 12345var logTable = []byte&#123; 0, 0, 1, 25, 2, 50, 26, 198, ... 116, 214, 244, 234, 168, 80, 88, 175,&#125; With these tables, the $\times$ and $/$ functions in $GF(2^8)$ are easily defined, 12345678910111213141516171819202122232425262728293031func galMultiply(a, b byte) byte &#123; if a == 0 || b == 0 &#123; return 0 &#125; logA := int(logTable[a]) logB := int(logTable[b]) sum := logA+logB if sum&gt;254 &#123; sum -= 255 &#125; return expTable[sum]&#125;func galDivide(a, b byte) byte &#123; if a == 0 &#123; return 0 &#125; if b == 0 &#123; panic("Argument 'divisor' is 0") &#125; logA := int(logTable[a]) logB := int(logTable[b]) logResult := logA - logB if logResult &lt; 0 &#123; logResult += 255 &#125; return expTable[logResult]&#125; Based on the result above, the power and inverse functions can be further obtained. In fact, the method to establish the bijection is not unique. The original paper of Reed and Solomon in 1960 provides another method with finite difference equation which has better computability. RS Code# Coding Matrix Method# 1. Orignal approach: For arbitrary $ k $ 8-bit symbols,$ m_{0}$, $m_{1}$, $...$, $m_{k-1} $, we have the message polynomial $$m(x)=m_{0}+m_{1}x+...+m_{k-1}x^{k-1},$$ with this $ m(x) $, $ 2^{8} $ codewords, i.e. $ m(0)$,$m(1)$,$...$, $m(\alpha^{r-2}) $ are obtained and the the encoded messages, which will be transmitted or stored, are $ n $ of the codewords (professionally called stripe). Using linear algebra, the stripe are denoted collectively as follows $$ \begin{bmatrix} m(\alpha_{1})\ m(\alpha_{2})\ ...\ m(\alpha_{n}) \end{bmatrix} = \begin{bmatrix} 1 &amp; \alpha_{1} &amp; ... &amp; \alpha_{1}^{k-1} \ 1 &amp; \alpha_{2} &amp; ...&amp;\alpha_{2}^{k-1} \ ... &amp; ... &amp; ...&amp;... \ 1 &amp; \alpha_{n} &amp; ...&amp;\alpha_{n}^{k-1} \end{bmatrix} \begin{bmatrix} m_{0}\ m_{1}\ ...\ m_{k-1} \end{bmatrix}\tag{3} $$ Note that we only discuss one byte a shard (the messages are splited into multiple shards for encoding) here, in practice one input shard contains thousands of bytes, in this case the output shard contains same size of byte as input shard and the vectors in $(3)$ becomes matrice. Coding procedure : 1.Split the whole message into same size data shards; 2. Build the Vandermonde matrix (coding matrix); 3. Multiplies the coding matrix by data shards to produce code shards. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (r reedSolomon) Split(data []byte) ([][]byte, error) &#123; if len(data) == 0 &#123; return nil, ErrShortData &#125; // Calculate number of bytes per data shard. perShard := (len(data) + r.DataShards - 1) / r.DataShards if cap(data) &gt; len(data) &#123; data = data[:cap(data)] &#125; // Only allocate memory if necessary if len(data) &lt; (r.Shards * perShard) &#123; // Pad data to r.Shards*perShard. padding := make([]byte, (r.Shards*perShard)-len(data)) data = append(data, padding...) &#125; // Split into equal-length shards. dst := make([][]byte, r.Shards) for i := range dst &#123; dst[i] = data[:perShard] data = data[perShard:] &#125; return dst, nil&#125;func vandermonde(rows, cols int) (matrix, error) &#123; result, err := newMatrix(rows, cols) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; for c := range row &#123; result[r][c] = galExp(byte(r), c) &#125; &#125; return result, nil&#125;// Multiplies a subset of rows from a coding matrix by a full set of// input shards to produce some output shards.// 'matrixRows' is The rows from the matrix to use.// 'inputs' An array of byte arrays, each of which is one input shard.// The number of inputs used is determined by the length of each matrix row.// outputs Byte arrays where the computed shards are stored.func (r reedSolomon) codeSomeShards(matrixRows, inputs, outputs [][]byte) &#123; for c := 0; c &lt; r.DataShards; c++ &#123; in := inputs[c] for iRow := 0; iRow &lt; outputCount; iRow++ &#123; if c == 0 &#123; galMulSlice(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; else &#123; galMulSliceXor(matrixRows[iRow][c], in, outputs[iRow], r.o.useSSSE3, r.o.useAVX2) &#125; &#125; &#125;&#125; Since any $ k $ rows of Vandermonde matrix are linearly independent, with arbitrary $ k $ correct code shards, the original $ k $ data shards can be reconstructed by multiplying the corresponding inverse matrix. However, in practice, we usually do not know which one is correct or corrupted for the $ n $ received codewords. In this case, the plurality of votes method is necessary and $$ \left(\begin{array}{c} n-s\k \end{array} \right)&gt;\left(\begin{array}{c} s+k-1\k \end{array} \right) $$ or $$ s&lt;\frac{n-k+1}{2} $$ where $s$ is number of unkown errors, therefore $ n=k+2s $ always satisfies the in-equation. Another approach is to use the Berlekamp-Welsh Algorithm which avoids the heavy computation of votes: Berlekamp-Welsh decoder: 1. Send $m(0),m(1),...,m(n)$, receive $m'(0),m'(1),...,m'(n)$, and most $s$ of them such that $m(i)\neq m'(i)$； 2. $E(x)=x{s}+b_{s-1}x{s-1}+...+b_{0}$, $Q(x)=a_{k+s-1}x{k+s-1}+a_{k+s-2}x{k+s-2}+...+a_{0}$ 3. Solve the coefficients of co$E(x)$,$Q(x)$ with $ Q(i)=m'(i)E(i)$ 4. Derive $m(x)=Q(x)/E(x)$. And $\forall m(i)\neq m'(i)$,$E(i)=0$. The implicite principle: $Q'(x)/E'(x)$ and $Q(x)/E(x)$ agree on at least $k+s$ points. $E'(x)$ and $E(x)$ both have at most $s$ zero points. Elimilate $E'(x)$ and $E(x)$,$Q'(x)/E'(x)$ and $Q(x)/E(x)$ are degree at least $k-1$ and agree on at least $k$ points, thus $Q'(x)/E'(x)=Q(x)/E(x)=m(x)$. 2. Systematic coding matrix: In the original approach, all the code shards have been encoded. While in the systematic encoding, the original data shards become part of the code shards and only the parity shards should be encoded. In other words, the stripe contains the original datas and parity codewords together no longer codewords only. The coding matrix is composed of the top square identity matrix and the parity matrix. There are three methods of building the coding matrix in this systematic way are provided: Elementary transform on the Vandermonde matrix as the procedure 1. 123456789101112131415161718func buildMatrix(dataShards, totalShards int) (matrix, error) &#123; vm, err := vandermonde(totalShards, dataShards) if err != nil &#123; return nil, err &#125; top, err := vm.SubMatrix(0, 0, dataShards, dataShards) if err != nil &#123; return nil, err &#125; topInv, err := top.Invert() if err != nil &#123; return nil, err &#125; return vm.Multiply(topInv)&#125; Parity matrix is Vandermonde matrix. 1234567891011121314151617181920func buildMatrixPAR1(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Vandermonde // matrix starting at 1 instead of 0. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = galExp(byte(c+1), r-dataShards) &#125; &#125; &#125; return result, nil&#125; Parity matrix is Cauchy matrix. Cauchy matrices are easier to invert than general matrices [8]. 12345678910111213141516171819func buildMatrixCauchy(dataShards, totalShards int) (matrix, error) &#123; result, err := newMatrix(totalShards, dataShards) if err != nil &#123; return nil, err &#125; for r, row := range result &#123; // The top portion of the matrix is the identity // matrix, and the bottom is a transposed Cauchy matrix. if r &lt; dataShards &#123; result[r][r] = 1 &#125; else &#123; for c := range row &#123; result[r][c] = invTable[(byte(r ^ c))] &#125; &#125; &#125; return result, nil&#125; Generator Polynomial Method# Define the generator polynomial: $$ g(x)=(x-\alpha)(x-\alpha{2})\dots(x-\alpha{2s}) $$ and the codeword polynomial can be directly computed as $$c(x)=m(x)g(x)$$ For the systematic form, which is more often used in practice, we define $$ b(x)=x^{2s}m(x) \quad mod\quad g(x) $$ then the codeword polynomial becomes $$ c(x)=x^{2s}m(x)-b(x) $$ where $-b(x)$ is the parity codeword polynomial. All the polynomial operation above is processed over $GF(2^8)$. It is also observed that the correction of received message can be checked by testing its divisibility by g(x), and there is no need to decode for the systematic encoding if the answer is affirmative. Otherwise, we denote $r(x)=c(x)+e(x)$ and suppose there are $ v(\leq s) $ errors Syndrome based decoder: 1.Calculate the $2s$ Syndromes: $S_{j}=r(\alpha{j})=e(\alpha{j})$ 2. Solve $$ \begin{bmatrix} S_{1} &amp; S_{2}&amp; ... &amp; S_{v} \ S_{2} &amp; S_{3} &amp; ...&amp;S_{v+1} \ ... &amp; ... &amp; ...&amp;... \ S_{v} &amp; S_{v+1} &amp; ...&amp;S_{2v-1} \end{bmatrix} \begin{bmatrix} \Lambda_{v}\ \Lambda_{v-1}\ ...\ \Lambda_{1} \end{bmatrix}=\begin{bmatrix} -S_{v} \ -S_{v+1}\ ...\ -S_{2v}\tag{4} \end{bmatrix} $$ and use Chien search solve $\Lambda(x)=\Lambda_{v}x^{v} +\Lambda_{v-1}x^{v-1}+...+1=0$ to derive the $v$ roots, denoted as,$x_{1},..,x_{v}$. 3. Use Forney algorithm to solve $$ \begin{bmatrix} x_{1}^{-1} &amp; x_{2}^{-1}&amp; ... &amp; x_{v}^{-1} \ x_{1}^{-2} &amp; x_{2}^{-2} &amp; ...&amp;x_{v}^{-2} \ ... &amp; ... &amp; ...&amp;... \ x_{1}^{-2s} &amp; x_{2}^{-2s} &amp; ...&amp;x_{v}^{-2s} \end{bmatrix} \begin{bmatrix} e_{i_{1}}\ e_{i_{2}}\ ...\ e_{i_{v}} \end{bmatrix}=\begin{bmatrix} S_{1} \ S_{2}\ ...\ S_{2s}\tag{5} \end{bmatrix} $$ 4. The index $i_{j}$ of $e_{i_{j}}$ are determined by looking up the logarithmic table as earlier mentioned 5. Compute $e(x)=\sum_{j=1}{v}e_{i_{j}}x{i_{j}}$ and $c(x) = r(x)-e(x)$. It is worth mentioning that all the syndromes are zeros if $r(x)=c(x)$, this can be used to check if the received message is corrupted or if the message was completely constructed. RS encoding is relatively straightforward for the generator approach, but decoding needs complicated algebraic computation, especially for the step 2. Because the real value of $v$ is unknown and the normal way has to use the trial value untill the matrix in $(4)$ is nonsingular. Other algebraic methods for the evaluation of this error location polynomial $\Lambda(x)$ include Berlekamp–Massey algorithm and Extended Euclidean algorithm. This syndrome based decoder can be implemented with different hardware unit such as matrix vector multiplication unit, remainder unit, and performs hard-decision decoding up to $s$ errors. Hard-decision decoding decides the bit according to the a threshold, where each bit is definitely one or zero. While soft-decision decoding requires additional reliability information to improve the decision, which has better coding gain for the white Guassian channel [2]. RS Code in Distributed Storage Systems# The RS code are stored in different disks in the distributed storage systems, and the performance arasure code in distributed storage systems involves disk I/O and repair bandwidth overhead. 5.1 Rotated Reed-Solomon code# In the conventional RS code, all the parity blocds are encoded with data blocks in the same strip, while in the rotated reed-solomon code, parity blocks may be generated with different stripes as in the following figure, when the disk 5 in the figure fails, this method reduceS 3 operations of reading the data blocks than the conventional RS code [5]. Local Reconstruction Code (LRC)# LRC introduces local parity codes which requires slightly more storage space than conventional RS code, but significantly reduce the number of participating data discs for encoding, thus it is beneficial to the reduction of bandwidth and disc I/O overhead. The figure of pyramid code is shown as follows [6] However, repair of the global redundancy still needs to access all data discs, another LRC approach in [7] further introduces parity code ($ S_{3} $ in the figure) for the global parity codes ($P_{1}$,$P_{2}$,$P_{3}$,$P_{4}$) to avoid this undesirable situation. By choosing the coefficients of $c_{1}^{'}$, $c_{2}^{'}$, $c_{3}^{'}$, $c_{4}^{'}$ and $c_{5}^{'}$, $c_{6}^{'}$ properly, the parity code of $ S_{3} $ can be calculated by the existing parity codes $ S_{1} $ and $ S_{2} $. Thus parity code $ S_{3} $ does not have to occupy additional storage. Observation: Copy is kind of LRC. References# [1] I. Reed and G. Solomon, BPolynomial codes over certain finite fields,[ J. Soc. Ind. Appl. Math., vol. 8, no. 2, pp. 300–304, Jun. 1960. [2] Wicker and Bhargava, Reed-Solomon Codes and Their Applications, 1994. [3] James S. Plank and Lihao Xu, Optimizing Cauchy Reed-Solomon Codes for Fault-Tolerant Network Storage Applications. [4] Reed–Solomon codes for coders. [5] Khan O, Burns R C, Plank J S, et al. Rethinking erasure codes for cloud file systems: minimizing I/O for recovery and degraded reads. [6] Huang Cheng, Chen Minghua, Li Jin. Pyramid codes: flexible schemes to trade space for access efficiency in reliable data storage systems. [7] Sathiamoorthy M, Asteris M, Papailiopoulos D, et al. Xoring elephants: novel erasure codes for big data. [8] J. Blomer, M. Kalfane, R. Karp, M. Karpinski, M. Luby, and D. Zuckerman, An XOR-Based Erasure-Resilient Coding Scheme.]]></content>
      <tags>
        <tag>RS Code</tag>
        <tag>Golang</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang编程基础]]></title>
    <url>%2F2018%2F08%2F20%2F2018-8-20%2F</url>
    <content type="text"><![CDATA[在Ubuntu安装: 数据类型: 基本类型： 聚集类型 (aggregate types)： 数组 结构 引用类型 指针 切片（slice） 字典（map） 函数 通道（channel） 接口类型（interface）： 控制流 （for if switch defer goto）： 创建工程目录： Tips: 其他： 参考资料： 在Ubuntu安装:# 123456789&gt;cd ~ &gt;wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz&gt;tar -C /usr/local -xzf go1.11.2.linux-amd64.tar.gz // 解压到得到的 go 目录，放到 /usr/local 目录下&gt;vim .bashrc // 写入以下内容export GOPATH=~/hejtao/go_projectsexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN&gt;source .bashrc 数据类型:# 基本类型：# 数值 整型：int； int8； int16； int32(rune，Unicode)； int64； uint； uint8(byte)； uint16； uint32； uint64； uintptr int, uint, uintptr 在 32 位系统上是 32 位，在 64位 系统上是 64位 浮点型：float32； float64 复数型：complex64； complex128 字符串：使用双引号 &quot;a&quot; 布尔: true； false 常量：三种基本类型 12345const( kb = 1024 e = 2.71828182845904523536028747135266249775724709369995957496696763 F = false) 在 if语句中，若检验条件为i &gt;= 0，则i 的类型不宜为 uint 型（uint 数据始终 &gt;= 0）。尽管内置函数 len() 返回值是非负整数，但它际返回 int 型， 1234medals := []string&#123;"gold", "silver", "bronze"&#125;for i := len(medals)-1; i &gt;= 0; i--&#123; fmt.Println(medals[i]) // "bronze", "silver", "gold"&#125; 基本类型与操作符构成表达式 取余 % 只用于整型；余数与被除数符号相同，5%3=2； -5%3=-2 5.0/4=1.25；5/4.0=1.25；5/4=1 &amp;&amp; 若左边的表达式结果为 false，不检验右边的表达式；&amp; 始终检验两边的表达式 与或^ ; 一元前缀^ 聚集类型 (aggregate types)：# 数组# 12345var a [3]intr := [...]int&#123;99: 1&#125; // 索引为99的元素，r[99]， 等于 1，其他默认 0p := new([10]int) // 将生成的数组的指针赋给 p, 为 *[10]int 类型p[0]=1 // 给 p 指向的数组的索引为0的元素赋值 1 数组的长度也是数组类型的一部分，因此 [3]int 和 [4]int 是不同类型的数组，不能进行比较或赋值。 结构# （1）结构的字段（field） 1234567891011121314151617181920212223type person struct&#123; // 定义 person 类型 gender string age int&#125;func main()&#123; student := person&#123;&#125; student.age = 16 student.gender = "male" // or student := person&#123; gender : "male", age : 16, //逗号不能省 &#125; // or student := person&#123;"male", 16&#125; teacher := &amp;person&#123; //取指针 gender : "female", age : 30, &#125; teacher.age = 36 //指针 teacher 仍然可以进行点操作&#125; 指针也可以进行点操作。 匿名结构，字段匿名 1234567891011121314student := struct&#123; // 匿名结构 gender : string age : int&#125;&#123; gender : "male", age : "17",&#125;type person struct&#123; string int&#125;// 按照顺序初始化student := person&#123;"male", 10&#125; 结构嵌套， 12345678910111213141516171819202122232425262728type person struct&#123; gender string age int parents struct&#123; // 嵌套一个匿名结构 dad, mom : string &#125;&#125;type address struct&#123; state, city string&#125;type person2 struct&#123; gender string age int address // 嵌套你一个结构address&#125;func main()&#123; student := person&#123;gender : "female", age : 10&#125; student.parents.dad = "Tom" student.parents.mom = "Lily" student2 := person2&#123;gender:"female", age:10, address : address&#123;county:"LA" state:"California"&#125; &#125; student2.address.state = "Massachusetts" // or student2.state = "Massachusetts" &#125; （2）结构的方法（method） 函数与方法 123456789101112131415161718192021222324package mainimport ( "fmt" "math")type Point struct&#123; X, Y float64 &#125;func Distance(p, q Point) float64 &#123; //函数 return math.Hypot(q.X-p.X, q.Y-p.Y)&#125;func (p Point) Distance(q Point) float64 &#123; // 方法，在函数名前增加一个形参（receiver） 类似于Java的this 和python的 self， return math.Hypot(q.X-p.X, q.Y-p.Y) // 接收者的名称通常取它的类型名称的第一个字母&#125;func main() &#123; p := Point&#123;1, 2&#125; q := Point&#123;4, 6&#125; fmt.Println(Distance(p, q)) // 打印 5， 调用函数 fmt.Println(p.Distance(q)) // 调用方法&#125; 当需要使用方法对值（value of type T，相对于方法来讲就是实参，argument） 的字段进行修改时，使用接收者为指针的方法或者叫指针方法 1234func (p *Point) ScaleBy(factor float64) &#123; // 接收者参数p的类型是指针类型 p.X *= factor // p在这里是指针，等价于 (*p).X p.Y *= factor&#125; 同一个 struct 的方法和字段占据相同的命名空间（name space），因此两者的名称不能重复； 指针方法看作高权限方法。 对方法的调用, 值（实参） 和 接收者（形参）类型要相同 12345678Point&#123;1, 2&#125;.Distance(q) // Point Pointpptr.ScaleBy(2) // *Point *Pointpptr.Distance(q) // 隐含 (*pptr)p.ScaleBy(2) // 隐含 (&amp;p) Point&#123;1, 2&#125;.ScaleBy(2) //错误！！！(&amp;Point&#123;1, 2&#125;).ScaleBy(2) 不仅仅是 struct 123456789101112131415161718package mainimport ( "fmt")type INT intfunc main() &#123; var a INT a = 1 a.Print() // 打印 2&#125;func (a *INT) Print() &#123; *a = 2 fmt.Println(*a)&#125; 方法是与命名类型(named type)相关联的函数。 引用类型# 指针# 1234var p *inti := 20p = &amp;i*p = 10 // i 的值为 10 切片（slice）# 123456789101112131415var s []int // 声明切片 sa := [5]int&#123;1, 2, 3, 4, 5&#125;s = a[:2] // [1, 2]， len(s)等于2，cap(s)等于5s = a[0:1] // [1]，len(s)等于1，cap(s)等于5s = a[3:] // [4, 5]，len(s)等于2，cap(s)等于2s := make([]int, 2, 4) //make([]type, len, cap) ，切片长度为2，底层数组的长度为4s = append(s, 1) // s 的地址不变s = append(s, 2, 3) // 生成新的数组，地址改变，容量翻倍，也就是cap(s)等于4*2=8s1 := []int&#123;1, 2, 3&#125;s2 := []int&#123;4, 5&#125;copy(s1, s2) //把 s2 复制到 s1，s1 为 [4, 5, 3]s1 = []int&#123;1, 2, 3&#125;copy(s2, s1) // s2 为 [1, 2] 切片的本质是对底层数组的引用；切片的容量（cap）是切片的始索引到底层数组的末索引的长度。 字典（map）# 123456var m map[int]string // key int 型；value string 型m = make(map[int]string)m2 := make(map[int]string)m[0] = "OK"delete(m, 0) // 删除 m 中键为0的键值对 嵌套， 123m := make(map[int]map[int]string) // value map型m[1] = make(map[int]string)m[1][2] = "YES" 函数# func main(int, []string) int means， function main takes an int and a slice of strings and returns an int 函数作为类型， 1var f func(func(int,int) int, int) func(int, int) int 不定长变参，闭包 12345678910111213141516171819202122232425262728package mainimport ( "fmt")func main()&#123; var_args(1) var_args(1, 2, 3) f := closure(10) fmt.Println(f(1)) fmt.Println(f(2)) &#125;func var_args(args ...int)&#123; fmt.Println(args)&#125;func closure(x int) func(int) int&#123; // 返回匿名函数 return func(y int) int&#123; return x + y &#125;&#125;输出：[1][1 2 3]1112 通道（channel）# channel 是 goroutine 沟通的桥梁，通过 make 创建，close 关闭 12345678910111213141516package mainimport ( "fmt")func main() &#123; c := make(chan bool) go func() &#123; fmt.Println("I from goroutine !") c &lt;- true &#125;() &lt;-c&#125; channel 作为函数形参 123456789101112131415161718package mainimport ( "fmt")func main() &#123; c := make(chan bool) go Hello(c) &lt;-c&#125;func Hello(c chan bool) &#123; fmt.Println("Hello, I from goroutine!") c &lt;- true &#125; 多个 goroutine，多个channel 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt" "runtime")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) // 开启多核 c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; // 启动多个 goroutin go Decomposition(c, i, 100000007) &#125; for i := 0; i &lt; 5; i++ &#123; // 多个 channel 阻塞 &lt;-c &#125;&#125;func Decomposition(c chan bool, index int, n int) &#123; // 质数分解 for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", index, n) c &lt;- true&#125;输出： 0: 1000000072: 1000000071: 1000000074: 1000000073: 100000007从输出结果的顺序可以看出 goroutine 并非先启动先执行 使用同步包来代替 channel 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( "fmt" "runtime" "sync")func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) wg := sync.WaitGroup&#123;&#125; wg.Add(5) // 添加 5 个 任务（goroutine） for i := 0; i &lt; 5; i++ &#123; go Decomposition(&amp;wg, i, 100000007) &#125; wg.Wait() // 等到任务数减到 0 &#125;func Decomposition(wg *sync.WaitGroup, m int, n int) &#123; for i := 2; i &lt;= n; i++ &#123; for n != i &#123; if n%i == 0 &#123; fmt.Printf("%d*", i) n = n / i &#125; else &#123; break &#125; &#125; &#125; fmt.Printf("%d: %d\n", m, n) wg.Done() // 任务数减 1&#125;输出：0: 1000000072: 1000000074: 1000000071: 1000000073: 100000007 selec{}语句， 如果有多个case 读取数据，select会随机选择一个case执行，其他不执行； 如果没有case读取数据，就执行default； 如果没有case读取数据，且没有default，select将阻塞，直到某个case可以执行。 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "fmt")func main() &#123; c1, c2, block := make(chan int), make(chan string), make(chan bool) go func() &#123; for &#123; select &#123; // 按随机顺序处理多个 case case message, open := &lt;-c1: if !open &#123; // 如果通道 c1 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c1:", message) case message, open := &lt;-c2: if !open &#123; // 如果通道 c2 关闭，则跳出无限循环 block &lt;- true break &#125; fmt.Println("A message from main by c2:", message) &#125; &#125; &#125;() c1 &lt;- 10 c2 &lt;- "hello" c1 &lt;- 20 c2 &lt;- "world" close(c1) // 关闭通道 c1 &lt;-block&#125;输出：A message from main by c1: 10A message from main by c2: helloA message from main by c1: 20A message from main by c2: world 12345678910111213141516171819package mainimport ( "fmt" "time")func main() &#123; select &#123; case &lt;-time.After(2000000 * time.Microsecond): fmt.Println("2 seconds") case &lt;-time.After(1999999 * time.Microsecond): fmt.Println("1.999999 seconds") &#125;&#125;输出：1.999999 seconds 接口类型（interface）：# （1）接口代表某些方法的集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( "fmt")type game interface &#123; Strike_of_Kings() int Battle_Grounds() int&#125;type contact interface &#123; Wechat() QQ()&#125;type smartphone interface&#123; // 接口嵌套， game contact&#125;type iphone struct &#123; version string price float32 user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func (iph *iphone) QQ() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;// iphone 不满足 contact 接口func (iph iphone) Battle_Grounds() int &#123; fmt.Println("There are 4 teammates at most in the Battle Grounds.") return 4&#125;func (iph iphone) Strike_of_Kings() int &#123; fmt.Println("There are 5 teammates at most in the Strike of Kings.") return 5&#125;// iphone 满足 game 接口func (iph *iphone) New_Version(version string) &#123; iph.version = version&#125;func all_round_game(game) &#123; // 接口作为形参 fmt.Println("Both Strike of_Kings and Battle Grounds have installed.")&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; my_phone.Wechat() fmt.Println(my_phone.Battle_Grounds()) all_round_game(my_phone) // my_phone 符合 game 接口，可作为该函数的实参 var _ game = iphone // 确保 iphone 实现了接口game &#125; （2）任何类型都满足空接口；空接口interface{}作为形参可以接受任何类型的实参 12345678910111213141516171819202122232425package mainimport ( "fmt")func main() &#123; m := make(map[int]interface&#123;&#125;) m[1] = "a" m[2] = 2 m[3] = false print_map(m)&#125;func print_map(m map[int]interface&#123;&#125;) &#123; for k, v := range m &#123; fmt.Println(k, ":", v) &#125;&#125;输出：1 : a2 : 23 : false []string 和 []interface{} 是不同的类型； 接口是一种抽象类型，可理解为是将所有具体类型按照方法集进行再分类； 指针方法集包含非指针方法集。 （3）接口值（interface value）包含 类型 （接口的动态类型）和 类型值 （接口的动态值） 两个部分，仅当两者均为nil 时，接口才为nil （4）反射 （reflection） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt" "reflect")type iphone struct &#123; version string price int user string&#125;func (iph iphone) Wechat() &#123; fmt.Println("I installed wechat on my iphone", iph.version)&#125;func main() &#123; my_phone := iphone&#123;"X", 8316, "Xiaohe"&#125; Info(my_phone)&#125;func Info(itf interface&#123;&#125;) &#123; t := reflect.TypeOf(itf) fmt.Println(t) for i := 0; i &lt; t.NumField(); i++ &#123; fmt.Println(t.Field(i)) &#125; fmt.Println("___________________") v := reflect.ValueOf(itf) fmt.Println(v) for i := 0; i &lt; v.NumField(); i++ &#123; fmt.Println(v.Field(i)) &#125;&#125;输出：main.iphone&#123;version main string 0 [0] false&#125;&#123;price main int 16 [1] false&#125;&#123;user main string 24 [2] false&#125;___________________&#123;X 8316 Xiaohe&#125;X8316Xiaohe 控制流 （for if switch defer goto）：# （1）for： 1234567891011for (inti statement)；condition；(post statement) &#123;&#125;for i := 0; i &lt; 10; i++ &#123;&#125; for ; i &lt; 10; &#123; // 去掉分号&#125; for i &lt; 10&#123; // while 语句&#125;for&#123; // 无限循环&#125; （2）if： 123456 if (init statement)；condition &#123;&#125; if (init statement)；condition &#123;&#125;else &#123;&#125; （3）switch： 12345678910111213switch (init statement)；some value &#123; case 0： case f()： ... default：&#125;switch &#123; case 布尔表达式1： case 布尔表达式2： ... default：&#125; 一旦符合条件自动终止，若希望继续检验下面的case，使用 fallthrough 语句。 （4）defer： defer 后必须跟函数引用 defer 语句被检验后，延迟函数获得变量的拷贝 123456func a() &#123; i := 0 defer fmt.Println(i) i++ return&#125; // defer 语句打印0 defer 语句被检验后，延迟匿名函数获得变量的地址 12345678910111213func b() (i int) &#123; defer func() &#123; i++ &#125;() return 1 // 将1 赋给 i&#125; // 返回 2。利用 defer 语句修改外围函数的命名返回值func c() &#123; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Print(i) &#125;() &#125; return&#125; // 打印 333 defer 语句被检验后，延迟函数的引用被推入堆栈，当外围函数返回后，按照后进先出的顺序被调用（即使外围函数发生错误，如 panic，延迟函数仍然会被调用） 12345func d() &#123; for i := 0; i &lt; 4; i++ &#123; defer fmt.Print(i) &#125;&#125; // 打印 3210 更多细节如，panic， recover（只能用在延迟函数中） 参考 defer blog。 （5）goto： 123456789101112131415161718192021222324LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; break LABEL // 跳出与LABEL同级的循环，即跳出无限循环 &#125; &#125; &#125;LABEL: for i := 0; i &lt; 10; i++ &#123; for &#123; continue LABEL &#125; &#125;LABEL: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; goto LABEL // 将再次进入无限循环 &#125; &#125; &#125; 通常标签放到 goto 的后面。 创建工程目录：# Go工程中共有三个部分： src：存放go源码文件 pkg：存放编译后的包文件 bin：存放编译后的可执行文件 **注意：**src目录需要自己创建，pkg和bin编译时会自动创建。 步骤： 新建工程目录，my_project，并在该目录下创建 src目录； 把my_project 添加到 GOPATH，GOPATH=/home/user/...;my_project（可以同时添加多个路径目录，Linux下用冒号:隔开，window下分号;隔开）; 在 src 下创建my_pkg 和 my_cmd; 包文件放入到 my_pkg 中，比如 test.go 1234567package my_pkgimport "fmt" func Test()&#123; fmt.Println("Hello,world!") fmt.Println("You used a function defined in my_package!")&#125; 在命令行src目录，执行 go install my_pkg 将创建 pkg 目录并声成 my_pkg.a 文件。 my_cmd 中放入 package main，比如 hello_world.go 12345678package mainimport( "my_pkg")func main()&#123; my_pkg.Test()&#125; 在命令行src目录，执行 go install my_cmd 将创建 bin 目录并生成可执行文件成 hello_world.exe 文件。 目录结构： src/ $\quad$ my_pkg/ $\qquad$ test.go $\quad$ my_cmd/ $\qquad$ hello_world.go Tips:# import 包A的时候，会自动调用包A的init()函数（i字母小写）。如果该包A又import了别的包B，会优先调用包B的init()函数，最后才调用main包的init()函数。 一个包的init()函数可以定义多个，每个都会被调用，调用的顺序按文件名排序。同一个文件也可以定义多个init函数。 其他：# fmt.printf verbs： %x %b：16进制，2进制显示；%t：显示 bool 结果；%T：显示值的类型；%v：显示值；%p：显示地址；\n：换行 Sublime text 3 上一个编辑处: alt+- 下一个编辑处: alt+shift+- GoSublime： GoSublime快捷键列表：ctrl+.+. (连击 .) 查看声明：ctrl+.+h 代码跳转：ctrl+shift+左键 package control：ctrl+shift+p Goland：退回上一次光标位置：ctrl+win+alt+左键 参考资料：# [1] 无闻;Go编程基础系列视频. [2] Alan A.A. Donovan; Brain W. Kernighan; The Go Programming Language; 2015.]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>长文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地项目上传到 Github 仓库、Git开发命令]]></title>
    <url>%2F2018%2F07%2F04%2F2018-7-4%2F</url>
    <content type="text"><![CDATA[生成本地版本库 （.git 文件夹） 创建 SSH key 创建 GitHub 仓库 上传到 GitHub 仓库 本地修改跟新到 GitHub 仓库 生成本地版本库 （.git 文件夹）# 123git initgit add .git commit -m "..." 操作如下， 创建 SSH key# 查看 c盘 用户目录是否包含 .ssh 目录。如果包含，打开 id_rsa.pub 文件并复制里面的内容（密钥） 如果不包含 .ssh 目录（上述操作会报错），通过如下命令创建 1ssh-keygen -t rsa -C "your email address" 其中 C 为大写。然后按照前面的方式复制密钥。 将密钥添加到 GitHub 创建 GitHub 仓库# ![](https://upload-images.jianshu.io/upload_images/1863961-d05408b0cfc2e198.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) ![](https://upload-images.jianshu.io/upload_images/1863961-f7edb952c890e069.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/650) 上传到 GitHub 仓库# 12git remote add origin git@github.com:jiangtaohe/test.gitgit push -u origin master 本地修改跟新到 GitHub 仓库# 若本地已经关联到仓库，git remote add origin 命令行去掉。 1234git remote add origin git@github.com:jiangtaohe/test.gitgit add .git commit -m "..."git push 1git add file file的修改添加到暂存区 1git commit file -m "备注信息" 创建新的版本库，并将file在暂存区中的修改添加到新的版本库中 1git stash 将工作区和暂存区的修改装箱后回到版本库初始状态(相当于撤销所有修改) 1git stash pop 将 git stash装箱的修改倒出 1git checkout -- file 撤销file工作区的修改 12git checkout --ours (--theirs) filegit add file file发生merge冲突时，完全采取本方(他方)的修改 1git fetch origin dev:local_dev 获取远程分支dev的代码，并在本地创建本地分支local_dev 1git pull origin dev 拉取远程分支dev与当前分支和并(merge) 1git reset --hard commit_id(前4位数) 切换到某个版本库 1git branch branch_name 新建分支 1git branch -d branch_name 删除分支 1git merge branch_name 合并分支 123git statusgit loggit reflog 1git remote -v 打印远程仓库名称和地址 1git remote set-url --add origin git@gitlab.com:jiangtaohe/test.git 增加一个远程仓库 1git rm --cached a.txt git不再跟踪a.txt, 但文件仍保留 1git rm -f a.txt git不再跟踪a.txt, 同时文件被删除]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅历]]></title>
    <url>%2F2018%2F07%2F01%2F2018-7-1%2F</url>
    <content type="text"><![CDATA[有时人的成长在不知不觉中发生，且不论是生理上的还是心智上的。比如人的身高的变化，对于旁人看来是很大的改变，但对于当事人可能是相当无感的（除非你刻意的去测量，并画出折线图来，很少人会这么做吧）。与前者相比，心智的 变化更加隐蔽，你甚至都不好记录数据作出图表来，但并非一无所知，有些是可以从生活中窥见端倪。 少年时期的我非常讨厌吃苦瓜。你可能已经脑补出我第一次吃苦瓜时候的表情了。 “是人吃的吗？”，当然没有说出口，但我当时就那么想的。让我惊奇的是母亲竟吃得津津有味 (＃°Д°) 好像我吃了一口假的苦瓜。转念一想，既然这玩意儿都叫苦瓜了，那是必苦无疑了。那时的我品不来苦瓜的味道，自然理解不了母亲的有滋有味了。后来偶尔遇到苦瓜也会吃上一小片，“浅尝辄止”，毕竟还是那个味儿啊，干嘛亏待自己。直到上了大学后才有了改变。 话说我在大学吃了几年食堂，喜欢吃的都吃得腻了。某天心血来潮，要不来盘炒苦瓜吧。我突然发现这玩意儿不那么苦了，甚至感到别有一番风味。原以为跟苦瓜品种有关，所以后来回外婆家时，我特意让外婆做了道炒苦瓜，吃起来也是不那么苦。我意识到“物是人已非”，苦瓜还是年少时的苦瓜，而我却不一样了。这种变化当然有生理上的，但更多的是心智上的，而后者是自己的阅历在不断增长的结果。有些事情阅历够了自然就会了。 类似的还有对戏曲的理解。以前的我根本就看不了戏曲的，无感啊。随着年龄的增长，我对戏曲的态度也发生改变，虽然谈不上热爱，但多少也能品到其中的一些韵味。尤其是京剧，不愧为国粹，尽管没看过一个完整的剧目，也叫不出多少剧目的名字来，当我被表演者的一颦一簇、一唱一打所牵动的时候，我知道那就是好的戏曲，了不起的艺术！]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独憩]]></title>
    <url>%2F2018%2F06%2F19%2F2018-6-19%2F</url>
    <content type="text"><![CDATA[有时候我真地喜欢安静，独自一人，不被打扰，做一些没有意义的事情。 当下简单地唯水，笔，布而已。]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运动与冥想]]></title>
    <url>%2F2018%2F06%2F14%2F2018-6-14%2F</url>
    <content type="text"><![CDATA[近来又把跑步纳入日常。跑着跑着，跑出了一点心得，今以记之，算是对自己坚持锻炼的勉励。 一开始，我是跟着小伙伴一起跑来着，然后有几次自己跑。回想运动时候的状态，我发现自己跑运动地更充分，锻炼的效果也更好。据说跑步半个小时是一种很好的锻炼方式，前提是要保质保量。保质就要求全程保持在跑的状态，你可以跑快点或者慢点，但不要是 walking 。保量就是最少跑半个小时，当然你也可以按照路程（多少圈跑道）来计。值得注意的是，这个保质保量因人而异，你需要给自己设立合理的目标且不能够轻易就可达成。 专注于跑步有利于目标的达成。这也解释了为什么独自跑步的效果更好（与小伙伴相互鼓励当然也挺好），因为不用刻意去协调别人，你可以更快找到自己的节奏。当你持续地专注于自己的身体和感觉时，你可以体会到控制与活力，而维持标准动作可以加深这种体会。因此，不妨把跑步看作一次冥想训练，专注于自我，体会积极的力量也接受脑涨腿乏感觉，但不要让疲劳占据上风，否则你将动作变形，愈感举步维艰。 避免外部干扰因素有助于专注，比如握着手机，携带狗狗等尽量避免。 最后需要强调的是注意安全。当身体出现不适的时候，千万不要勉强。前两些天就有公众号报道某男子跑步过程中摔倒了两次仍要坚持，最终导致猝亡的杯具。还有上文提到独自运动有助于专注，但还是避免去人少的地方活动，尤其是女同学。学校的操场是绝佳的场所，因为有其他的同学还可以减少孤独感，对自己的坚持是很有帮助的。]]></content>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多宝塔碑精选]]></title>
    <url>%2F2018%2F06%2F10%2F2018-6-10%2F</url>
    <content type="text"><![CDATA[《多宝塔碑》精选三十七字。来源于搜狐“书法思考”，今藏以时习之。 横、竖：(三、王、十、半、中)# 撇、捺：(大、手、又、年、入)# 点：(心、涵、浮、并、尚、小、於、其、感)# 钩、挑：(宗、求、观、表、见、咸、食、以)# 折：(自、名、了、山、牙、矣、母、外、女)#]]></content>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 笔记]]></title>
    <url>%2F2018%2F05%2F28%2F2018-5-28%2F</url>
    <content type="text"><![CDATA[创建 flask instance（也就是一个应用）两种方式：1. (module) 在URL\my_app.py中加入 12from flask import Flaskapp = Flask(__name__) 2.(package) 在URL\app_folder\__init__.py中加入 12from flask import Flaskapp = Flask(&apos;app_folder&apos;) 阅读 Miguel Grinberg's book: Flask Web Developent SECOND EDITION 中的一个小应用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import os from datetime import datetime # python 标准库，datetime.utcnow()from flask import Flask, render_template, session, redirect, url_for, flash from flask_bootstrap import Bootstrap # flask 扩展from flask_moment import Moment # flask 扩展from flask_wtf import FlaskFormfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequiredfrom flask_sqlalchemy import SQLAlchemyfrom flask_migrate import Migratebasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__) # 创建应用app.config['SECRET_KEY'] = 'hard to guess string'app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(basedir, 'data.sqlite')app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = Falsebootstrap = Bootstrap(app) # templates 文件夹中 base.html 扩展了 bootstrap/base.htmlmoment = Moment(app) # 设置日期、时间的格式。moment.js 由 base.html导入db = SQLAlchemy(app) # 创建数据库migrate = Migrate(app, db)class Role(db.Model): __tablename__ = 'roles' # 表格名称 id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship('User', backref='role', lazy='dynamic') # 与 User 类关联。backref 给 User 类创建 role 属性，在生成 User 对象时通过 role 与一个 Role 对象关联。 def __repr__(self): # 直接输出对象或者通过 print 打印对象时，信息都按__repr__方法中定义的格式进行显示。 类似的 __str__ 只有在 print 打印时才生效。便于调试。 return '&lt;Role %r&gt;' % self.nameclass User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey('roles.id')) def __repr__(self): return '&lt;User %r&gt;' % self.usernameclass NameForm(FlaskForm): name = StringField('What is your name?', validators=[DataRequired()]) # DataRequired()要求提交时表单不为空 submit = SubmitField('Submit') # 表单的提交按钮。 在 render html 时，添加 type='Submit' 属性@app.shell_context_processordef make_shell_context(): # 运行 flask shell 时自动从 app(hello.py) 导入 db, User, Role return dict(db=db, User=User, Role=Role)@app.errorhandler(404) def page_not_found(e): # 404，500 为 html 错误类型 return render_template('404.html'), 404 # 返回元组@app.errorhandler(500)def internal_server_error(e): return render_template('500.html'), 500'''@app.route('/')def index(): return render_template('index.html', current_time=datetime.utcnow())'''@app.route('/user/&lt;name&gt;')def user(name): return render_template('user.html', name=name) # name=name， 前者代表 user.html 中的 name 变量，后者代表由用户在网址栏中输入的值，即&lt;name&gt;@app.route('/', methods=['GET', 'POST']) def index(): # Post/Redirect/Get pattern，inde()被调用两次 form = NameForm() # 生成表单实例 if form.validate_on_submit(): # 表单被提交且通过所有的 validators （这里只有 DataRequired()一个）时返回 True old_name = session.get('name') if old_name is not None and old_name != form.name.data: flash('Looks like you have changed your name!') # 当两次提交的内容不同时显示提示框。flash() 里的参数被 模板 base.html 中的 get_flashed_messages() 函数提取。 session['name'] = form.name.data # 保存表单提交的 data return redirect(url_for('index')) # url_for('index') 返回 root URL。redirect() 发出对 root URL 的 GET请求，作为对 POST 请求的回应。 return render_template('index.html', form=form, name=session.get('name')) # 对 redirect() 的 GET请求的回应。# 加入数据库@app.route('/', methods=['GET', 'POST'])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() # 查询表单提交的用户名 if user is None: # 如果不在数据库中就把它加入 user = User(username=form.name.data) db.session.add(user) db.session.commit() session['known'] = False else: session['known'] = True session['name'] = form.name.data return redirect(url_for('index')) return render_template('index.html', form=form, name=session.get('name'), known=session.get('known', False))]]></content>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to Create a Personal Blog]]></title>
    <url>%2F2018%2F05%2F22%2F2018-5-22%2F</url>
    <content type="text"><![CDATA[The Structure of The Blog Apply For a Github Account and Create a Repository Create hexo source file download and install create file select and add your theme 2.4 deploy the source file to the github repository When you see this blog post, you have already had some kind of motivation to create a personal blog, maybe it is to possess something, record your ideas or just to be cool. From my observation, most people who have a personal blog are the computer professionals. But this does not mean you have to create your blog with much computer knowledge. The rest of this post will show you the process can be easy and fun. The Structure of The Blog# From the structure, you almost know what to do next. You don't have to build a browser, since your PC has already had one. You just need to do the left two things, applying for a github account as the remote platform to store your blog files, creating the local source file which is the root of your blog. Apply For a Github Account and Create a Repository# Click Github to apply. Create hexo source file# Most of the source file is generated by Hexo which is a popular blog framework and is based on Node.js. We also need Git to deploy the source file to your newly created repository. download and install# Node.js Git Hexo is installed with the Git tool. After installing the Git, click your the right mouse button on the desktop and select the &quot;Git Bash Here&quot; option (means open the bash window in the current directory). Type the following commond to enter your home directory. 1cd ~ Input the following commond to install Hexo. 1npm install hexo-cli -g create file# Create hexo source file . You can make your own file name to replace &quot;hexo_source&quot;. 1hexo init hexo_source select and add your theme# Select a theme from hexo themes library . You can also use hexo-new-vno if you like the theme of my blog 😉. Then use the commond to add the theme file to your hexo source file you have already created. 12cd hexo_sourcegit clone https://github.com/monniya/hexo-theme-new-vno themes/new-vno You will see the new-vno file at ...\hexo_source\themes\new-vno if not wrong. In fact, hexo has a built-in theme landscape. Open ...\hexo_source\ _config.yml (you can use editors like atom, sublime etc.) and revise some arguments. 1234567891011121314151617181920title: 小禾の新世界subtitle: STAY HUNGRY, STAY FOOLISH!description: (～￣▽￣)～ 嗨 (✿●'◡'●)keywords:author: #your name as authorlanguage: zh-Hans timezone: email: #your email addressurl: https://your_user_name.github.ioroot: /your_user_name.github.io/plugins: hexo-generate-feed # you need input "npm install hexo-generate-feed" in the git bash window to install this plugin.theme: new-vnodeploy: type: git repo: https://github.com/your_user_name/your_user_name.github.io.git branch: master More details of configuration click here. And revise arguments in ...\hexo_source\themes\new-vno\ _config.yml to configure the theme. 12345678910111213menu: 归档: /archivesrss: /atom.xmldescription: RSSsocial: weibo: #your weibo address github: #your github address stack_overflow: facebook: twitter: google_plus: To write a blog, you just write a markdown file in .../hexo_source/source/ _posts folder. 1234567---title: How to Create a Personal Blogdate: 2018-05-22 21:37:37tags: hexo---My first blog post ...## The Structure of The Blog 2.4 deploy the source file to the github repository# Install the deploy tool. 1npm install hexo-deployer-git --save Start to deploy. 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d After the deploy you can visit your blog by typing &quot;your_user_name.github.io&quot; in the browser. You have already built the blog. Congratulations!]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
